{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP4KhZQNlU6ZPcwnCdbBtBT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MinsooKwak/Public_data_analysis/blob/main/Skills/Crawling_intro.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# requests 패키지 사용 방법"
      ],
      "metadata": {
        "id": "O7g5eHzU8R5S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**urllib**\n",
        "\n",
        "- 조금 느림"
      ],
      "metadata": {
        "id": "BrZC9nFv9wba"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmXLzmFD8Q53",
        "outputId": "56eaa6d6-257a-498c-c5b1-5ddb43128967"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "b'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"en\"><head><meta content=\"Search the world\\'s information, including webpages, images, videos and more. Google has many special features to help you find exactly what you\\'re looking for.\" name=\"description\"><meta content=\"noodp\" name=\"robots\"><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"d1f-ilLsKF5YwBIKeB2CIw\">(function(){var _g={kEI:\\'xH78ZMXcBtKmqtsP-rWXwAg\\',kEXPI:\\'0,793110,566299,6059,206,4804,2316,383,246,5,1129120,1197737,657,380096,16115,28684,22430,1362,12316,17583,4998,17075,38444,2872,2891,3926,213,7615,606,29843,20215,10632,15324,781,1244,1,16916,2652,4,32894,13064,13659,2980,1457,22595,6642,7596,1,39047,1,3109,2,16392,342,23024,5679,1020,31122,4569,6258,23418,1249,33067,2,2,1,24626,2006,8155,7381,2,3,15965,872,9626,10008,7,1922,9779,22887,13398,2393,3781,20198,20137,14,82,16514,3692,109,2412,849,5007,3785,15203,2277,3098,2266,764,5628,483,5040,4665,1804,7734,18098,575,6690,2172,5249,238,6326,1635,2170,6669,868,5279,11712,1993,5922,7653,5089,3,9,3689,440,1271,3592,5210031,108,2,195,47,5994723,97,2803117,3311,141,795,19735,1,1,346,8436,80,8,46,5,7,24,6,11,7,78,2,6,20,15,5,14,11,17,1,2,2,1,1,2,1,2,1,2,1,22,23941649,2862026,1182080,16673,36928,2354,1400657,23764694,2739,4636,8409,2878,444,1154,29,3498,24,1708,4723,241,495,1197,274,4941,1372,1705,284,2388,2811,1996,452,1,1541,296,7,258,270,1,1,2,3,2070,3,487,661,486,238,631,384,2639,1981,117,1520,881,1598,554,482,843,361,10,2,19,3,146,1700,500,2,493,302,41,1492,2,1007,1665,1512,1335,1,1131,464,429,886,879,1362,61,120,157,1076,429,248,619,1451,250,124,100,179,56,1,469,774,2,287,47,5,774,47,1366,46,495,172,1,2,266,176,1637,188,464,537,1109,1187,206,305,4,9,1238,1222,12,1541,284,152,1,561,4,537,562,669,142,23,195,876,149,444,6,1,1,2,3,248,1,141,2,380,160,4,9,662,216,208,316,280,27,258,223,1160,1044,96,4,454,54,67,1,486,2,330,63,1,501,328,1351,456,56,4\\',kBL:\\'AiMy\\',kOPI:89978449};(function(){var a;(null==(a=window.google)?0:a.stvsc)?google.kEI=_g.kEI:window.google=_g;}).call(this);})();(function(){google.sn=\\'webhp\\';google.kHL=\\'en\\';})();(function(){\\nvar h=this||self;function l(){return void 0!==window.google&&void 0!==window.google.kOPI&&0!==window.google.kOPI?window.google.kOPI:null};var m,n=[];function p(a){for(var b;a&&(!a.getAttribute||!(b=a.getAttribute(\"eid\")));)a=a.parentNode;return b||m}function q(a){for(var b=null;a&&(!a.getAttribute||!(b=a.getAttribute(\"leid\")));)a=a.parentNode;return b}function r(a){/^http:/i.test(a)&&\"https:\"===window.location.protocol&&(google.ml&&google.ml(Error(\"a\"),!1,{src:a,glmm:1}),a=\"\");return a}\\nfunction t(a,b,c,d,k){var e=\"\";-1===b.search(\"&ei=\")&&(e=\"&ei=\"+p(d),-1===b.search(\"&lei=\")&&(d=q(d))&&(e+=\"&lei=\"+d));d=\"\";var g=-1===b.search(\"&cshid=\")&&\"slh\"!==a,f=[];f.push([\"zx\",Date.now().toString()]);h._cshid&&g&&f.push([\"cshid\",h._cshid]);c=c();null!=c&&f.push([\"opi\",c.toString()]);for(c=0;c<f.length;c++){if(0===c||0<c)d+=\"&\";d+=f[c][0]+\"=\"+f[c][1]}return\"/\"+(k||\"gen_204\")+\"?atyp=i&ct=\"+String(a)+\"&cad=\"+(b+e+d)};m=google.kEI;google.getEI=p;google.getLEI=q;google.ml=function(){return null};google.log=function(a,b,c,d,k,e){e=void 0===e?l:e;c||(c=t(a,b,e,d,k));if(c=r(c)){a=new Image;var g=n.length;n[g]=a;a.onerror=a.onload=a.onabort=function(){delete n[g]};a.src=c}};google.logUrl=function(a,b){b=void 0===b?l:b;return t(\"\",a,b)};}).call(this);(function(){google.y={};google.sy=[];google.x=function(a,b){if(a)var c=a.id;else{do c=Math.random();while(google.y[c])}google.y[c]=[a,b];return!1};google.sx=function(a){google.sy.push(a)};google.lm=[];google.plm=function(a){google.lm.push.apply(google.lm,a)};google.lq=[];google.load=function(a,b,c){google.lq.push([[a],b,c])};google.loadAll=function(a,b){google.lq.push([a,b])};google.bx=!1;google.lx=function(){};var d=[];google.fce=function(a,b,c,e){d.push([a,b,c,e])};google.qce=d;}).call(this);google.f={};(function(){\\ndocument.documentElement.addEventListener(\"submit\",function(b){var a;if(a=b.target){var c=a.getAttribute(\"data-submitfalse\");a=\"1\"===c||\"q\"===c&&!a.elements.q.value?!0:!1}else a=!1;a&&(b.preventDefault(),b.stopPropagation())},!0);document.documentElement.addEventListener(\"click\",function(b){var a;a:{for(a=b.target;a&&a!==document.documentElement;a=a.parentElement)if(\"A\"===a.tagName){a=\"1\"===a.getAttribute(\"data-nohref\");break a}a=!1}a&&b.preventDefault()},!0);}).call(this);</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}\\n</style><style>body,td,a,p,.h{font-family:arial,sans-serif}body{margin:0;overflow-y:scroll}#gog{padding:3px 8px 0}td{line-height:.8em}.gac_m td{line-height:17px}form{margin-bottom:20px}.h{color:#1967d2}em{font-weight:bold;font-style:normal}.lst{height:25px;width:496px}.gsfi,.lst{font:18px arial,sans-serif}.gsfs{font:17px arial,sans-serif}.ds{display:inline-box;display:inline-block;margin:3px 0 4px;margin-left:4px}input{font-family:inherit}body{background:#fff;color:#000}a{color:#681da8;text-decoration:none}a:hover,a:active{text-decoration:underline}.fl a{color:#1967d2}a:visited{color:#681da8}.sblc{padding-top:5px}.sblc a{display:block;margin:2px 0;margin-left:13px;font-size:11px}.lsbb{background:#f8f9fa;border:solid 1px;border-color:#dadce0 #70757a #70757a #dadce0;height:30px}.lsbb{display:block}#WqQANb a{display:inline-block;margin:0 12px}.lsb{background:url(/images/nav_logo229.png) 0 -261px repeat-x;color:#000;border:none;cursor:pointer;height:30px;margin:0;outline:0;font:15px arial,sans-serif;vertical-align:top}.lsb:active{background:#dadce0}.lst:focus{outline:none}</style><script nonce=\"d1f-ilLsKF5YwBIKeB2CIw\">(function(){window.google.erd={jsr:1,bv:1864,de:true};\\nvar l=this||self;var m,n=null!=(m=l.mei)?m:1,p,q=null!=(p=l.sdo)?p:!0,r=0,t,u=google.erd,v=u.jsr;google.ml=function(a,b,d,h,e){e=void 0===e?2:e;b&&(t=a&&a.message);if(google.dl)return google.dl(a,e,d),null;if(0>v){window.console&&console.error(a,d);if(-2===v)throw a;b=!1}else b=!a||!a.message||\"Error loading script\"===a.message||r>=n&&!h?!1:!0;if(!b)return null;r++;d=d||{};b=encodeURIComponent;var c=\"/gen_204?atyp=i&ei=\"+b(google.kEI);google.kEXPI&&(c+=\"&jexpid=\"+b(google.kEXPI));c+=\"&srcpg=\"+b(google.sn)+\"&jsr=\"+b(u.jsr)+\"&bver=\"+b(u.bv);var f=a.lineNumber;void 0!==f&&(c+=\"&line=\"+f);var g=\\na.fileName;g&&(0<g.indexOf(\"-extension:/\")&&(e=3),c+=\"&script=\"+b(g),f&&g===window.location.href&&(f=document.documentElement.outerHTML.split(\"\\\\n\")[f],c+=\"&cad=\"+b(f?f.substring(0,300):\"No script found.\")));c+=\"&cad=ple_\"+google.ple+\".aple_\"+google.aple;google.ple&&1===google.ple&&(e=2);c+=\"&jsel=\"+e;for(var k in d)c+=\"&\",c+=b(k),c+=\"=\",c+=b(d[k]);c=c+\"&emsg=\"+b(a.name+\": \"+a.message);c=c+\"&jsst=\"+b(a.stack||\"N/A\");12288<=c.length&&(c=c.substr(0,12288));a=c;h||google.log(0,\"\",a);return a};window.onerror=function(a,b,d,h,e){if(t!==a){a=e instanceof Error?e:Error(a);void 0===d||\"lineNumber\"in a||(a.lineNumber=d);void 0===b||\"fileName\"in a||(a.fileName=b);b=void 0;if(a.stack&&(-1!==a.stack.indexOf(\"?xjs=s0\")||-1!==a.stack.indexOf(\"&xjs=s0\"))){b=document.querySelectorAll(\"script[src*=\\\\\\\\/xjs\\\\\\\\/_\\\\\\\\/js\\\\\\\\/]\");for(h=d=0;h<b.length;h++)d+=b[h].async?1:0;var c=e=h=-1,f=-1,g=-1;if(performance&&google.xjsu){h=0;e=google.timers.load.t.xjsee?1:0;f=c=0;g=performance.getEntriesByType(\"resource\");for(var k=\\n0;k<g.length;k++)-1!==g[k].name.indexOf(google.xjsu)&&(h=1),-1!==g[k].name.indexOf(\"/xjs/_/js/\")&&(c+=1,f+=\"script\"===g[k].initiatorType?1:0);g=c-f}b={cad:\"pl_\"+h+\".pe_\"+e+\".asc_\"+d+\".tsc_\"+b.length+\".fasc_\"+(b.length-d)+\".lxc_\"+c+\".lsx_\"+f+\".lnsx_\"+g}}google.ml(a,!1,b,!1,\"SyntaxError\"===a.name||\"SyntaxError\"===a.message.substring(0,11)||-1!==a.message.indexOf(\"Script error\")?3:0)}t=null;q&&r>=n&&(window.onerror=null)};})();</script></head><body bgcolor=\"#fff\"><script nonce=\"d1f-ilLsKF5YwBIKeB2CIw\">(function(){var src=\\'/images/nav_logo229.png\\';var iesg=false;document.body.onload = function(){window.n && window.n();if (document.images){new Image().src=src;}\\nif (!iesg){document.f&&document.f.q.focus();document.gbqf&&document.gbqf.q.focus();}\\n}\\n})();</script><div id=\"mngb\"><div id=gbar><nobr><b class=gb1>Search</b> <a class=gb1 href=\"https://www.google.com/imghp?hl=en&tab=wi\">Images</a> <a class=gb1 href=\"http://maps.google.com/maps?hl=en&tab=wl\">Maps</a> <a class=gb1 href=\"https://play.google.com/?hl=en&tab=w8\">Play</a> <a class=gb1 href=\"https://www.youtube.com/?tab=w1\">YouTube</a> <a class=gb1 href=\"https://news.google.com/?tab=wn\">News</a> <a class=gb1 href=\"https://mail.google.com/mail/?tab=wm\">Gmail</a> <a class=gb1 href=\"https://drive.google.com/?tab=wo\">Drive</a> <a class=gb1 style=\"text-decoration:none\" href=\"https://www.google.com/intl/en/about/products?tab=wh\"><u>More</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a href=\"http://www.google.com/history/optout?hl=en\" class=gb4>Web History</a> | <a  href=\"/preferences?hl=en\" class=gb4>Settings</a> | <a target=_top id=gb_70 href=\"https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=http://www.google.com/&ec=GAZAAQ\" class=gb4>Sign in</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div></div><center><br clear=\"all\" id=\"lgpd\"><div id=\"lga\"><img alt=\"Google\" height=\"92\" src=\"/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\" style=\"padding:28px 0 14px\" width=\"272\" id=\"hplogo\"><br><br></div><form action=\"/search\" name=\"f\"><table cellpadding=\"0\" cellspacing=\"0\"><tr valign=\"top\"><td width=\"25%\">&nbsp;</td><td align=\"center\" nowrap=\"\"><input name=\"ie\" value=\"ISO-8859-1\" type=\"hidden\"><input value=\"en\" name=\"hl\" type=\"hidden\"><input name=\"source\" type=\"hidden\" value=\"hp\"><input name=\"biw\" type=\"hidden\"><input name=\"bih\" type=\"hidden\"><div class=\"ds\" style=\"height:32px;margin:4px 0\"><input class=\"lst\" style=\"margin:0;padding:5px 8px 0 6px;vertical-align:top;color:#000\" autocomplete=\"off\" value=\"\" title=\"Google Search\" maxlength=\"2048\" name=\"q\" size=\"57\"></div><br style=\"line-height:0\"><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" value=\"Google Search\" name=\"btnG\" type=\"submit\"></span></span><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" id=\"tsuid_1\" value=\"I\\'m Feeling Lucky\" name=\"btnI\" type=\"submit\"><script nonce=\"d1f-ilLsKF5YwBIKeB2CIw\">(function(){var id=\\'tsuid_1\\';document.getElementById(id).onclick = function(){if (this.form.q.value){this.checked = 1;if (this.form.iflsig)this.form.iflsig.disabled = false;}\\nelse top.location=\\'/doodles/\\';};})();</script><input value=\"AD69kcEAAAAAZPyM1EZOtmLD__onoUfTsPURbyhGRmWB\" name=\"iflsig\" type=\"hidden\"></span></span></td><td class=\"fl sblc\" align=\"left\" nowrap=\"\" width=\"25%\"><a href=\"/advanced_search?hl=en&amp;authuser=0\">Advanced search</a></td></tr></table><input id=\"gbv\" name=\"gbv\" type=\"hidden\" value=\"1\"><script nonce=\"d1f-ilLsKF5YwBIKeB2CIw\">(function(){var a,b=\"1\";if(document&&document.getElementById)if(\"undefined\"!=typeof XMLHttpRequest)b=\"2\";else if(\"undefined\"!=typeof ActiveXObject){var c,d,e=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"];for(c=0;d=e[c++];)try{new ActiveXObject(d),b=\"2\"}catch(h){}}a=b;if(\"2\"==a&&-1==location.search.indexOf(\"&gbv=2\")){var f=google.gbvu,g=document.getElementById(\"gbv\");g&&(g.value=a);f&&window.setTimeout(function(){location.href=f},0)};}).call(this);</script></form><div id=\"gac_scont\"></div><div style=\"font-size:83%;min-height:3.5em\"><br></div><span id=\"footer\"><div style=\"font-size:10pt\"><div style=\"margin:19px auto;text-align:center\" id=\"WqQANb\"><a href=\"/intl/en/ads/\">Advertising</a><a href=\"/services/\">Business Solutions</a><a href=\"/intl/en/about.html\">About Google</a></div></div><p style=\"font-size:8pt;color:#70757a\">&copy; 2023 - <a href=\"/intl/en/policies/privacy/\">Privacy</a> - <a href=\"/intl/en/policies/terms/\">Terms</a></p></span></center><script nonce=\"d1f-ilLsKF5YwBIKeB2CIw\">(function(){window.google.cdo={height:757,width:1440};(function(){var a=window.innerWidth,b=window.innerHeight;if(!a||!b){var c=window.document,d=\"CSS1Compat\"==c.compatMode?c.documentElement:c.body;a=d.clientWidth;b=d.clientHeight}\\nif(a&&b&&(a!=google.cdo.width||b!=google.cdo.height)){var e=google,f=e.log,g=\"/client_204?&atyp=i&biw=\"+a+\"&bih=\"+b+\"&ei=\"+google.kEI,h=\"\",k=[],l=void 0!==window.google&&void 0!==window.google.kOPI&&0!==window.google.kOPI?window.google.kOPI:null;null!=l&&k.push([\"opi\",l.toString()]);for(var m=0;m<k.length;m++){if(0===m||0<m)h+=\"&\";h+=k[m][0]+\"=\"+k[m][1]}f.call(e,\"\",\"\",g+h)};}).call(this);})();</script> <script nonce=\"d1f-ilLsKF5YwBIKeB2CIw\">(function(){google.xjs={ck:\\'xjs.hp.vK-EJsoEmCo.L.X.O\\',cs:\\'ACT90oHOsJs2hLmBZgCMBoKojGOesyIM3Q\\',cssopt:false,csss:\\'ACT90oH2EyIDFeXzhL_udVKBGGuoj_HnEQ\\',excm:[],sepcss:false};})();</script>     <script nonce=\"d1f-ilLsKF5YwBIKeB2CIw\">(function(){var u=\\'/xjs/_/js/k\\\\x3dxjs.hp.en.93c7DJJQAvE.O/am\\\\x3dAAAAAAAAAAAAAAAgAAAAAAAIAAgIAAAAAAAASAAAOgIAwAIAXA/d\\\\x3d1/ed\\\\x3d1/rs\\\\x3dACT90oF_7auMT3W8sIE_W3CCv_D58vIKOg/m\\\\x3dsb_he,d,cEt90b,SNUn3,qddgKe,sTsDMc,dtl0hd,eHDfl\\';var amd=0;\\nvar e=this||self,f=function(a){return a};var g;var h=function(a){this.g=a};h.prototype.toString=function(){return this.g+\"\"};var k={};var l=function(){var a=document;var b=\"SCRIPT\";\"application/xhtml+xml\"===a.contentType&&(b=b.toLowerCase());return a.createElement(b)};\\nfunction m(a,b){a.src=b instanceof h&&b.constructor===h?b.g:\"type_error:TrustedResourceUrl\";var c,d;(c=(b=null==(d=(c=(a.ownerDocument&&a.ownerDocument.defaultView||window).document).querySelector)?void 0:d.call(c,\"script[nonce]\"))?b.nonce||b.getAttribute(\"nonce\")||\"\":\"\")&&a.setAttribute(\"nonce\",c)};function n(a){a=null===a?\"null\":void 0===a?\"undefined\":a;if(void 0===g){var b=null;var c=e.trustedTypes;if(c&&c.createPolicy){try{b=c.createPolicy(\"goog#html\",{createHTML:f,createScript:f,createScriptURL:f})}catch(d){e.console&&e.console.error(d.message)}g=b}else g=b}a=(b=g)?b.createScriptURL(a):a;return new h(a,k)};void 0===google.ps&&(google.ps=[]);function p(){var a=u,b=function(){};google.lx=google.stvsc?b:function(){q(a);google.lx=b};google.bx||google.lx()}function r(a,b){b&&m(a,n(b));var c=a.onload;a.onload=function(d){c&&c(d);google.ps=google.ps.filter(function(t){return a!==t})};google.ps.push(a);document.body.appendChild(a)}google.as=r;function q(a){google.timers&&google.timers.load&&google.tick&&google.tick(\"load\",\"xjsls\");var b=l();b.onerror=function(){google.ple=1};b.onload=function(){google.ple=0};google.xjsus=void 0;r(b,a);google.aple=-1;google.psa=!0};google.xjsu=u;e._F_jsUrl=u;setTimeout(function(){0<amd?google.caft(function(){return p()},amd):p()},0);})();window._ = window._ || {};window._DumpException = _._DumpException = function(e){throw e;};window._s = window._s || {};_s._DumpException = _._DumpException;window._qs = window._qs || {};_qs._DumpException = _._DumpException;(function(){window._F_toggles=[1,0,0,8,524289,8224,0,4608,570,24117259];})();function _F_installCss(c){}\\n(function(){google.jl={blt:\\'none\\',chnk:0,dw:false,dwu:true,emtn:0,end:0,ico:false,ikb:0,ine:false,injs:\\'none\\',injt:0,injth:0,injv2:false,lls:\\'default\\',pdt:0,rep:0,snet:true,strt:0,ubm:false,uwp:true};})();(function(){var pmc=\\'{\\\\x22d\\\\x22:{},\\\\x22sb_he\\\\x22:{\\\\x22agen\\\\x22:true,\\\\x22cgen\\\\x22:true,\\\\x22client\\\\x22:\\\\x22heirloom-hp\\\\x22,\\\\x22dh\\\\x22:true,\\\\x22ds\\\\x22:\\\\x22\\\\x22,\\\\x22fl\\\\x22:true,\\\\x22host\\\\x22:\\\\x22google.com\\\\x22,\\\\x22jsonp\\\\x22:true,\\\\x22msgs\\\\x22:{\\\\x22cibl\\\\x22:\\\\x22Clear Search\\\\x22,\\\\x22dym\\\\x22:\\\\x22Did you mean:\\\\x22,\\\\x22lcky\\\\x22:\\\\x22I\\\\\\\\u0026#39;m Feeling Lucky\\\\x22,\\\\x22lml\\\\x22:\\\\x22Learn more\\\\x22,\\\\x22psrc\\\\x22:\\\\x22This search was removed from your \\\\\\\\u003Ca href\\\\x3d\\\\\\\\\\\\x22/history\\\\\\\\\\\\x22\\\\\\\\u003EWeb History\\\\\\\\u003C/a\\\\\\\\u003E\\\\x22,\\\\x22psrl\\\\x22:\\\\x22Remove\\\\x22,\\\\x22sbit\\\\x22:\\\\x22Search by image\\\\x22,\\\\x22srch\\\\x22:\\\\x22Google Search\\\\x22},\\\\x22ovr\\\\x22:{},\\\\x22pq\\\\x22:\\\\x22\\\\x22,\\\\x22rfs\\\\x22:[],\\\\x22sbas\\\\x22:\\\\x220 3px 8px 0 rgba(0,0,0,0.2),0 0 0 1px rgba(0,0,0,0.08)\\\\x22,\\\\x22stok\\\\x22:\\\\x22byLlZ6CqP6JV6M1b3Z4jMroZeaM\\\\x22}}\\';google.pmc=JSON.parse(pmc);})();(function(){var b=function(a){var c=0;return function(){return c<a.length?{done:!1,value:a[c++]}:{done:!0}}};\\nvar e=this||self;var g,h;a:{for(var k=[\"CLOSURE_FLAGS\"],l=e,n=0;n<k.length;n++)if(l=l[k[n]],null==l){h=null;break a}h=l}var p=h&&h[610401301];g=null!=p?p:!1;var q,r=e.navigator;q=r?r.userAgentData||null:null;function t(a){return g?q?q.brands.some(function(c){return(c=c.brand)&&-1!=c.indexOf(a)}):!1:!1}function u(a){var c;a:{if(c=e.navigator)if(c=c.userAgent)break a;c=\"\"}return-1!=c.indexOf(a)};function v(){return g?!!q&&0<q.brands.length:!1}function w(){return u(\"Safari\")&&!(x()||(v()?0:u(\"Coast\"))||(v()?0:u(\"Opera\"))||(v()?0:u(\"Edge\"))||(v()?t(\"Microsoft Edge\"):u(\"Edg/\"))||(v()?t(\"Opera\"):u(\"OPR\"))||u(\"Firefox\")||u(\"FxiOS\")||u(\"Silk\")||u(\"Android\"))}function x(){return v()?t(\"Chromium\"):(u(\"Chrome\")||u(\"CriOS\"))&&!(v()?0:u(\"Edge\"))||u(\"Silk\")}function y(){return u(\"Android\")&&!(x()||u(\"Firefox\")||u(\"FxiOS\")||(v()?0:u(\"Opera\"))||u(\"Silk\"))};var z=v()?!1:u(\"Trident\")||u(\"MSIE\");y();x();w();var A=!z&&!w(),D=function(a){if(/-[a-z]/.test(\"ved\"))return null;if(A&&a.dataset){if(y()&&!(\"ved\"in a.dataset))return null;a=a.dataset.ved;return void 0===a?null:a}return a.getAttribute(\"data-\"+\"ved\".replace(/([A-Z])/g,\"-$1\").toLowerCase())};var E=[],F=null;function G(a){a=a.target;var c=performance.now(),f=[],H=f.concat,d=E;if(!(d instanceof Array)){var m=\"undefined\"!=typeof Symbol&&Symbol.iterator&&d[Symbol.iterator];if(m)d=m.call(d);else if(\"number\"==typeof d.length)d={next:b(d)};else throw Error(\"a`\"+String(d));for(var B=[];!(m=d.next()).done;)B.push(m.value);d=B}E=H.call(f,d,[c]);if(a&&a instanceof HTMLElement)if(a===F){if(c=4<=E.length)c=5>(E[E.length-1]-E[E.length-4])/1E3;if(c){c=google.getEI(a);a.hasAttribute(\"data-ved\")?f=a?D(a)||\"\":\"\":f=(f=\\na.closest(\"[data-ved]\"))?D(f)||\"\":\"\";f=f||\"\";if(a.hasAttribute(\"jsname\"))a=a.getAttribute(\"jsname\");else{var C;a=null==(C=a.closest(\"[jsname]\"))?void 0:C.getAttribute(\"jsname\")}google.log(\"rcm\",\"&ei=\"+c+\"&ved=\"+f+\"&jsname=\"+(a||\"\"))}}else F=a,E=[c]}window.document.addEventListener(\"DOMContentLoaded\",function(){document.body.addEventListener(\"click\",G)});}).call(this);</script></body></html>'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from urllib.request import urlopen\n",
        "\n",
        "url =\"http://www.google.com\"\n",
        "html = urlopen(url)  # html 파일 읽어올 수 있게 함\n",
        "html.read()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**requests**"
      ],
      "metadata": {
        "id": "zP9dH5No91bm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests"
      ],
      "metadata": {
        "id": "MlFHw2Gz8ncz"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"http://www.google.com\"\n",
        "r = requests.get(url)\n",
        "r.status_code # 상태코드"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuJn7QTt-jwH",
        "outputId": "1185d787-c10c-42e9-fa4a-32f96cf61c17"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Jklon-pzCNrk",
        "outputId": "830bcae0-841f-403b-9832-149527a04257"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<!doctype html><html itemscope=\"\" itemtype=\"http://schema.org/WebPage\" lang=\"en\"><head><meta content=\"Search the world\\'s information, including webpages, images, videos and more. Google has many special features to help you find exactly what you\\'re looking for.\" name=\"description\"><meta content=\"noodp\" name=\"robots\"><meta content=\"text/html; charset=UTF-8\" http-equiv=\"Content-Type\"><meta content=\"/images/branding/googleg/1x/googleg_standard_color_128dp.png\" itemprop=\"image\"><title>Google</title><script nonce=\"EOJ9DMVnI7SOkbo5sxgvjg\">(function(){var _g={kEI:\\'xH78ZKGnLqGlqtsPo9KOyA4\\',kEXPI:\\'0,793108,566301,6058,207,4804,2316,383,246,5,1129120,1197745,380745,16115,28684,22431,1361,12317,17582,4998,17075,41316,2891,3926,213,4210,3405,606,67087,8927,2025,1,16916,2652,4,32894,13063,13660,2980,1457,22583,6654,7596,1,42154,2,16395,342,3533,19491,5679,1020,31122,4568,6259,23418,1252,33064,2,2,1,6960,19672,8155,7381,2,3,15964,873,9626,10008,7,1922,9779,12415,30044,20199,20136,14,82,16514,3692,109,2412,5856,3785,4266,10909,280,298,3310,1515,3030,5630,481,5040,4665,1804,7734,15549,2549,576,6689,529,6895,6561,1633,8841,6147,8374,3338,1993,5922,12742,3,9,4129,1271,3592,5210030,109,2,196,46,218,5994601,2803123,3447,795,2,19733,2,300,46,8436,79,2,53,5,7,22,10,11,7,77,1,4,38,30,16,1,1,1,1,1,2,2,1,1,1,1,1,1,1,14,23941656,4044107,16672,39283,1621,1761,1397275,23759270,5175,2,2986,4636,8408,2880,442,1152,3554,1704,1023,3704,241,1692,274,4261,2052,1703,285,2396,2804,2448,1,1541,284,269,278,1,1,2,3,345,2877,486,1252,1549,1090,194,5,1899,688,3311,1036,778,65,361,10,2,19,3,1128,316,58,153,191,995,302,1533,2,6646,470,429,884,881,710,651,61,277,1373,380,619,1452,263,111,99,179,56,1,468,775,2,341,624,195,1910,148,26,1,2,261,176,909,5,722,192,998,1109,1189,114,1,89,305,4,9,619,619,231,1,990,13,266,335,1364,1,1114,561,90,743,195,878,496,349,1,707,4,9,199,1,662,830,259,222,1116,47,417,1180,607,2,265,188,441,336,1029,7,1,8,292,519,4\\',kBL:\\'AiMy\\',kOPI:89978449};(function(){var a;(null==(a=window.google)?0:a.stvsc)?google.kEI=_g.kEI:window.google=_g;}).call(this);})();(function(){google.sn=\\'webhp\\';google.kHL=\\'en\\';})();(function(){\\nvar h=this||self;function l(){return void 0!==window.google&&void 0!==window.google.kOPI&&0!==window.google.kOPI?window.google.kOPI:null};var m,n=[];function p(a){for(var b;a&&(!a.getAttribute||!(b=a.getAttribute(\"eid\")));)a=a.parentNode;return b||m}function q(a){for(var b=null;a&&(!a.getAttribute||!(b=a.getAttribute(\"leid\")));)a=a.parentNode;return b}function r(a){/^http:/i.test(a)&&\"https:\"===window.location.protocol&&(google.ml&&google.ml(Error(\"a\"),!1,{src:a,glmm:1}),a=\"\");return a}\\nfunction t(a,b,c,d,k){var e=\"\";-1===b.search(\"&ei=\")&&(e=\"&ei=\"+p(d),-1===b.search(\"&lei=\")&&(d=q(d))&&(e+=\"&lei=\"+d));d=\"\";var g=-1===b.search(\"&cshid=\")&&\"slh\"!==a,f=[];f.push([\"zx\",Date.now().toString()]);h._cshid&&g&&f.push([\"cshid\",h._cshid]);c=c();null!=c&&f.push([\"opi\",c.toString()]);for(c=0;c<f.length;c++){if(0===c||0<c)d+=\"&\";d+=f[c][0]+\"=\"+f[c][1]}return\"/\"+(k||\"gen_204\")+\"?atyp=i&ct=\"+String(a)+\"&cad=\"+(b+e+d)};m=google.kEI;google.getEI=p;google.getLEI=q;google.ml=function(){return null};google.log=function(a,b,c,d,k,e){e=void 0===e?l:e;c||(c=t(a,b,e,d,k));if(c=r(c)){a=new Image;var g=n.length;n[g]=a;a.onerror=a.onload=a.onabort=function(){delete n[g]};a.src=c}};google.logUrl=function(a,b){b=void 0===b?l:b;return t(\"\",a,b)};}).call(this);(function(){google.y={};google.sy=[];google.x=function(a,b){if(a)var c=a.id;else{do c=Math.random();while(google.y[c])}google.y[c]=[a,b];return!1};google.sx=function(a){google.sy.push(a)};google.lm=[];google.plm=function(a){google.lm.push.apply(google.lm,a)};google.lq=[];google.load=function(a,b,c){google.lq.push([[a],b,c])};google.loadAll=function(a,b){google.lq.push([a,b])};google.bx=!1;google.lx=function(){};var d=[];google.fce=function(a,b,c,e){d.push([a,b,c,e])};google.qce=d;}).call(this);google.f={};(function(){\\ndocument.documentElement.addEventListener(\"submit\",function(b){var a;if(a=b.target){var c=a.getAttribute(\"data-submitfalse\");a=\"1\"===c||\"q\"===c&&!a.elements.q.value?!0:!1}else a=!1;a&&(b.preventDefault(),b.stopPropagation())},!0);document.documentElement.addEventListener(\"click\",function(b){var a;a:{for(a=b.target;a&&a!==document.documentElement;a=a.parentElement)if(\"A\"===a.tagName){a=\"1\"===a.getAttribute(\"data-nohref\");break a}a=!1}a&&b.preventDefault()},!0);}).call(this);</script><style>#gbar,#guser{font-size:13px;padding-top:1px !important;}#gbar{height:22px}#guser{padding-bottom:7px !important;text-align:right}.gbh,.gbd{border-top:1px solid #c9d7f1;font-size:1px}.gbh{height:0;position:absolute;top:24px;width:100%}@media all{.gb1{height:22px;margin-right:.5em;vertical-align:top}#gbar{float:left}}a.gb1,a.gb4{text-decoration:underline !important}a.gb1,a.gb4{color:#00c !important}.gbi .gb4{color:#dd8e27 !important}.gbf .gb4{color:#900 !important}\\n</style><style>body,td,a,p,.h{font-family:arial,sans-serif}body{margin:0;overflow-y:scroll}#gog{padding:3px 8px 0}td{line-height:.8em}.gac_m td{line-height:17px}form{margin-bottom:20px}.h{color:#1967d2}em{font-weight:bold;font-style:normal}.lst{height:25px;width:496px}.gsfi,.lst{font:18px arial,sans-serif}.gsfs{font:17px arial,sans-serif}.ds{display:inline-box;display:inline-block;margin:3px 0 4px;margin-left:4px}input{font-family:inherit}body{background:#fff;color:#000}a{color:#681da8;text-decoration:none}a:hover,a:active{text-decoration:underline}.fl a{color:#1967d2}a:visited{color:#681da8}.sblc{padding-top:5px}.sblc a{display:block;margin:2px 0;margin-left:13px;font-size:11px}.lsbb{background:#f8f9fa;border:solid 1px;border-color:#dadce0 #70757a #70757a #dadce0;height:30px}.lsbb{display:block}#WqQANb a{display:inline-block;margin:0 12px}.lsb{background:url(/images/nav_logo229.png) 0 -261px repeat-x;color:#000;border:none;cursor:pointer;height:30px;margin:0;outline:0;font:15px arial,sans-serif;vertical-align:top}.lsb:active{background:#dadce0}.lst:focus{outline:none}</style><script nonce=\"EOJ9DMVnI7SOkbo5sxgvjg\">(function(){window.google.erd={jsr:1,bv:1864,de:true};\\nvar l=this||self;var m,n=null!=(m=l.mei)?m:1,p,q=null!=(p=l.sdo)?p:!0,r=0,t,u=google.erd,v=u.jsr;google.ml=function(a,b,d,h,e){e=void 0===e?2:e;b&&(t=a&&a.message);if(google.dl)return google.dl(a,e,d),null;if(0>v){window.console&&console.error(a,d);if(-2===v)throw a;b=!1}else b=!a||!a.message||\"Error loading script\"===a.message||r>=n&&!h?!1:!0;if(!b)return null;r++;d=d||{};b=encodeURIComponent;var c=\"/gen_204?atyp=i&ei=\"+b(google.kEI);google.kEXPI&&(c+=\"&jexpid=\"+b(google.kEXPI));c+=\"&srcpg=\"+b(google.sn)+\"&jsr=\"+b(u.jsr)+\"&bver=\"+b(u.bv);var f=a.lineNumber;void 0!==f&&(c+=\"&line=\"+f);var g=\\na.fileName;g&&(0<g.indexOf(\"-extension:/\")&&(e=3),c+=\"&script=\"+b(g),f&&g===window.location.href&&(f=document.documentElement.outerHTML.split(\"\\\\n\")[f],c+=\"&cad=\"+b(f?f.substring(0,300):\"No script found.\")));c+=\"&cad=ple_\"+google.ple+\".aple_\"+google.aple;google.ple&&1===google.ple&&(e=2);c+=\"&jsel=\"+e;for(var k in d)c+=\"&\",c+=b(k),c+=\"=\",c+=b(d[k]);c=c+\"&emsg=\"+b(a.name+\": \"+a.message);c=c+\"&jsst=\"+b(a.stack||\"N/A\");12288<=c.length&&(c=c.substr(0,12288));a=c;h||google.log(0,\"\",a);return a};window.onerror=function(a,b,d,h,e){if(t!==a){a=e instanceof Error?e:Error(a);void 0===d||\"lineNumber\"in a||(a.lineNumber=d);void 0===b||\"fileName\"in a||(a.fileName=b);b=void 0;if(a.stack&&(-1!==a.stack.indexOf(\"?xjs=s0\")||-1!==a.stack.indexOf(\"&xjs=s0\"))){b=document.querySelectorAll(\"script[src*=\\\\\\\\/xjs\\\\\\\\/_\\\\\\\\/js\\\\\\\\/]\");for(h=d=0;h<b.length;h++)d+=b[h].async?1:0;var c=e=h=-1,f=-1,g=-1;if(performance&&google.xjsu){h=0;e=google.timers.load.t.xjsee?1:0;f=c=0;g=performance.getEntriesByType(\"resource\");for(var k=\\n0;k<g.length;k++)-1!==g[k].name.indexOf(google.xjsu)&&(h=1),-1!==g[k].name.indexOf(\"/xjs/_/js/\")&&(c+=1,f+=\"script\"===g[k].initiatorType?1:0);g=c-f}b={cad:\"pl_\"+h+\".pe_\"+e+\".asc_\"+d+\".tsc_\"+b.length+\".fasc_\"+(b.length-d)+\".lxc_\"+c+\".lsx_\"+f+\".lnsx_\"+g}}google.ml(a,!1,b,!1,\"SyntaxError\"===a.name||\"SyntaxError\"===a.message.substring(0,11)||-1!==a.message.indexOf(\"Script error\")?3:0)}t=null;q&&r>=n&&(window.onerror=null)};})();</script></head><body bgcolor=\"#fff\"><script nonce=\"EOJ9DMVnI7SOkbo5sxgvjg\">(function(){var src=\\'/images/nav_logo229.png\\';var iesg=false;document.body.onload = function(){window.n && window.n();if (document.images){new Image().src=src;}\\nif (!iesg){document.f&&document.f.q.focus();document.gbqf&&document.gbqf.q.focus();}\\n}\\n})();</script><div id=\"mngb\"><div id=gbar><nobr><b class=gb1>Search</b> <a class=gb1 href=\"https://www.google.com/imghp?hl=en&tab=wi\">Images</a> <a class=gb1 href=\"http://maps.google.com/maps?hl=en&tab=wl\">Maps</a> <a class=gb1 href=\"https://play.google.com/?hl=en&tab=w8\">Play</a> <a class=gb1 href=\"https://www.youtube.com/?tab=w1\">YouTube</a> <a class=gb1 href=\"https://news.google.com/?tab=wn\">News</a> <a class=gb1 href=\"https://mail.google.com/mail/?tab=wm\">Gmail</a> <a class=gb1 href=\"https://drive.google.com/?tab=wo\">Drive</a> <a class=gb1 style=\"text-decoration:none\" href=\"https://www.google.com/intl/en/about/products?tab=wh\"><u>More</u> &raquo;</a></nobr></div><div id=guser width=100%><nobr><span id=gbn class=gbi></span><span id=gbf class=gbf></span><span id=gbe></span><a href=\"http://www.google.com/history/optout?hl=en\" class=gb4>Web History</a> | <a  href=\"/preferences?hl=en\" class=gb4>Settings</a> | <a target=_top id=gb_70 href=\"https://accounts.google.com/ServiceLogin?hl=en&passive=true&continue=http://www.google.com/&ec=GAZAAQ\" class=gb4>Sign in</a></nobr></div><div class=gbh style=left:0></div><div class=gbh style=right:0></div></div><center><br clear=\"all\" id=\"lgpd\"><div id=\"lga\"><img alt=\"Google\" height=\"92\" src=\"/images/branding/googlelogo/1x/googlelogo_white_background_color_272x92dp.png\" style=\"padding:28px 0 14px\" width=\"272\" id=\"hplogo\"><br><br></div><form action=\"/search\" name=\"f\"><table cellpadding=\"0\" cellspacing=\"0\"><tr valign=\"top\"><td width=\"25%\">&nbsp;</td><td align=\"center\" nowrap=\"\"><input name=\"ie\" value=\"ISO-8859-1\" type=\"hidden\"><input value=\"en\" name=\"hl\" type=\"hidden\"><input name=\"source\" type=\"hidden\" value=\"hp\"><input name=\"biw\" type=\"hidden\"><input name=\"bih\" type=\"hidden\"><div class=\"ds\" style=\"height:32px;margin:4px 0\"><input class=\"lst\" style=\"margin:0;padding:5px 8px 0 6px;vertical-align:top;color:#000\" autocomplete=\"off\" value=\"\" title=\"Google Search\" maxlength=\"2048\" name=\"q\" size=\"57\"></div><br style=\"line-height:0\"><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" value=\"Google Search\" name=\"btnG\" type=\"submit\"></span></span><span class=\"ds\"><span class=\"lsbb\"><input class=\"lsb\" id=\"tsuid_1\" value=\"I\\'m Feeling Lucky\" name=\"btnI\" type=\"submit\"><script nonce=\"EOJ9DMVnI7SOkbo5sxgvjg\">(function(){var id=\\'tsuid_1\\';document.getElementById(id).onclick = function(){if (this.form.q.value){this.checked = 1;if (this.form.iflsig)this.form.iflsig.disabled = false;}\\nelse top.location=\\'/doodles/\\';};})();</script><input value=\"AD69kcEAAAAAZPyM1CePwUcF6tGwlMsBchBcQI2trTp1\" name=\"iflsig\" type=\"hidden\"></span></span></td><td class=\"fl sblc\" align=\"left\" nowrap=\"\" width=\"25%\"><a href=\"/advanced_search?hl=en&amp;authuser=0\">Advanced search</a></td></tr></table><input id=\"gbv\" name=\"gbv\" type=\"hidden\" value=\"1\"><script nonce=\"EOJ9DMVnI7SOkbo5sxgvjg\">(function(){var a,b=\"1\";if(document&&document.getElementById)if(\"undefined\"!=typeof XMLHttpRequest)b=\"2\";else if(\"undefined\"!=typeof ActiveXObject){var c,d,e=[\"MSXML2.XMLHTTP.6.0\",\"MSXML2.XMLHTTP.3.0\",\"MSXML2.XMLHTTP\",\"Microsoft.XMLHTTP\"];for(c=0;d=e[c++];)try{new ActiveXObject(d),b=\"2\"}catch(h){}}a=b;if(\"2\"==a&&-1==location.search.indexOf(\"&gbv=2\")){var f=google.gbvu,g=document.getElementById(\"gbv\");g&&(g.value=a);f&&window.setTimeout(function(){location.href=f},0)};}).call(this);</script></form><div id=\"gac_scont\"></div><div style=\"font-size:83%;min-height:3.5em\"><br></div><span id=\"footer\"><div style=\"font-size:10pt\"><div style=\"margin:19px auto;text-align:center\" id=\"WqQANb\"><a href=\"/intl/en/ads/\">Advertising</a><a href=\"/services/\">Business Solutions</a><a href=\"/intl/en/about.html\">About Google</a></div></div><p style=\"font-size:8pt;color:#70757a\">&copy; 2023 - <a href=\"/intl/en/policies/privacy/\">Privacy</a> - <a href=\"/intl/en/policies/terms/\">Terms</a></p></span></center><script nonce=\"EOJ9DMVnI7SOkbo5sxgvjg\">(function(){window.google.cdo={height:757,width:1440};(function(){var a=window.innerWidth,b=window.innerHeight;if(!a||!b){var c=window.document,d=\"CSS1Compat\"==c.compatMode?c.documentElement:c.body;a=d.clientWidth;b=d.clientHeight}\\nif(a&&b&&(a!=google.cdo.width||b!=google.cdo.height)){var e=google,f=e.log,g=\"/client_204?&atyp=i&biw=\"+a+\"&bih=\"+b+\"&ei=\"+google.kEI,h=\"\",k=[],l=void 0!==window.google&&void 0!==window.google.kOPI&&0!==window.google.kOPI?window.google.kOPI:null;null!=l&&k.push([\"opi\",l.toString()]);for(var m=0;m<k.length;m++){if(0===m||0<m)h+=\"&\";h+=k[m][0]+\"=\"+k[m][1]}f.call(e,\"\",\"\",g+h)};}).call(this);})();</script> <script nonce=\"EOJ9DMVnI7SOkbo5sxgvjg\">(function(){google.xjs={ck:\\'xjs.hp.vK-EJsoEmCo.L.X.O\\',cs:\\'ACT90oHOsJs2hLmBZgCMBoKojGOesyIM3Q\\',cssopt:false,csss:\\'ACT90oH2EyIDFeXzhL_udVKBGGuoj_HnEQ\\',excm:[],sepcss:false};})();</script>     <script nonce=\"EOJ9DMVnI7SOkbo5sxgvjg\">(function(){var u=\\'/xjs/_/js/k\\\\x3dxjs.hp.en.93c7DJJQAvE.O/am\\\\x3dAAAAAAAAAAAAAAAgAAAAAAAIAAgIAAAAAAAASAAAOgIAwAIAXA/d\\\\x3d1/ed\\\\x3d1/rs\\\\x3dACT90oF_7auMT3W8sIE_W3CCv_D58vIKOg/m\\\\x3dsb_he,d,cEt90b,SNUn3,qddgKe,sTsDMc,dtl0hd,eHDfl\\';var amd=0;\\nvar e=this||self,f=function(a){return a};var g;var h=function(a){this.g=a};h.prototype.toString=function(){return this.g+\"\"};var k={};var l=function(){var a=document;var b=\"SCRIPT\";\"application/xhtml+xml\"===a.contentType&&(b=b.toLowerCase());return a.createElement(b)};\\nfunction m(a,b){a.src=b instanceof h&&b.constructor===h?b.g:\"type_error:TrustedResourceUrl\";var c,d;(c=(b=null==(d=(c=(a.ownerDocument&&a.ownerDocument.defaultView||window).document).querySelector)?void 0:d.call(c,\"script[nonce]\"))?b.nonce||b.getAttribute(\"nonce\")||\"\":\"\")&&a.setAttribute(\"nonce\",c)};function n(a){a=null===a?\"null\":void 0===a?\"undefined\":a;if(void 0===g){var b=null;var c=e.trustedTypes;if(c&&c.createPolicy){try{b=c.createPolicy(\"goog#html\",{createHTML:f,createScript:f,createScriptURL:f})}catch(d){e.console&&e.console.error(d.message)}g=b}else g=b}a=(b=g)?b.createScriptURL(a):a;return new h(a,k)};void 0===google.ps&&(google.ps=[]);function p(){var a=u,b=function(){};google.lx=google.stvsc?b:function(){q(a);google.lx=b};google.bx||google.lx()}function r(a,b){b&&m(a,n(b));var c=a.onload;a.onload=function(d){c&&c(d);google.ps=google.ps.filter(function(t){return a!==t})};google.ps.push(a);document.body.appendChild(a)}google.as=r;function q(a){google.timers&&google.timers.load&&google.tick&&google.tick(\"load\",\"xjsls\");var b=l();b.onerror=function(){google.ple=1};b.onload=function(){google.ple=0};google.xjsus=void 0;r(b,a);google.aple=-1;google.psa=!0};google.xjsu=u;e._F_jsUrl=u;setTimeout(function(){0<amd?google.caft(function(){return p()},amd):p()},0);})();window._ = window._ || {};window._DumpException = _._DumpException = function(e){throw e;};window._s = window._s || {};_s._DumpException = _._DumpException;window._qs = window._qs || {};_qs._DumpException = _._DumpException;(function(){window._F_toggles=[1,0,0,8,524289,8224,0,4608,570,24117259];})();function _F_installCss(c){}\\n(function(){google.jl={blt:\\'none\\',chnk:0,dw:false,dwu:true,emtn:0,end:0,ico:false,ikb:0,ine:false,injs:\\'none\\',injt:0,injth:0,injv2:false,lls:\\'default\\',pdt:0,rep:0,snet:true,strt:0,ubm:false,uwp:true};})();(function(){var pmc=\\'{\\\\x22d\\\\x22:{},\\\\x22sb_he\\\\x22:{\\\\x22agen\\\\x22:true,\\\\x22cgen\\\\x22:true,\\\\x22client\\\\x22:\\\\x22heirloom-hp\\\\x22,\\\\x22dh\\\\x22:true,\\\\x22ds\\\\x22:\\\\x22\\\\x22,\\\\x22fl\\\\x22:true,\\\\x22host\\\\x22:\\\\x22google.com\\\\x22,\\\\x22jsonp\\\\x22:true,\\\\x22msgs\\\\x22:{\\\\x22cibl\\\\x22:\\\\x22Clear Search\\\\x22,\\\\x22dym\\\\x22:\\\\x22Did you mean:\\\\x22,\\\\x22lcky\\\\x22:\\\\x22I\\\\\\\\u0026#39;m Feeling Lucky\\\\x22,\\\\x22lml\\\\x22:\\\\x22Learn more\\\\x22,\\\\x22psrc\\\\x22:\\\\x22This search was removed from your \\\\\\\\u003Ca href\\\\x3d\\\\\\\\\\\\x22/history\\\\\\\\\\\\x22\\\\\\\\u003EWeb History\\\\\\\\u003C/a\\\\\\\\u003E\\\\x22,\\\\x22psrl\\\\x22:\\\\x22Remove\\\\x22,\\\\x22sbit\\\\x22:\\\\x22Search by image\\\\x22,\\\\x22srch\\\\x22:\\\\x22Google Search\\\\x22},\\\\x22ovr\\\\x22:{},\\\\x22pq\\\\x22:\\\\x22\\\\x22,\\\\x22rfs\\\\x22:[],\\\\x22sbas\\\\x22:\\\\x220 3px 8px 0 rgba(0,0,0,0.2),0 0 0 1px rgba(0,0,0,0.08)\\\\x22,\\\\x22stok\\\\x22:\\\\x22xrCpPUM13Ta9m06hzmlxau4U10s\\\\x22}}\\';google.pmc=JSON.parse(pmc);})();(function(){var b=function(a){var c=0;return function(){return c<a.length?{done:!1,value:a[c++]}:{done:!0}}};\\nvar e=this||self;var g,h;a:{for(var k=[\"CLOSURE_FLAGS\"],l=e,n=0;n<k.length;n++)if(l=l[k[n]],null==l){h=null;break a}h=l}var p=h&&h[610401301];g=null!=p?p:!1;var q,r=e.navigator;q=r?r.userAgentData||null:null;function t(a){return g?q?q.brands.some(function(c){return(c=c.brand)&&-1!=c.indexOf(a)}):!1:!1}function u(a){var c;a:{if(c=e.navigator)if(c=c.userAgent)break a;c=\"\"}return-1!=c.indexOf(a)};function v(){return g?!!q&&0<q.brands.length:!1}function w(){return u(\"Safari\")&&!(x()||(v()?0:u(\"Coast\"))||(v()?0:u(\"Opera\"))||(v()?0:u(\"Edge\"))||(v()?t(\"Microsoft Edge\"):u(\"Edg/\"))||(v()?t(\"Opera\"):u(\"OPR\"))||u(\"Firefox\")||u(\"FxiOS\")||u(\"Silk\")||u(\"Android\"))}function x(){return v()?t(\"Chromium\"):(u(\"Chrome\")||u(\"CriOS\"))&&!(v()?0:u(\"Edge\"))||u(\"Silk\")}function y(){return u(\"Android\")&&!(x()||u(\"Firefox\")||u(\"FxiOS\")||(v()?0:u(\"Opera\"))||u(\"Silk\"))};var z=v()?!1:u(\"Trident\")||u(\"MSIE\");y();x();w();var A=!z&&!w(),D=function(a){if(/-[a-z]/.test(\"ved\"))return null;if(A&&a.dataset){if(y()&&!(\"ved\"in a.dataset))return null;a=a.dataset.ved;return void 0===a?null:a}return a.getAttribute(\"data-\"+\"ved\".replace(/([A-Z])/g,\"-$1\").toLowerCase())};var E=[],F=null;function G(a){a=a.target;var c=performance.now(),f=[],H=f.concat,d=E;if(!(d instanceof Array)){var m=\"undefined\"!=typeof Symbol&&Symbol.iterator&&d[Symbol.iterator];if(m)d=m.call(d);else if(\"number\"==typeof d.length)d={next:b(d)};else throw Error(\"a`\"+String(d));for(var B=[];!(m=d.next()).done;)B.push(m.value);d=B}E=H.call(f,d,[c]);if(a&&a instanceof HTMLElement)if(a===F){if(c=4<=E.length)c=5>(E[E.length-1]-E[E.length-4])/1E3;if(c){c=google.getEI(a);a.hasAttribute(\"data-ved\")?f=a?D(a)||\"\":\"\":f=(f=\\na.closest(\"[data-ved]\"))?D(f)||\"\":\"\";f=f||\"\";if(a.hasAttribute(\"jsname\"))a=a.getAttribute(\"jsname\");else{var C;a=null==(C=a.closest(\"[jsname]\"))?void 0:C.getAttribute(\"jsname\")}google.log(\"rcm\",\"&ei=\"+c+\"&ved=\"+f+\"&jsname=\"+(a||\"\"))}}else F=a,E=[c]}window.document.addEventListener(\"DOMContentLoaded\",function(){document.body.addEventListener(\"click\",G)});}).call(this);</script></body></html>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#requests.content  # 원본 데이터의 바이트 스크립 내려받기 (이미지 등)"
      ],
      "metadata": {
        "id": "7HfI4MYZCTFm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "url_image = 'https://www.google.com/images/branding/googlelogo/1x/googlelogo_color_272x92dp.png'\n",
        "r = requests.get(url_image)\n",
        "r.status_code"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gCRjKhnrC3yh",
        "outputId": "27fad296-aa2b-4f11-bec1-6f1cea7f2bde"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "200"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 바이트 스트림 반환\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "Image.open(BytesIO(r.content))  # 재구성하는 것"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 109
        },
        "id": "SXteAiCdDIig",
        "outputId": "66dbdb3b-c612-4b82-852a-5004dbcea2bf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=RGBA size=272x92>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install beautifulsoup4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NfZvhkvrDmr9",
        "outputId": "f79412f9-307e-445e-9c14-d20e9efa958b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (4.11.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4) (2.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from bs4 import BeautifulSoup"
      ],
      "metadata": {
        "id": "no03NsfHE9MA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filename = \"/content/[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving.html\"\n",
        "html = \"\"\n",
        "\n",
        "with open(filename, 'r', encoding='UTF-8') as file:\n",
        "  for line in file:\n",
        "    html += line\n",
        "\n",
        "html"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "DgzW1sWNFABE",
        "outputId": "cf506242-57c4-4418-82e8-681b2210fe39"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'<!doctype html>\\n<html><head><title data-rh=\"true\">[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving </title><link data-rh=\"true\" rel=\"canonical\" href=\"https://velog.io/@minkyu4506/논문리뷰-Multi-Modal-Fusion-Transformer-for-End-to-End-Autonomous-Driving\"/><meta data-rh=\"true\" property=\"fb:app_id\" content=\"203040656938507\"/><meta data-rh=\"true\" name=\"description\" content=\" 안녕하세요. 밍기뉴와제제입니다.\\n\\n정말 오랜만에 돌아왔습니다. 이번에 리뷰하는 논문은 &#x27;Multi-Modal Fusion Transformer for End-to-End Autonomous Driving&#x27;입니다.\\n\"/><meta data-rh=\"true\" property=\"og:url\" content=\"https://velog.io/@minkyu4506/논문리뷰-Multi-Modal-Fusion-Transformer-for-End-to-End-Autonomous-Driving\"/><meta data-rh=\"true\" property=\"og:type\" content=\"article\"/><meta data-rh=\"true\" property=\"og:title\" content=\"[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving \"/><meta data-rh=\"true\" property=\"og:description\" content=\" 안녕하세요. 밍기뉴와제제입니다.\\n\\n정말 오랜만에 돌아왔습니다. 이번에 리뷰하는 논문은 &#x27;Multi-Modal Fusion Transformer for End-to-End Autonomous Driving&#x27;입니다.\\n\"/><meta data-rh=\"true\" property=\"og:image\" content=\"https://velog.velcdn.com/images/minkyu4506/post/18537d03-8701-4bc7-90aa-f1cd4b26a51a/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.14.18.png\"/><meta data-rh=\"true\" name=\"twitter:card\" content=\"summary_large_image\"/><meta data-rh=\"true\" name=\"twitter:title\" content=\"[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving \"/><meta data-rh=\"true\" name=\"twitter:description\" content=\" 안녕하세요. 밍기뉴와제제입니다.\\n\\n정말 오랜만에 돌아왔습니다. 이번에 리뷰하는 논문은 &#x27;Multi-Modal Fusion Transformer for End-to-End Autonomous Driving&#x27;입니다.\\n\"/><meta data-rh=\"true\" name=\"twitter:image\" content=\"https://images.velog.io/images/minkyu4506/post/18537d03-8701-4bc7-90aa-f1cd4b26a51a/스크린샷 2021-08-06 오전 12.14.18.png\"/><style data-styled=\"\" data-styled-version=\"5.3.3\">.hSMJOX{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;font-weight:bold;cursor:pointer;outline:none;border:none;color:white;background:var(--primary1);color:var(--button-text);border-radius:4px;padding-top:0;padding-bottom:0;height:2rem;padding-left:1.25rem;padding-right:1.25rem;font-size:1rem;}/*!sc*/\\n.hSMJOX:hover,.hSMJOX:focus{background:var(--primary2);}/*!sc*/\\n.sc-jrQzAO + .sc-jrQzAO{margin-left:0.5rem;}/*!sc*/\\n.hSMJOX:disabled{cursor:not-allowed;background:var(--bg-element4);color:var(--text3);}/*!sc*/\\n.hSMJOX:disabled:hover{background:var(--bg-element4);color:var(--text3);}/*!sc*/\\ndata-styled.g11[id=\"sc-jrQzAO\"]{content:\"hSMJOX,\"}/*!sc*/\\nbody{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,\"Helvetica Neue\",\"Apple SD Gothic Neo\",\"Malgun Gothic\",\"맑은 고딕\",나눔고딕,\"Nanum Gothic\",\"Noto Sans KR\",\"Noto Sans CJK KR\",arial,돋움,Dotum,Tahoma,Geneva,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:var(--text1);box-sizing:border-box;}/*!sc*/\\n*{box-sizing:inherit;}/*!sc*/\\ncode{font-family:\\'Fira Mono\\',source-code-pro,Menlo,Monaco,Consolas,\\'Courier New\\', monospace;}/*!sc*/\\ninput,button,textarea{font-family:inherit;}/*!sc*/\\nhtml,body,#root{height:100%;}/*!sc*/\\nbody{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\\n@media (prefers-color-scheme:dark){body{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}}/*!sc*/\\nbody[data-theme=\\'light\\']{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\\nbody[data-theme=\\'dark\\']{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}/*!sc*/\\ndata-styled.g13[id=\"sc-global-gYCCRU1\"]{content:\"sc-global-gYCCRU1,\"}/*!sc*/\\n.gflbJg{height:2rem;padding-left:1rem;padding-right:1rem;font-size:1rem;border-radius:1rem;background:none;border:none;outline:none;font-weight:bold;word-break:keep-all;background:var(--bg-element5);color:var(--button-text);-webkit-transition:0.125s all ease-in;transition:0.125s all ease-in;cursor:pointer;}/*!sc*/\\n.gflbJg:hover{background:var(--bg-element6);}/*!sc*/\\n.gflbJg:focus{box-shadow:0px 2px 12px #00000030;}/*!sc*/\\n.gflbJg:disabled{background:var(--bg-element2);}/*!sc*/\\ndata-styled.g17[id=\"sc-egiyK\"]{content:\"gflbJg,\"}/*!sc*/\\n.evafIC{width:1728px;margin-left:auto;margin-right:auto;}/*!sc*/\\n@media (max-width:1919px){.evafIC{width:1376px;}}/*!sc*/\\n@media (max-width:1440px){.evafIC{width:1024px;}}/*!sc*/\\n@media (max-width:1056px){.evafIC{width:calc(100% - 2rem);}}/*!sc*/\\ndata-styled.g21[id=\"sc-fotOHu\"]{content:\"evafIC,\"}/*!sc*/\\n.cdniDY{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;font-weight:bold;color:var(--text1);font-size:1.3125rem;-webkit-text-decoration:none;text-decoration:none;font-family:Fira Mono,monospace;}/*!sc*/\\n@media (max-width:1024px){.cdniDY{font-size:1.125rem;}.cdniDY .velog-logo{height:1.25rem;}}/*!sc*/\\n.cdniDY a{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\\n.cdniDY .user-logo{display:block;max-width:calc(100vw - 200px);text-overflow:ellipsis;white-space:nowrap;overflow-x:hidden;overflow-y:hidden;}/*!sc*/\\ndata-styled.g26[id=\"sc-hGPBjI\"]{content:\"cdniDY,\"}/*!sc*/\\n.eleXpO{color:inherit;}/*!sc*/\\n.eleXpO svg{color:inherit;margin-right:1rem;width:1.75rem;height:1.75rem;display:block;}/*!sc*/\\n@media (max-width:1024px){.eleXpO svg{width:1.5rem;height:1.5rem;margin-right:0.75rem;}}/*!sc*/\\ndata-styled.g27[id=\"sc-dlVxhl\"]{content:\"eleXpO,\"}/*!sc*/\\n.hcjGyB{height:4rem;}/*!sc*/\\ndata-styled.g31[id=\"sc-iwjdpV\"]{content:\"hcjGyB,\"}/*!sc*/\\n.iIPjQP{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background:transparent;border:none;width:2.5rem;height:2.5rem;outline:none;border-radius:50%;color:var(--text1);cursor:pointer;margin-right:0.5rem;}/*!sc*/\\n.iIPjQP:hover{background:var(--slight-layer);}/*!sc*/\\n.iIPjQP svg{width:1.125rem;height:1.125rem;}/*!sc*/\\ndata-styled.g32[id=\"sc-cxpSdN\"]{content:\"iIPjQP,\"}/*!sc*/\\n.kYqaTx{height:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/\\ndata-styled.g33[id=\"sc-llYSUQ\"]{content:\"kYqaTx,\"}/*!sc*/\\n.cxmSXL{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;}/*!sc*/\\n@media (max-width:1024px){.cxmSXL .write-button{display:none;}}/*!sc*/\\ndata-styled.g34[id=\"sc-iJKOTD\"]{content:\"cxmSXL,\"}/*!sc*/\\n.iZAesw{position:fixed;top:0;background:var(--bg-element1);width:100%;z-index:10;box-shadow:0px 0 8px rgba(0,0,0,0.08);}/*!sc*/\\n.iZAesw .tab-wrapper{margin-top:-2rem;}/*!sc*/\\ndata-styled.g49[id=\"sc-efQSVx\"]{content:\"iZAesw,\"}/*!sc*/\\n.cMpExe{padding-bottom:4rem;}/*!sc*/\\ndata-styled.g52[id=\"sc-dPiLbb\"]{content:\"cMpExe,\"}/*!sc*/\\n.gihSnS{background:var(--bg-element4);-webkit-animation:gsdBxV 1s ease-in-out infinite;animation:gsdBxV 1s ease-in-out infinite;display:inline-block;border-radius:4px;height:1em;}/*!sc*/\\n.sc-gSQFLo + .sc-gSQFLo{margin-left:0.5rem;}/*!sc*/\\n.jbsFLX{background:var(--bg-element4);-webkit-animation:gsdBxV 1s ease-in-out infinite;animation:gsdBxV 1s ease-in-out infinite;display:inline-block;border-radius:4px;height:1em;}/*!sc*/\\ndata-styled.g59[id=\"sc-gSQFLo\"]{content:\"gihSnS,jbsFLX,\"}/*!sc*/\\nbody{background:var(--bg-page2);}/*!sc*/\\ndata-styled.g68[id=\"sc-global-iqNrnJ1\"]{content:\"sc-global-iqNrnJ1,\"}/*!sc*/\\n.ijHvhk{width:768px;margin-left:auto;margin-right:auto;}/*!sc*/\\n@media (max-width:768px){.ijHvhk{width:100%;}}/*!sc*/\\ndata-styled.g75[id=\"sc-dvQaRk\"]{content:\"ijHvhk,\"}/*!sc*/\\n@media (max-width:1024px){.ePkhDB{padding-left:1rem;padding-right:1rem;}}/*!sc*/\\ndata-styled.g76[id=\"sc-TBWPX\"]{content:\"ePkhDB,\"}/*!sc*/\\n.iQZhhJ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\\n@media (max-width:768px){.iQZhhJ{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}}/*!sc*/\\n.iQZhhJ img{display:block;width:8rem;height:8rem;border-radius:50%;object-fit:cover;box-shadow:0 0 4px 0 rgba(0,0,0,0.06);}/*!sc*/\\n@media (max-width:768px){.iQZhhJ img{width:5rem;height:5rem;}}/*!sc*/\\ndata-styled.g77[id=\"sc-jIkXHa\"]{content:\"iQZhhJ,\"}/*!sc*/\\n.eYREua{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-left:1rem;}/*!sc*/\\n.eYREua .name{font-size:1.5rem;line-height:1.5;font-weight:bold;color:var(--text1);}/*!sc*/\\n.eYREua .name a{color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\\n.eYREua .name a:hover{color:var(--text1);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\\n.eYREua .description{white-space:pre-wrap;font-size:1.125rem;line-height:1.5;margin-top:0.25rem;color:var(--text2);-webkit-letter-spacing:-0.004em;-moz-letter-spacing:-0.004em;-ms-letter-spacing:-0.004em;letter-spacing:-0.004em;}/*!sc*/\\n@media (max-width:768px){.eYREua{margin-left:0;margin-top:1rem;}.eYREua .name{font-size:1.125rem;}.eYREua .description{margin-top:0.5rem;font-size:0.875rem;-webkit-letter-spacing:-0.004em;-moz-letter-spacing:-0.004em;-ms-letter-spacing:-0.004em;letter-spacing:-0.004em;}}/*!sc*/\\ndata-styled.g78[id=\"sc-ZOtfp\"]{content:\"eYREua,\"}/*!sc*/\\n.fWmBKb{background:var(--bg-element3);width:100%;height:1px;margin-top:2rem;margin-bottom:1.5rem;}/*!sc*/\\n@media (max-width:768px){.fWmBKb{margin-top:1rem;margin-bottom:1rem;}}/*!sc*/\\ndata-styled.g79[id=\"sc-jOxtWs\"]{content:\"fWmBKb,\"}/*!sc*/\\n.fBgOP{color:var(--text3);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/\\n.fBgOP svg{cursor:pointer;width:2rem;height:2rem;}/*!sc*/\\n.fBgOP svg:hover{color:var(--text1);}/*!sc*/\\n@media (max-width:768px){.fBgOP svg{width:1.5rem;height:1.5rem;}}/*!sc*/\\n.fBgOP a{color:inherit;display:block;}/*!sc*/\\n.fBgOP a + a,.fBgOP a + svg{margin-left:1rem;}/*!sc*/\\ndata-styled.g80[id=\"sc-hmjpVf\"]{content:\"fBgOP,\"}/*!sc*/\\n.jhmYjy{margin-bottom:0.875rem;background:var(--bg-tag);padding-left:1rem;padding-right:1rem;height:2rem;border-radius:1rem;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-right:0.875rem;color:var(--primary1);-webkit-text-decoration:none;text-decoration:none;font-weight:500;font-size:1rem;}/*!sc*/\\n@media (max-width:768px){.jhmYjy{height:1.5rem;font-size:0.75rem;border-radius:0.75rem;padding-left:0.75rem;padding-right:0.75rem;margin-right:0.5rem;margin-bottom:0.5rem;}}/*!sc*/\\n.jhmYjy:hover{opacity:0.75;}/*!sc*/\\ndata-styled.g90[id=\"sc-fbyfCU\"]{content:\"jhmYjy,\"}/*!sc*/\\n.ehISJN{font-size:1.125rem;color:var(--text1);-webkit-transition:color 0.125s ease-in;transition:color 0.125s ease-in;line-height:1.7;-webkit-letter-spacing:-0.004em;-moz-letter-spacing:-0.004em;-ms-letter-spacing:-0.004em;letter-spacing:-0.004em;word-break:keep-all;word-wrap:break-word;}/*!sc*/\\n.ehISJN ul b,.ehISJN ol b,.ehISJN p b{font-weight:400;}/*!sc*/\\n.ehISJN ul code,.ehISJN ol code,.ehISJN p code{background:var(--bg-inline-code);padding:0.2em 0.4em;font-size:85%;border-radius:3px;}/*!sc*/\\n.ehISJN ul a code,.ehISJN ol a code,.ehISJN p a code{color:var(--primary1);}/*!sc*/\\n.ehISJN a{color:var(--primary1);-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\\n.ehISJN a:hover{color:var(--primary1);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\\n.ehISJN code{font-family:\\'Fira Mono\\',source-code-pro,Menlo,Monaco,Consolas, \\'Courier New\\',monospace;}/*!sc*/\\n.ehISJN hr{border:none;height:1px;width:100%;background:var(--border3);margin-top:2rem;margin-bottom:2rem;}/*!sc*/\\n.ehISJN p img{display:block;margin:0 auto;max-width:100%;margin-top:3rem;margin-bottom:3rem;}/*!sc*/\\n.ehISJN h1{font-size:2.5rem;}/*!sc*/\\n.ehISJN h2{font-size:2rem;}/*!sc*/\\n.ehISJN h3{font-size:1.5rem;}/*!sc*/\\n.ehISJN h4{font-size:1.125rem;}/*!sc*/\\n.ehISJN h1,.ehISJN h2,.ehISJN h3,.ehISJN h4{line-height:1.5;margin-bottom:1rem;}/*!sc*/\\n.ehISJN p + h1,.ehISJN p + h2,.ehISJN p + h3,.ehISJN p + h4{margin-top:2.5rem;}/*!sc*/\\n@media (max-width:768px){.ehISJN{font-size:1rem;}.ehISJN h1{font-size:2.25rem;}.ehISJN h2{font-size:1.75rem;}.ehISJN h3{font-size:1.25rem;}.ehISJN h4{font-size:1rem;}.ehISJN h1,.ehISJN h2,.ehISJN h3,.ehISJN h4{margin-bottom:0.75rem;}.ehISJN p + h1,.ehISJN p + h2,.ehISJN p + h3,.ehISJN p + h4{margin-top:2rem;}}/*!sc*/\\n.ehISJN blockquote{margin-top:2rem;margin-bottom:2rem;border-left:4px solid var(--primary2);border-top-right-radius:4px;border-bottom-right-radius:4px;background:var(--bg-element2);margin-left:0;margin-right:0;padding:1rem;padding-left:2rem;color:var(--text1);}/*!sc*/\\n.ehISJN blockquote ul,.ehISJN blockquote ol{padding-left:1rem;}/*!sc*/\\n.ehISJN blockquote *:first-child{margin-top:0;}/*!sc*/\\n.ehISJN blockquote *:last-child{margin-bottom:0;}/*!sc*/\\ndata-styled.g113[id=\"sc-bQtKYq\"]{content:\"ehISJN,\"}/*!sc*/\\n.jlUmJL.atom-one pre{background:var(--prism-bg);}/*!sc*/\\n.jlUmJL.atom-one code[class*=\\'language-\\'],.jlUmJL.atom-one pre[class*=\\'language-\\']{color:var(--prism-default-text);background:none;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}/*!sc*/\\n.jlUmJL.atom-one pre[class*=\\'language-\\']::-moz-selection,.jlUmJL.atom-one pre[class*=\\'language-\\'] ::-moz-selection,.jlUmJL.atom-one code[class*=\\'language-\\']::-moz-selection,.jlUmJL.atom-one code[class*=\\'language-\\'] ::-moz-selection{text-shadow:none;background:var(--prism-selection-bg);}/*!sc*/\\n.jlUmJL.atom-one pre[class*=\\'language-\\']::selection,.jlUmJL.atom-one pre[class*=\\'language-\\'] ::selection,.jlUmJL.atom-one code[class*=\\'language-\\']::selection,.jlUmJL.atom-one code[class*=\\'language-\\'] ::selection{text-shadow:none;background:var(--prism-selection-bg);}/*!sc*/\\n@media print{.jlUmJL.atom-one code[class*=\\'language-\\'],.jlUmJL.atom-one pre[class*=\\'language-\\']{text-shadow:none;}}/*!sc*/\\n.jlUmJL.atom-one pre[class*=\\'language-\\']{padding:1em;margin:0.5em 0;overflow:auto;}/*!sc*/\\n.jlUmJL.atom-one:not(pre) > code[class*=\\'language-\\'],.jlUmJL.atom-one pre[class*=\\'language-\\']{background:var(--prism-code-block-bg);}/*!sc*/\\n.jlUmJL.atom-one:not(pre) > code[class*=\\'language-\\']{padding:0.1em;border-radius:0.3em;white-space:normal;}/*!sc*/\\n.jlUmJL.atom-one .token.comment,.jlUmJL.atom-one .token.prolog,.jlUmJL.atom-one .token.doctype,.jlUmJL.atom-one .token.cdata{color:var(--prism-code-1);}/*!sc*/\\n.jlUmJL.atom-one .token.punctuation{color:var(--prism-code-2);}/*!sc*/\\n.jlUmJL.atom-one .token.selector,.jlUmJL.atom-one .token.tag{color:var(--prism-code-3);}/*!sc*/\\n.jlUmJL.atom-one .token.property,.jlUmJL.atom-one .token.boolean,.jlUmJL.atom-one .token.number,.jlUmJL.atom-one .token.constant,.jlUmJL.atom-one .token.symbol,.jlUmJL.atom-one .token.attr-name,.jlUmJL.atom-one .token.deleted{color:var(--prism-code-4);}/*!sc*/\\n.jlUmJL.atom-one .token.string,.jlUmJL.atom-one .token.char,.jlUmJL.atom-one .token.attr-value,.jlUmJL.atom-one .token.builtin,.jlUmJL.atom-one .token.inserted{color:var(--prism-code-6);}/*!sc*/\\n.jlUmJL.atom-one .token.operator,.jlUmJL.atom-one .token.entity,.jlUmJL.atom-one .token.url,.jlUmJL.atom-one .language-css .token.string,.jlUmJL.atom-one .style .token.string{color:var(--prism-code-5);}/*!sc*/\\n.jlUmJL.atom-one .token.atrule,.jlUmJL.atom-one .token.keyword{color:var(--prism-code-7);}/*!sc*/\\n.jlUmJL.atom-one .token.function{color:var(--prism-code-8);}/*!sc*/\\n.jlUmJL.atom-one .token.regex,.jlUmJL.atom-one .token.important,.jlUmJL.atom-one .token.variable{color:var(--prism-code-9);}/*!sc*/\\n.jlUmJL.atom-one .token.important,.jlUmJL.atom-one .token.bold{font-weight:bold;}/*!sc*/\\n.jlUmJL.atom-one .token.italic{font-style:italic;}/*!sc*/\\n.jlUmJL.atom-one .token.entity{cursor:help;}/*!sc*/\\n.jlUmJL.atom-one pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber;}/*!sc*/\\n.jlUmJL.atom-one pre.line-numbers > code{position:relative;}/*!sc*/\\n.jlUmJL.atom-one .line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:0;font-size:100%;left:-3.8em;width:3em;-webkit-letter-spacing:-1px;-moz-letter-spacing:-1px;-ms-letter-spacing:-1px;letter-spacing:-1px;border-right:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}/*!sc*/\\n.jlUmJL.atom-one .line-numbers-rows > span{pointer-events:none;display:block;counter-increment:linenumber;}/*!sc*/\\n.jlUmJL.atom-one .line-numbers-rows > span:before{content:counter(linenumber);color:var(--prism-line-number);display:block;padding-right:0.8em;text-align:right;}/*!sc*/\\n.jlUmJL.github code,.jlUmJL.github code[class*=\\'language-\\'],.jlUmJL.github pre[class*=\\'language-\\']{color:#24292e;}/*!sc*/\\n.jlUmJL.github pre{color:#24292e;background:#f6f8fa;}/*!sc*/\\n.jlUmJL.github .token.function{color:#005cc5;}/*!sc*/\\n.jlUmJL.github .token.comment,.jlUmJL.github .token.prolog,.jlUmJL.github .token.doctype,.jlUmJL.github .token.cdata{color:#969896;}/*!sc*/\\n.jlUmJL.github .token.punctuation{color:#24292e;}/*!sc*/\\n.jlUmJL.github .token.string{color:#032f62;}/*!sc*/\\n.jlUmJL.github .token.atrule,.jlUmJL.github .token.attr-value{color:#183691;}/*!sc*/\\n.jlUmJL.github .token.property,.jlUmJL.github .token.tag{color:#63a35c;}/*!sc*/\\n.jlUmJL.github .token.boolean,.jlUmJL.github .token.number{color:#0086b3;}/*!sc*/\\n.jlUmJL.github .token.selector,.jlUmJL.github .token.attr-name,.jlUmJL.github .token.attr-value .punctuation:first-child,.jlUmJL.github .token.keyword,.jlUmJL.github .token.regex,.jlUmJL.github .token.important{color:#d73a49;}/*!sc*/\\n.jlUmJL.github .token.operator,.jlUmJL.github .token.entity,.jlUmJL.github .token.url,.jlUmJL.github .language-css{color:#d73a49;}/*!sc*/\\n.jlUmJL.github .token.entity{cursor:help;}/*!sc*/\\n.jlUmJL.github .namespace{opacity:0.7;}/*!sc*/\\n.jlUmJL.monokai code[class*=\\'language-\\'],.jlUmJL.monokai pre[class*=\\'language-\\']{color:#f8f8f2;text-shadow:0 1px rgba(0,0,0,0.3);}/*!sc*/\\n.jlUmJL.monokai:not(pre) > code[class*=\\'language-\\'],.jlUmJL.monokai pre[class*=\\'language-\\']{background:#272822;}/*!sc*/\\n.jlUmJL.monokai pre{color:#f8f8f2;text-shadow:0 1px rgba(0,0,0,0.3);background:#272822;}/*!sc*/\\n.jlUmJL.monokai .token.comment,.jlUmJL.monokai .token.prolog,.jlUmJL.monokai .token.doctype,.jlUmJL.monokai .token.cdata{color:#778090;}/*!sc*/\\n.jlUmJL.monokai .token.punctuation{color:#f8f8f2;}/*!sc*/\\n.jlUmJL.monokai .namespace{opacity:0.7;}/*!sc*/\\n.jlUmJL.monokai .token.property,.jlUmJL.monokai .token.tag,.jlUmJL.monokai .token.constant,.jlUmJL.monokai .token.symbol,.jlUmJL.monokai .token.deleted{color:#f92672;}/*!sc*/\\n.jlUmJL.monokai .token.boolean,.jlUmJL.monokai .token.number{color:#ae81ff;}/*!sc*/\\n.jlUmJL.monokai .token.selector,.jlUmJL.monokai .token.attr-name,.jlUmJL.monokai .token.string,.jlUmJL.monokai .token.char,.jlUmJL.monokai .token.builtin,.jlUmJL.monokai .token.inserted{color:#a6e22e;}/*!sc*/\\n.jlUmJL.monokai .token.operator,.jlUmJL.monokai .token.entity,.jlUmJL.monokai .token.url,.jlUmJL.monokai .language-css .token.string,.jlUmJL.monokai .style .token.string,.jlUmJL.monokai .token.variable{color:#f8f8f2;}/*!sc*/\\n.jlUmJL.monokai .token.atrule,.jlUmJL.monokai .token.attr-value,.jlUmJL.monokai .token.function{color:#e6db74;}/*!sc*/\\n.jlUmJL.monokai .token.keyword{color:#f92672;}/*!sc*/\\n.jlUmJL.monokai .token.regex,.jlUmJL.monokai .token.important{color:#fd971f;}/*!sc*/\\n.jlUmJL.monokai .token.important,.jlUmJL.monokai .token.bold{font-weight:bold;}/*!sc*/\\n.jlUmJL.monokai .token.italic{font-style:italic;}/*!sc*/\\n.jlUmJL.monokai .token.entity{cursor:help;}/*!sc*/\\n.jlUmJL.dracula code[class*=\\'language-\\'],.jlUmJL.dracula pre[class*=\\'language-\\']{color:#ccc;background:rgb(40,41,54);}/*!sc*/\\n.jlUmJL.dracula pre[class*=\\'language-\\']::-moz-selection,.jlUmJL.dracula pre[class*=\\'language-\\'] ::-moz-selection,.jlUmJL.dracula code[class*=\\'language-\\']::-moz-selection,.jlUmJL.dracula code[class*=\\'language-\\'] ::-moz-selection{text-shadow:none;background-color:#5a5f80;}/*!sc*/\\n.jlUmJL.dracula pre[class*=\\'language-\\']::selection,.jlUmJL.dracula pre[class*=\\'language-\\'] ::selection,.jlUmJL.dracula code[class*=\\'language-\\']::selection,.jlUmJL.dracula code[class*=\\'language-\\'] ::selection{text-shadow:none;background-color:#5a5f80;}/*!sc*/\\n.jlUmJL.dracula:not(pre) > code[class*=\\'language-\\']{border-radius:0.3em;white-space:normal;}/*!sc*/\\n.jlUmJL.dracula pre{color:#ccc;background:rgb(40,41,54);}/*!sc*/\\n.jlUmJL.dracula .limit-300{height:300px !important;}/*!sc*/\\n.jlUmJL.dracula .limit-400{height:400px !important;}/*!sc*/\\n.jlUmJL.dracula .limit-500{height:500px !important;}/*!sc*/\\n.jlUmJL.dracula .limit-600{height:600px !important;}/*!sc*/\\n.jlUmJL.dracula .limit-700{height:700px !important;}/*!sc*/\\n.jlUmJL.dracula .limit-800{height:800px !important;}/*!sc*/\\n.jlUmJL.dracula .token.comment{color:rgba(98,114,164,1);}/*!sc*/\\n.jlUmJL.dracula .token.prolog{color:rgba(207,207,194,1);}/*!sc*/\\n.jlUmJL.dracula .token.tag{color:rgba(220,104,170,1);}/*!sc*/\\n.jlUmJL.dracula .token.entity{color:rgba(139,233,253,1);}/*!sc*/\\n.jlUmJL.dracula .token.atrule{color:rgba(98,239,117,1);}/*!sc*/\\n.jlUmJL.dracula .token.url{color:rgba(102,217,239,1);}/*!sc*/\\n.jlUmJL.dracula .token.selector{color:rgba(207,207,194,1);}/*!sc*/\\n.jlUmJL.dracula .token.string{color:rgba(241,250,140,1);}/*!sc*/\\n.jlUmJL.dracula .token.property{color:rgba(255,184,108,1);}/*!sc*/\\n.jlUmJL.dracula .token.important{color:rgba(255,121,198,1);font-weight:bold;}/*!sc*/\\n.jlUmJL.dracula .token.punctuation{color:rgba(230,219,116,1);}/*!sc*/\\n.jlUmJL.dracula .token.number{color:rgba(189,147,249,1);}/*!sc*/\\n.jlUmJL.dracula .token.function{color:rgba(80,250,123,1);}/*!sc*/\\n.jlUmJL.dracula .token.class-name{color:rgba(255,184,108,1);}/*!sc*/\\n.jlUmJL.dracula .token.keyword{color:rgba(255,121,198,1);}/*!sc*/\\n.jlUmJL.dracula .token.boolean{color:rgba(255,184,108,1);}/*!sc*/\\n.jlUmJL.dracula .token.operator{color:rgba(139,233,253,1);}/*!sc*/\\n.jlUmJL.dracula .token.char{color:rgba(255,135,157,1);}/*!sc*/\\n.jlUmJL.dracula .token.regex{color:rgba(80,250,123,1);}/*!sc*/\\n.jlUmJL.dracula .token.variable{color:rgba(80,250,123,1);}/*!sc*/\\n.jlUmJL.dracula .token.constant{color:rgba(255,184,108,1);}/*!sc*/\\n.jlUmJL.dracula .token.symbol{color:rgba(255,184,108,1);}/*!sc*/\\n.jlUmJL.dracula .token.builtin{color:rgba(255,121,198,1);}/*!sc*/\\n.jlUmJL.dracula .token.attr-value{color:#7ec699;}/*!sc*/\\n.jlUmJL.dracula .token.deleted{color:#e2777a;}/*!sc*/\\n.jlUmJL.dracula .token.namespace{color:#e2777a;}/*!sc*/\\n.jlUmJL.dracula .token.bold{font-weight:bold;}/*!sc*/\\n.jlUmJL.dracula .token.italic{font-style:italic;}/*!sc*/\\n.jlUmJL.dracula .token{color:#ff79c6;}/*!sc*/\\n.jlUmJL.dracula .langague-cpp .token.string{color:#8be9fd;}/*!sc*/\\n.jlUmJL.dracula .langague-c .token.string{color:#8be9fd;}/*!sc*/\\n.jlUmJL.dracula .language-css .token.selector{color:rgba(80,250,123,1);}/*!sc*/\\n.jlUmJL.dracula .language-css .token.property{color:rgba(255,184,108,1);}/*!sc*/\\n.jlUmJL.dracula .language-java span.token.class-name{color:#8be9fd;}/*!sc*/\\n.jlUmJL.dracula .language-java .token.class-name{color:#8be9fd;}/*!sc*/\\n.jlUmJL.dracula .language-markup .token.attr-value{color:rgba(102,217,239,1);}/*!sc*/\\n.jlUmJL.dracula .language-markup .token.tag{color:rgba(80,250,123,1);}/*!sc*/\\n.jlUmJL.dracula .language-objectivec .token.property{color:#66d9ef;}/*!sc*/\\n.jlUmJL.dracula .language-objectivec .token.string{color:#50fa7b;}/*!sc*/\\n.jlUmJL.dracula .language-php .token.boolean{color:#8be9fd;}/*!sc*/\\n.jlUmJL.dracula .language-php .token.function{color:#ff79c6;}/*!sc*/\\n.jlUmJL.dracula .language-php .token.keyword{color:#66d9ef;}/*!sc*/\\n.jlUmJL.dracula .language-ruby .token.symbol{color:#8be9fd;}/*!sc*/\\n.jlUmJL.dracula .language-ruby .token.class-name{color:#cfcfc2;}/*!sc*/\\n.jlUmJL.dracula pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber;}/*!sc*/\\n.jlUmJL.dracula pre.line-numbers > code{position:relative;white-space:inherit;}/*!sc*/\\n.jlUmJL.dracula .line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:0;font-size:100%;left:-3.8em;width:3em;-webkit-letter-spacing:-1px;-moz-letter-spacing:-1px;-ms-letter-spacing:-1px;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}/*!sc*/\\n.jlUmJL.dracula .line-numbers-rows > span{pointer-events:none;display:block;counter-increment:linenumber;}/*!sc*/\\n.jlUmJL.dracula .line-numbers-rows > span:before{content:counter(linenumber);color:#999;display:block;padding-right:0.8em;text-align:right;}/*!sc*/\\n.jlUmJL.dracula div.code-toolbar{position:relative;}/*!sc*/\\n.jlUmJL.dracula div.code-toolbar > .toolbar{position:absolute;top:0.3em;right:0.2em;-webkit-transition:opacity 0.3s ease-in-out;transition:opacity 0.3s ease-in-out;opacity:0;}/*!sc*/\\n.jlUmJL.dracula div.code-toolbar:hover > .toolbar{opacity:1;}/*!sc*/\\n.jlUmJL.dracula div.code-toolbar > .toolbar .toolbar-item{display:inline-block;padding-right:20px;}/*!sc*/\\n.jlUmJL.dracula div.code-toolbar > .toolbar a{cursor:pointer;}/*!sc*/\\n.jlUmJL.dracula div.code-toolbar > .toolbar button{background:none;border:0;color:inherit;font:inherit;line-height:normal;overflow:visible;padding:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;}/*!sc*/\\n.jlUmJL.dracula div.code-toolbar > .toolbar a,.jlUmJL.dracula div.code-toolbar > .toolbar button,.jlUmJL.dracula div.code-toolbar > .toolbar span{color:#ccc;font-size:0.8em;padding:0.5em;background:rgba(98,114,164,1);border-radius:0.5em;}/*!sc*/\\n.jlUmJL.dracula div.code-toolbar > .toolbar a:hover,.jlUmJL.dracula div.code-toolbar > .toolbar a:focus,.jlUmJL.dracula div.code-toolbar > .toolbar button:hover,.jlUmJL.dracula div.code-toolbar > .toolbar button:focus,.jlUmJL.dracula div.code-toolbar > .toolbar span:hover,.jlUmJL.dracula div.code-toolbar > .toolbar span:focus{color:inherit;-webkit-text-decoration:none;text-decoration:none;background-color:var(--verde);}/*!sc*/\\n.jlUmJL pre{font-family:\\'Fira Mono\\',source-code-pro,Menlo,Monaco,Consolas, \\'Courier New\\',monospace;font-size:0.875rem;padding:1rem;border-radius:4px;line-height:1.5;overflow-x:auto;-webkit-letter-spacing:0px;-moz-letter-spacing:0px;-ms-letter-spacing:0px;letter-spacing:0px;}/*!sc*/\\n@media (max-width:768px){.jlUmJL pre{font-size:0.75rem;padding:0.75rem;}}/*!sc*/\\n.jlUmJL img{max-width:100%;height:auto;display:block;margin-top:1.5rem;margin-bottom:1.5rem;}/*!sc*/\\n.jlUmJL iframe{width:768px;height:430px;max-width:100%;background:black;display:block;margin:auto;border:none;border-radius:4px;overflow:hidden;}/*!sc*/\\n.jlUmJL .twitter-wrapper{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-left:none;background:none;padding:none;}/*!sc*/\\n.jlUmJL table{min-width:40%;max-width:100%;border:1px solid var(--border2);border-collapse:collapse;font-size:0.875rem;}/*!sc*/\\n.jlUmJL table thead > tr > th{border-bottom:4px solid var(--border2);}/*!sc*/\\n.jlUmJL table th,.jlUmJL table td{word-break:break-word;padding:0.5rem;}/*!sc*/\\n.jlUmJL table td + td,.jlUmJL table th + th{border-left:1px solid var(--border2);}/*!sc*/\\n.jlUmJL table tr:nth-child(even){background:var(--bg-element2);}/*!sc*/\\n.jlUmJL table tr:nth-child(odd){background:var(--bg-page1);}/*!sc*/\\n.jlUmJL .katex-mathml{display:none;}/*!sc*/\\ndata-styled.g114[id=\"sc-fXEqDS\"]{content:\"jlUmJL,\"}/*!sc*/\\n@-webkit-keyframes gsdBxV{0%{opacity:0.5;}50%{opacity:1;}100%{opacity:0.5;}}/*!sc*/\\n@keyframes gsdBxV{0%{opacity:0.5;}50%{opacity:1;}100%{opacity:0.5;}}/*!sc*/\\ndata-styled.g124[id=\"sc-keyframes-gsdBxV\"]{content:\"gsdBxV,\"}/*!sc*/\\nbody{background:var(--bg-page2);}/*!sc*/\\ndata-styled.g149[id=\"sc-global-iqNrnJ2\"]{content:\"sc-global-iqNrnJ2,\"}/*!sc*/\\nbody{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,\"Helvetica Neue\",\"Apple SD Gothic Neo\",\"Malgun Gothic\",\"맑은 고딕\",나눔고딕,\"Nanum Gothic\",\"Noto Sans KR\",\"Noto Sans CJK KR\",arial,돋움,Dotum,Tahoma,Geneva,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:var(--text1);box-sizing:border-box;}/*!sc*/\\n*{box-sizing:inherit;}/*!sc*/\\ncode{font-family:\\'Fira Mono\\',source-code-pro,Menlo,Monaco,Consolas,\\'Courier New\\', monospace;}/*!sc*/\\ninput,button,textarea{font-family:inherit;}/*!sc*/\\nhtml,body,#root{height:100%;}/*!sc*/\\nbody{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\\n@media (prefers-color-scheme:dark){body{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}}/*!sc*/\\nbody[data-theme=\\'light\\']{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\\nbody[data-theme=\\'dark\\']{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}/*!sc*/\\ndata-styled.g150[id=\"sc-global-gYCCRU2\"]{content:\"sc-global-gYCCRU2,\"}/*!sc*/\\nbody{background:var(--bg-page2);}/*!sc*/\\ndata-styled.g151[id=\"sc-global-iqNrnJ3\"]{content:\"sc-global-iqNrnJ3,\"}/*!sc*/\\nbody{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,\"Helvetica Neue\",\"Apple SD Gothic Neo\",\"Malgun Gothic\",\"맑은 고딕\",나눔고딕,\"Nanum Gothic\",\"Noto Sans KR\",\"Noto Sans CJK KR\",arial,돋움,Dotum,Tahoma,Geneva,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:var(--text1);box-sizing:border-box;}/*!sc*/\\n*{box-sizing:inherit;}/*!sc*/\\ncode{font-family:\\'Fira Mono\\',source-code-pro,Menlo,Monaco,Consolas,\\'Courier New\\', monospace;}/*!sc*/\\ninput,button,textarea{font-family:inherit;}/*!sc*/\\nhtml,body,#root{height:100%;}/*!sc*/\\nbody{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\\n@media (prefers-color-scheme:dark){body{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}}/*!sc*/\\nbody[data-theme=\\'light\\']{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\\nbody[data-theme=\\'dark\\']{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}/*!sc*/\\ndata-styled.g152[id=\"sc-global-gYCCRU3\"]{content:\"sc-global-gYCCRU3,\"}/*!sc*/\\n.fdAPYo{margin-top:2rem;padding:2rem 1.5rem;background:var(--bg-element2);border-radius:8px;box-shadow:0 0 4px 0 rgba(0,0,0,0.06);position:relative;}/*!sc*/\\n@media (max-width:768px){.fdAPYo{padding:1rem;}}/*!sc*/\\n.fdAPYo svg{color:var(--primary1);}/*!sc*/\\n.fdAPYo h2{margin-top:0;color:var(--text2);font-weight:bold;padding-right:2rem;font-size:1.5rem;}/*!sc*/\\n.fdAPYo h2 a{-webkit-text-decoration:none;text-decoration:none;color:inherit;}/*!sc*/\\n.fdAPYo h2 a:hover{color:var(--text3);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\\n@media (max-width:768px){.fdAPYo h2{font-size:1.125rem;padding-right:2.5rem;margin-bottom:1.5rem;}}/*!sc*/\\n.fdAPYo .series-corner-image{position:absolute;right:1.5rem;top:0px;}/*!sc*/\\n@media (max-width:768px){.fdAPYo .series-corner-image{right:1rem;width:1.5rem;height:auto;}}/*!sc*/\\ndata-styled.g153[id=\"sc-fyrocj\"]{content:\"fdAPYo,\"}/*!sc*/\\n.kHBljz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\\n.kHBljz .series-number{font-size:0.875rem;color:var(--text3);}/*!sc*/\\ndata-styled.g154[id=\"sc-iWVNaa\"]{content:\"kHBljz,\"}/*!sc*/\\n.iaYsmD{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:-5px;color:var(--text2);line-height:1;cursor:pointer;}/*!sc*/\\n.iaYsmD svg{margin-right:0.25rem;color:var(--text1);font-size:1.5rem;}/*!sc*/\\n.iaYsmD:hover{color:var(--text1);}/*!sc*/\\n.iaYsmD:hover svg{color:var(--text1);}/*!sc*/\\ndata-styled.g155[id=\"sc-jKTccl\"]{content:\"iaYsmD,\"}/*!sc*/\\n.bLPYpH{margin-top:3rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\\ndata-styled.g156[id=\"sc-bUbRBg\"]{content:\"bLPYpH,\"}/*!sc*/\\n.ezwaSR{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-left:1.125rem;}/*!sc*/\\ndata-styled.g157[id=\"sc-tAExr\"]{content:\"ezwaSR,\"}/*!sc*/\\n.eRIqao{width:1.5rem;height:1.5rem;border-radius:50%;outline:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;font-size:1.25rem;color:var(--primary1);background:var(--bg-element1);border:1px solid var(--border4);padding:0;cursor:pointer;}/*!sc*/\\n.eRIqao:hover{background:var(--primary1);color:white;}/*!sc*/\\n.sc-dSfdvi + .sc-dSfdvi{margin-left:0.375rem;}/*!sc*/\\n.eRIqao:disabled{cursor:default;background:var(--bg-element2);border:1px solid var(--border4);color:var(--text3);opacity:0.3;}/*!sc*/\\ndata-styled.g158[id=\"sc-dSfdvi\"]{content:\"eRIqao,\"}/*!sc*/\\n.homixB{margin-top:0.875rem;margin-bottom:-0.875rem;min-height:0.875rem;}/*!sc*/\\n@media (max-width:768px){.homixB{margin-top:0.5rem;margin-bottom:-0.5rem;min-height:0.5rem;}}/*!sc*/\\ndata-styled.g160[id=\"sc-cHzqoD\"]{content:\"homixB,\"}/*!sc*/\\n.cjEODL{margin-top:5.5rem;}/*!sc*/\\n@media (max-width:1024px){.cjEODL .head-wrapper{padding-left:1rem;padding-right:1rem;}}/*!sc*/\\n.cjEODL h1{font-size:3rem;line-height:1.5;-webkit-letter-spacing:-0.004em;-moz-letter-spacing:-0.004em;-ms-letter-spacing:-0.004em;letter-spacing:-0.004em;margin-top:0;font-weight:800;color:var(--text1);margin-bottom:2rem;word-break:keep-all;-webkit-transition:color 0.125s ease-in;transition:color 0.125s ease-in;}/*!sc*/\\n@media (max-width:1024px){.cjEODL{margin-top:2rem;}.cjEODL h1{font-size:2.25rem;}}/*!sc*/\\ndata-styled.g161[id=\"sc-JkixQ\"]{content:\"cjEODL,\"}/*!sc*/\\n.gIGUn{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:1rem;color:var(--text2);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/\\n.gIGUn .information .username{color:var(--text1);font-weight:bold;}/*!sc*/\\n.gIGUn .information .username a{color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\\n.gIGUn .information .username a:hover{color:var(--text2);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\\n.gIGUn .information .separator{margin-left:0.5rem;margin-right:0.5rem;}/*!sc*/\\n@media (max-width:768px){.gIGUn .information{font-size:0.875rem;}}/*!sc*/\\n@media (max-width:768px){.gIGUn{margin-bottom:0.75rem;}}/*!sc*/\\ndata-styled.g162[id=\"sc-gGPzkF\"]{content:\"gIGUn,\"}/*!sc*/\\n.gNSMhR{max-height:100vh;max-width:100%;width:auto;margin:0 auto;height:auto;object-fit:contain;display:block;margin-top:2rem;}/*!sc*/\\n@media (max-width:768px){.gNSMhR{margin-top:1.5rem;}}/*!sc*/\\ndata-styled.g164[id=\"sc-jivBlf\"]{content:\"gNSMhR,\"}/*!sc*/\\n.lhyTWG{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:none;}/*!sc*/\\n@media (max-width:1024px){.lhyTWG{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/\\ndata-styled.g165[id=\"sc-hkgtus\"]{content:\"lhyTWG,\"}/*!sc*/\\n.bBHgCY{width:768px;margin:0 auto;margin-top:5rem;}/*!sc*/\\n@media (max-width:1024px){.bBHgCY{padding-left:1rem;padding-right:1rem;}}/*!sc*/\\n@media (max-width:768px){.bBHgCY{width:100%;}}/*!sc*/\\ndata-styled.g167[id=\"sc-jvvksu\"]{content:\"bBHgCY,\"}/*!sc*/\\n.ewkRvR{margin-top:3rem;color:var(--text1);}/*!sc*/\\n.ewkRvR h4{font-size:1.125rem;line-height:1.5;font-weight:600;margin-bottom:1rem;}/*!sc*/\\n@media (max-width:768px){.ewkRvR{padding-left:1rem;padding-right:1rem;}}/*!sc*/\\ndata-styled.g168[id=\"sc-edERGn\"]{content:\"ewkRvR,\"}/*!sc*/\\n.ioCAmf > .buttons-wrapper{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/\\ndata-styled.g170[id=\"sc-iWBNLc\"]{content:\"ioCAmf,\"}/*!sc*/\\n.jjhhWc{resize:none;padding:1rem;padding-bottom:1.5rem;outline:none;border:1px solid var(--border4);margin-bottom:1.5rem;width:100%;border-radius:4px;min-height:6.125rem;font-size:1rem;color:var(--text1);line-height:1.75;background:var(--bg-element1);}/*!sc*/\\n.jjhhWc::-webkit-input-placeholder{color:var(--text3);}/*!sc*/\\n.jjhhWc::-moz-placeholder{color:var(--text3);}/*!sc*/\\n.jjhhWc:-ms-input-placeholder{color:var(--text3);}/*!sc*/\\n.jjhhWc::placeholder{color:var(--text3);}/*!sc*/\\n@media (max-width:768px){.jjhhWc{margin-bottom:1rem;}}/*!sc*/\\ndata-styled.g171[id=\"sc-hYQoXb\"]{content:\"jjhhWc,\"}/*!sc*/\\n.eAtqhB{padding-top:1.5rem;padding-bottom:1.5rem;}/*!sc*/\\n.sc-cVAmsi + .sc-cVAmsi{border-top:1px solid var(--border4);}/*!sc*/\\ndata-styled.g176[id=\"sc-cVAmsi\"]{content:\"eAtqhB,\"}/*!sc*/\\n.iNiviY{margin-bottom:1.5rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\\n.iNiviY .profile{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\\n.iNiviY .profile img{width:3.375rem;height:3.375rem;display:block;border-radius:50%;object-fit:cover;}/*!sc*/\\n@media (max-width:768px){.iNiviY .profile img{width:2.5rem;height:2.5rem;}}/*!sc*/\\n.iNiviY .profile .comment-info{margin-left:1rem;line-height:1;}/*!sc*/\\n@media (max-width:768px){.iNiviY .profile .comment-info{margin-left:0.5rem;}}/*!sc*/\\n.iNiviY .profile .comment-info .username{font-size:1rem;font-weight:bold;color:var(--text1);}/*!sc*/\\n@media (max-width:768px){.iNiviY .profile .comment-info .username{font-size:0.875rem;}}/*!sc*/\\n.iNiviY .profile .comment-info .username a{color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\\n.iNiviY .profile .comment-info .username a:hover{-webkit-text-decoration:underline;text-decoration:underline;color:var(--text2);}/*!sc*/\\n.iNiviY .profile .comment-info .date{margin-top:0.5rem;color:var(--text3);font-size:0.875rem;}/*!sc*/\\n@media (max-width:768px){.iNiviY .profile .comment-info .date{font-size:0.75rem;}}/*!sc*/\\n.iNiviY .actions{font-size:0.875rem;color:var(--text3);}/*!sc*/\\n@media (max-width:768px){.iNiviY .actions{font-size:0.75rem;}}/*!sc*/\\n.iNiviY .actions span{cursor:pointer;}/*!sc*/\\n.iNiviY .actions span:hover{color:var(--text3);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\\n.iNiviY .actions span + span{margin-left:0.5rem;}/*!sc*/\\ndata-styled.g177[id=\"sc-kHxTfl\"]{content:\"iNiviY,\"}/*!sc*/\\n.iYgFNI h1,.iYgFNI h2{font-size:1.75rem;}/*!sc*/\\n@media (max-width:768px){.iYgFNI h1,.iYgFNI h2{font-size:1.5rem;}}/*!sc*/\\ndata-styled.g178[id=\"sc-ksHpcM\"]{content:\"iYgFNI,\"}/*!sc*/\\n.mIalr{margin-top:2rem;}/*!sc*/\\ndata-styled.g179[id=\"sc-gXRojI\"]{content:\"mIalr,\"}/*!sc*/\\n.kbaMiN{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--primary1);font-weight:bold;cursor:pointer;}/*!sc*/\\n.kbaMiN svg{margin-right:0.5rem;}/*!sc*/\\n.kbaMiN:hover{color:var(--primary2);}/*!sc*/\\ndata-styled.g180[id=\"sc-bGaVxB\"]{content:\"kbaMiN,\"}/*!sc*/\\n.jGGkyw{margin-top:2.5rem;}/*!sc*/\\ndata-styled.g182[id=\"sc-gnnDb\"]{content:\"jGGkyw,\"}/*!sc*/\\n.dhBvrx{position:relative;margin-top:2rem;}/*!sc*/\\n@media (max-width:1024px){.dhBvrx{display:none;}}/*!sc*/\\ndata-styled.g184[id=\"sc-igXgud\"]{content:\"dhBvrx,\"}/*!sc*/\\n.eiGuQF{position:absolute;left:-7rem;}/*!sc*/\\ndata-styled.g185[id=\"sc-JEhMO\"]{content:\"eiGuQF,\"}/*!sc*/\\n.eRdeFp{width:4rem;background:var(--bg-element2);border:1px solid var(--border4);border-radius:2rem;padding:0.5rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\\ndata-styled.g186[id=\"sc-gHjyzD\"]{content:\"eRdeFp,\"}/*!sc*/\\n.SGCHT{height:3rem;width:3rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background:var(--bg-element1);border:1px solid var(--border3);border-radius:1.5rem;color:var(--text3);cursor:pointer;z-index:5;}/*!sc*/\\n.SGCHT svg{width:24px;height:24px;}/*!sc*/\\n.SGCHT svg.share{width:20px;height:20px;}/*!sc*/\\n.SGCHT:hover{color:var(--text1);border-color:var(--text1);}/*!sc*/\\ndata-styled.g187[id=\"sc-itWPBs\"]{content:\"SGCHT,\"}/*!sc*/\\n.lpdPRq{margin-top:0.5rem;color:var(--text2);line-height:1;font-size:0.75rem;margin-bottom:1rem;font-weight:bold;}/*!sc*/\\ndata-styled.g188[id=\"sc-dcgwPl\"]{content:\"lpdPRq,\"}/*!sc*/\\n.kPcWLl{position:relative;width:100%;z-index:5;}/*!sc*/\\n.kPcWLl .positioner{position:absolute;}/*!sc*/\\ndata-styled.g189[id=\"sc-ehIJor\"]{content:\"kPcWLl,\"}/*!sc*/\\n.jUaBPZ{top:0;left:0;position:absolute;width:48px;height:48px;}/*!sc*/\\ndata-styled.g190[id=\"sc-hGnimi\"]{content:\"jUaBPZ,\"}/*!sc*/\\n.crTinq{width:32px;height:32px;border-radius:16px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border:1px solid var(--primary2);font-size:1.5rem;color:var(--primary2);margin-right:1rem;}/*!sc*/\\n.NTSqV{width:32px;height:32px;border-radius:16px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border:1px solid var(--primary2);font-size:1.5rem;color:var(--primary2);margin-left:1rem;}/*!sc*/\\ndata-styled.g195[id=\"sc-hJhJFJ\"]{content:\"crTinq,NTSqV,\"}/*!sc*/\\n.gkzonb{cursor:pointer;background:var(--bg-element2);box-shadow:0 0 4px 0 rgba(0,0,0,0.06);width:100%;padding-left:1rem;padding-right:1rem;height:4rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\\n.gkzonb:hover .sc-hJhJFJ{-webkit-animation-duration:0.35s;animation-duration:0.35s;-webkit-animation-name:dRQjsE;animation-name:dRQjsE;-webkit-animation-fill-mode:forwards;animation-fill-mode:forwards;-webkit-animation-timing-function:ease-out;animation-timing-function:ease-out;}/*!sc*/\\n.jOoREI{cursor:pointer;background:var(--bg-element2);box-shadow:0 0 4px 0 rgba(0,0,0,0.06);width:100%;padding-left:1rem;padding-right:1rem;height:4rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-text-decoration:none;text-decoration:none;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;}/*!sc*/\\n.jOoREI:hover .sc-hJhJFJ{-webkit-animation-duration:0.35s;animation-duration:0.35s;-webkit-animation-name:iyGUEJ;animation-name:iyGUEJ;-webkit-animation-fill-mode:forwards;animation-fill-mode:forwards;-webkit-animation-timing-function:ease-out;animation-timing-function:ease-out;}/*!sc*/\\ndata-styled.g196[id=\"sc-lhMiDA\"]{content:\"gkzonb,jOoREI,\"}/*!sc*/\\n.lasECz{-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;line-height:1;min-width:0;}/*!sc*/\\n.lasECz .description{font-size:0.75rem;font-weight:bold;color:var(--text2);}/*!sc*/\\n.lasECz h3{width:100%;font-size:1.125rem;color:var(--text2);line-height:1.15;margin:0;margin-top:0.5rem;text-overflow:ellipsis;white-space:nowrap;overflow-x:hidden;overflow-y:hidden;}/*!sc*/\\n@media (max-width:768px){.lasECz h3{font-size:1rem;}}/*!sc*/\\n.cQnPYI{-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;line-height:1;min-width:0;}/*!sc*/\\n.cQnPYI .description{font-size:0.75rem;font-weight:bold;color:var(--text2);}/*!sc*/\\n.cQnPYI h3{text-align:right;width:100%;font-size:1.125rem;color:var(--text2);line-height:1.15;margin:0;margin-top:0.5rem;text-overflow:ellipsis;white-space:nowrap;overflow-x:hidden;overflow-y:hidden;}/*!sc*/\\n@media (max-width:768px){.cQnPYI h3{font-size:1rem;}}/*!sc*/\\ndata-styled.g197[id=\"sc-cvlWTT\"]{content:\"lasECz,cQnPYI,\"}/*!sc*/\\n.eMFVHd{margin-top:3rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/\\n@media (max-width:768px){.eMFVHd{-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;padding-left:1rem;padding-right:1rem;}}/*!sc*/\\ndata-styled.g198[id=\"sc-fTQvRK\"]{content:\"eMFVHd,\"}/*!sc*/\\n.cOfbyG{min-width:0;-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/\\n.sc-bUhFKy + .sc-bUhFKy{margin-left:3rem;}/*!sc*/\\n@media (max-width:768px){.cOfbyG{-webkit-flex:initial;-ms-flex:initial;flex:initial;width:100%;}.sc-bUhFKy + .sc-bUhFKy{margin-left:0;margin-bottom:1.5rem;}}/*!sc*/\\ndata-styled.g199[id=\"sc-bUhFKy\"]{content:\"cOfbyG,\"}/*!sc*/\\n.kGybnn{margin-top:5.5rem;}/*!sc*/\\n.kGybnn h1{padding-right:2rem;font-size:3.75rem;margin-top:0;margin-bottom:2rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/\\n.kGybnn .subinfo{font-size:1rem;}/*!sc*/\\n.kGybnn .tags{font-size:2rem;margin-top:0.875rem;}/*!sc*/\\n.kGybnn .tags .tag-skeleton + .tag-skeleton{margin-left:0.5rem;}/*!sc*/\\n.kGybnn .series{margin-top:2rem;}/*!sc*/\\n.kGybnn .thumbnail{margin-top:2rem;padding-top:52.35%;position:relative;}/*!sc*/\\n.kGybnn .thumbnail .thumbnail-skeleton{position:absolute;top:0;left:0;width:100%;height:100%;}/*!sc*/\\n.kGybnn .contents{margin-top:5rem;}/*!sc*/\\n.kGybnn .contents .line{margin-bottom:0.75rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-size:1.125rem;}/*!sc*/\\n.kGybnn .contents .lines + .lines{margin-top:3rem;}/*!sc*/\\n@media (max-width:1024px){.kGybnn{margin-top:2rem;}.kGybnn h1{font-size:2.25rem;}.kGybnn .subinfo{font-size:0.875rem;}.kGybnn .tags{font-size:1.5rem;}}/*!sc*/\\ndata-styled.g200[id=\"sc-hRMWxn\"]{content:\"kGybnn,\"}/*!sc*/\\n@media (max-width:768px){.enaCzh{padding-left:1rem;padding-right:1rem;}}/*!sc*/\\ndata-styled.g201[id=\"sc-fTxOGA\"]{content:\"enaCzh,\"}/*!sc*/\\n.WNKnM{background:var(--bg-element1);border:1px solid var(--border2);padding-left:0.75rem;padding-right:0.75rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:1.5rem;border-radius:0.75rem;outline:none;}/*!sc*/\\n.WNKnM svg{width:0.75rem;height:0.75rem;margin-right:0.75rem;color:var(--text3);}/*!sc*/\\n.WNKnM span{font-size:0.75rem;font-weight:bold;color:var(--text3);}/*!sc*/\\ndata-styled.g202[id=\"sc-BHvUt\"]{content:\"WNKnM,\"}/*!sc*/\\n.iA-dFHq{margin-top:1rem;margin-bottom:1rem;}/*!sc*/\\ndata-styled.g207[id=\"sc-hKTqa\"]{content:\"iA-dFHq,\"}/*!sc*/\\n.hpspee{margin-top:16rem;margin-bottom:6rem;}/*!sc*/\\n@media (max-width:1024px){.hpspee{margin-top:8rem;margin-bottom:3rem;}}/*!sc*/\\n@media (max-width:768px){.hpspee{margin-top:2rem;}}/*!sc*/\\ndata-styled.g208[id=\"sc-gfqkcP\"]{content:\"hpspee,\"}/*!sc*/\\n@-webkit-keyframes dRQjsE{0%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}50%{-webkit-transform:translateX(-8px);-ms-transform:translateX(-8px);transform:translateX(-8px);}100%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}}/*!sc*/\\n@keyframes dRQjsE{0%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}50%{-webkit-transform:translateX(-8px);-ms-transform:translateX(-8px);transform:translateX(-8px);}100%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}}/*!sc*/\\ndata-styled.g209[id=\"sc-keyframes-dRQjsE\"]{content:\"dRQjsE,\"}/*!sc*/\\n@-webkit-keyframes iyGUEJ{0%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}50%{-webkit-transform:translateX(8px);-ms-transform:translateX(8px);transform:translateX(8px);}100%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}}/*!sc*/\\n@keyframes iyGUEJ{0%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}50%{-webkit-transform:translateX(8px);-ms-transform:translateX(8px);transform:translateX(8px);}100%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}}/*!sc*/\\ndata-styled.g210[id=\"sc-keyframes-iyGUEJ\"]{content:\"iyGUEJ,\"}/*!sc*/\\nbody{background:var(--bg-page2);}/*!sc*/\\ndata-styled.g211[id=\"sc-global-iqNrnJ4\"]{content:\"sc-global-iqNrnJ4,\"}/*!sc*/\\nbody{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,\"Helvetica Neue\",\"Apple SD Gothic Neo\",\"Malgun Gothic\",\"맑은 고딕\",나눔고딕,\"Nanum Gothic\",\"Noto Sans KR\",\"Noto Sans CJK KR\",arial,돋움,Dotum,Tahoma,Geneva,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:var(--text1);box-sizing:border-box;}/*!sc*/\\n*{box-sizing:inherit;}/*!sc*/\\ncode{font-family:\\'Fira Mono\\',source-code-pro,Menlo,Monaco,Consolas,\\'Courier New\\', monospace;}/*!sc*/\\ninput,button,textarea{font-family:inherit;}/*!sc*/\\nhtml,body,#root{height:100%;}/*!sc*/\\nbody{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\\n@media (prefers-color-scheme:dark){body{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}}/*!sc*/\\nbody[data-theme=\\'light\\']{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\\nbody[data-theme=\\'dark\\']{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}/*!sc*/\\ndata-styled.g212[id=\"sc-global-gYCCRU4\"]{content:\"sc-global-gYCCRU4,\"}/*!sc*/\\n</style><link data-chunk=\"main\" rel=\"preload\" as=\"style\" href=\"https://static.velog.io/static/css/main.e7869632.chunk.css\"/><link data-chunk=\"main\" rel=\"preload\" as=\"style\" href=\"https://static.velog.io/static/css/20.5dbdccff.chunk.css\"/><link data-chunk=\"main\" rel=\"preload\" as=\"script\" href=\"https://static.velog.io/static/js/runtime-main.5e039cd5.js\"/><link data-chunk=\"main\" rel=\"preload\" as=\"script\" href=\"https://static.velog.io/static/js/20.357f3aca.chunk.js\"/><link data-chunk=\"main\" rel=\"preload\" as=\"script\" href=\"https://static.velog.io/static/js/main.7e8cf780.chunk.js\"/><link data-chunk=\"pages-velog-VelogPage\" rel=\"preload\" as=\"script\" href=\"https://static.velog.io/static/js/pages-velog-VelogPage.ebd63700.chunk.js\"/><link data-chunk=\"PostPage\" rel=\"preload\" as=\"script\" href=\"https://static.velog.io/static/js/0.1f8bb2ed.chunk.js\"/><link data-chunk=\"PostPage\" rel=\"preload\" as=\"script\" href=\"https://static.velog.io/static/js/23.3869d1a9.chunk.js\"/><link data-chunk=\"PostPage\" rel=\"preload\" as=\"script\" href=\"https://static.velog.io/static/js/1.5cd4e340.chunk.js\"/><link data-chunk=\"PostPage\" rel=\"preload\" as=\"script\" href=\"https://static.velog.io/static/js/PostPage.3dee536f.chunk.js\"/><link data-chunk=\"main\" rel=\"stylesheet\" href=\"https://static.velog.io/static/css/20.5dbdccff.chunk.css\"/><link data-chunk=\"main\" rel=\"stylesheet\" href=\"https://static.velog.io/static/css/main.e7869632.chunk.css\"/><link rel=\"shortcut icon\" href=\"https://static.velog.io/favicon.ico\"/><link rel=\"apple-touch-icon\" sizes=\"152x152\" href=\"https://static.velog.io/favicons/apple-icon-152x152.png\"/><link rel=\"icon\" sizes=\"32x32\" href=\"https://static.velog.io/favicons/favicon-32x32.png\"/><link rel=\"icon\" sizes=\"96x96\" href=\"https://static.velog.io/favicons/favicon-96x96.png\"/><link rel=\"icon\" sizes=\"16x16\" href=\"https://static.velog.io/favicons/favicon-16x16.png\"/><meta name=\"viewport\" content=\"width=device-width, initial-scale=1\"/><script async=\"\" src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9161852896103498\" crossorigin=\"anonymous\"></script><script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=G-8D0MD2S4PK\"></script><script>window.dataLayer = window.dataLayer || [];\\n            function gtag(){dataLayer.push(arguments);}\\n            gtag(\\'js\\', new Date());\\n          \\n            gtag(\\'config\\', \\'G-8D0MD2S4PK\\');</script></head><body><div id=\"root\"><div class=\"__jazzbar false false\" style=\"width:0%\"></div><div class=\"sc-jObWnj sc-dPiLbb cMpExe\"><div class=\"sc-iwjdpV hcjGyB\"><div class=\"sc-fotOHu evafIC sc-llYSUQ kYqaTx\"><div class=\"sc-hGPBjI cdniDY\"><a class=\"sc-dlVxhl eleXpO\" href=\"/\"><svg width=\"192\" height=\"192\" viewBox=\"0 0 192 192\" fill=\"currentColor\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M24 0H168C181.255 0 192 10.7451 192 24V168C192 181.255 181.255 192 168 192H24C10.7451 192 0 181.255 0 168V24C0 10.7451 10.7451 0 24 0ZM49 57.9199V65.48H67L80.6799 142.52L98.5 141.26C116.02 119.06 127.84 102.44 133.96 91.3999C140.2 80.24 143.32 70.9399 143.32 63.5C143.32 59.0601 142 55.7 139.36 53.4199C136.84 51.1399 133.66 50 129.82 50C122.62 50 116.62 53.0601 111.82 59.1799C116.5 62.3 119.68 64.8799 121.36 66.9199C123.16 68.8401 124.06 71.4199 124.06 74.6599C124.06 80.0601 122.44 86.1799 119.2 93.02C116.08 99.8601 112.66 105.92 108.94 111.2C106.54 114.56 103.48 118.7 99.76 123.62L88.0601 57.2C87.1001 52.3999 84.1001 50 79.0601 50C76.78 50 72.3999 50.96 65.9199 52.8799C59.4399 54.6799 53.8 56.3601 49 57.9199Z\" fill=\"currentColor\"></path></svg></a><a class=\"user-logo\" href=\"/@minkyu4506\">Minguinho_zeze.log</a></div><div class=\"sc-iJKOTD cxmSXL\"><a class=\"sc-cxpSdN iIPjQP\" href=\"/search?username=minkyu4506\"><svg width=\"17\" height=\"17\" viewBox=\"0 0 17 17\"><path fill-rule=\"evenodd\" d=\"M13.66 7.36a6.3 6.3 0 1 1-12.598 0 6.3 6.3 0 0 1 12.598 0zm-1.73 5.772a7.36 7.36 0 1 1 1.201-1.201l3.636 3.635c.31.31.31.815 0 1.126l-.075.075a.796.796 0 0 1-1.126 0l-3.636-3.635z\" clip-rule=\"evenodd\" fill=\"currentColor\"></path></svg></a><button color=\"darkGray\" class=\"sc-egiyK gflbJg\">로그인</button></div></div></div><div style=\"margin-top:0;opacity:0\" class=\"sc-efQSVx iZAesw\"><div class=\"sc-iwjdpV hcjGyB\"><div class=\"sc-fotOHu evafIC sc-llYSUQ kYqaTx\"><div class=\"sc-hGPBjI cdniDY\"><a class=\"sc-dlVxhl eleXpO\" href=\"/\"><svg width=\"192\" height=\"192\" viewBox=\"0 0 192 192\" fill=\"currentColor\"><path fill-rule=\"evenodd\" clip-rule=\"evenodd\" d=\"M24 0H168C181.255 0 192 10.7451 192 24V168C192 181.255 181.255 192 168 192H24C10.7451 192 0 181.255 0 168V24C0 10.7451 10.7451 0 24 0ZM49 57.9199V65.48H67L80.6799 142.52L98.5 141.26C116.02 119.06 127.84 102.44 133.96 91.3999C140.2 80.24 143.32 70.9399 143.32 63.5C143.32 59.0601 142 55.7 139.36 53.4199C136.84 51.1399 133.66 50 129.82 50C122.62 50 116.62 53.0601 111.82 59.1799C116.5 62.3 119.68 64.8799 121.36 66.9199C123.16 68.8401 124.06 71.4199 124.06 74.6599C124.06 80.0601 122.44 86.1799 119.2 93.02C116.08 99.8601 112.66 105.92 108.94 111.2C106.54 114.56 103.48 118.7 99.76 123.62L88.0601 57.2C87.1001 52.3999 84.1001 50 79.0601 50C76.78 50 72.3999 50.96 65.9199 52.8799C59.4399 54.6799 53.8 56.3601 49 57.9199Z\" fill=\"currentColor\"></path></svg></a><a class=\"user-logo\" href=\"/@minkyu4506\">Minguinho_zeze.log</a></div><div class=\"sc-iJKOTD cxmSXL\"><a class=\"sc-cxpSdN iIPjQP\" href=\"/search?username=minkyu4506\"><svg width=\"17\" height=\"17\" viewBox=\"0 0 17 17\"><path fill-rule=\"evenodd\" d=\"M13.66 7.36a6.3 6.3 0 1 1-12.598 0 6.3 6.3 0 0 1 12.598 0zm-1.73 5.772a7.36 7.36 0 1 1 1.201-1.201l3.636 3.635c.31.31.31.815 0 1.126l-.075.075a.796.796 0 0 1-1.126 0l-3.636-3.635z\" clip-rule=\"evenodd\" fill=\"currentColor\"></path></svg></a><button color=\"darkGray\" class=\"sc-egiyK gflbJg\">로그인</button></div></div></div></div><div class=\"sc-dvQaRk ijHvhk sc-JkixQ cjEODL\"><div class=\"head-wrapper\"><h1>[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving </h1><div class=\"sc-gGPzkF gIGUn\"><div class=\"information\"><span class=\"username\"><a href=\"/@minkyu4506\">minkyu4506</a></span><span class=\"separator\">·</span><span>2021년 8월 5일</span></div><div class=\"sc-hkgtus lhyTWG\"><button data-testid=\"like-btn\" class=\"sc-BHvUt WNKnM\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\"><path fill=\"currentColor\" d=\"M18 1l-6 4-6-4-6 5v7l12 10 12-10v-7z\"></path></svg><span>6</span></button></div></div><div class=\"sc-cHzqoD homixB\"><a class=\"sc-fbyfCU jhmYjy\" href=\"/tags/autonomous-driving\">autonomous driving</a><a class=\"sc-fbyfCU jhmYjy\" href=\"/tags/multimodal-learning\">multimodal learning</a><a class=\"sc-fbyfCU jhmYjy\" href=\"/tags/paperreview\">paper_review</a></div><div class=\"sc-igXgud dhBvrx\"><div class=\"sc-JEhMO eiGuQF\"><div class=\"sc-cjrPHo sc-gHjyzD eRdeFp\"><div data-testid=\"like\" active=\"false\" style=\"transform:scale(1)\" class=\"sc-itWPBs SGCHT\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\"><path fill=\"currentColor\" d=\"M18 1l-6 4-6-4-6 5v7l12 10 12-10v-7z\"></path></svg></div><div class=\"sc-dcgwPl lpdPRq\">6</div><div class=\"sc-ehIJor kPcWLl\"><div class=\"positioner\"><div style=\"opacity:0;transform:translate(0px, 0px)\" class=\"sc-hGnimi jUaBPZ\"><div class=\"sc-itWPBs SGCHT\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 512 512\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z\"></path></svg></div></div><div style=\"opacity:0;transform:translate(0px)\" class=\"sc-hGnimi jUaBPZ\"><div class=\"sc-itWPBs SGCHT\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 512 512\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z\"></path></svg></div></div><div style=\"opacity:0;transform:translate(0px, 0px)\" class=\"sc-hGnimi jUaBPZ\"><div class=\"sc-itWPBs SGCHT\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\"><path d=\"M21.586 10.461l-10.05 10.075c-1.95 1.949-5.122 1.949-7.071 0s-1.95-5.122 0-7.072l10.628-10.585c1.17-1.17 3.073-1.17 4.243 0 1.169 1.17 1.17 3.072 0 4.242l-8.507 8.464c-.39.39-1.024.39-1.414 0s-.39-1.024 0-1.414l7.093-7.05-1.415-1.414-7.093 7.049c-1.172 1.172-1.171 3.073 0 4.244s3.071 1.171 4.242 0l8.507-8.464c.977-.977 1.464-2.256 1.464-3.536 0-2.769-2.246-4.999-5-4.999-1.28 0-2.559.488-3.536 1.465l-10.627 10.583c-1.366 1.368-2.05 3.159-2.05 4.951 0 3.863 3.13 7 7 7 1.792 0 3.583-.684 4.95-2.05l10.05-10.075-1.414-1.414z\" fill=\"currentColor\"></path></svg></div></div></div></div><div><div style=\"position:relative\" class=\"sc-itWPBs SGCHT\"><svg width=\"24\" height=\"24\" viewBox=\"0 0 24 24\" class=\"share\"><path fill=\"currentColor\" d=\"M5 7c2.761 0 5 2.239 5 5s-2.239 5-5 5-5-2.239-5-5 2.239-5 5-5zm11.122 12.065c-.073.301-.122.611-.122.935 0 2.209 1.791 4 4 4s4-1.791 4-4-1.791-4-4-4c-1.165 0-2.204.506-2.935 1.301l-5.488-2.927c-.23.636-.549 1.229-.943 1.764l5.488 2.927zm7.878-15.065c0-2.209-1.791-4-4-4s-4 1.791-4 4c0 .324.049.634.122.935l-5.488 2.927c.395.535.713 1.127.943 1.764l5.488-2.927c.731.795 1.77 1.301 2.935 1.301 2.209 0 4-1.791 4-4z\"></path></svg></div></div></div></div></div><div class=\"sc-fyrocj fdAPYo\"><h2><a href=\"/@minkyu4506/series/논문-리뷰-구현\">논문 리뷰 + 구현</a></h2><svg width=\"32\" height=\"48\" fill=\"currentColor\" viewBox=\"0 0 32 48\" class=\"series-corner-image\"><path fill=\"currentColor\" d=\"M32 0H0v48h.163l16-16L32 47.836V0z\"></path></svg><div class=\"sc-bUbRBg bLPYpH\"><div class=\"sc-jKTccl iaYsmD\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 24 24\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 10l5 5 5-5z\"></path></svg>목록 보기</div><div class=\"sc-iWVNaa kHBljz\"><div class=\"series-number\">2<!-- -->/<!-- -->21</div><div class=\"sc-tAExr ezwaSR\"><button class=\"sc-dSfdvi eRIqao\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 24 24\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M15.41 7.41L14 6l-6 6 6 6 1.41-1.41L10.83 12z\"></path></svg></button><button class=\"sc-dSfdvi eRIqao\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 24 24\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z\"></path></svg></button></div></div></div></div></div><img src=\"https://velog.velcdn.com/images/minkyu4506/post/18537d03-8701-4bc7-90aa-f1cd4b26a51a/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.14.18.png\" alt=\"post-thumbnail\" class=\"sc-jivBlf gNSMhR\"/></div><div class=\"sc-dvQaRk ijHvhk sc-hKTqa iA-dFHq\"><ins class=\"adsbygoogle\" style=\"display:block;text-align:center\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-9161852896103498\" data-ad-slot=\"6869845586\"></ins></div><div class=\"sc-jvvksu bBHgCY\"><div class=\"sc-bQtKYq ehISJN\"><div class=\"sc-fXEqDS jlUmJL atom-one\"><p> 안녕하세요. 밍기뉴와제제입니다. </p>\\n<p>정말 오랜만에 돌아왔습니다. 논문은 여러개 봤는데 리뷰할 정도로 깊게 탐구한 논문이 별로 없어 한동안 글을 안쓰다 이번에 논문 세미나를 하다보니 꼼꼼히 살펴본 논문이 생겼습니다. </p>\\n<p> 이번에 리뷰를 하려는 논문은 \\'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving \\'라는 논문입니다. 자율주행에 관한 논문이죠. </p>\\n<p> 이름을 보면 대충 짐작 가시겠지만 이 논문은 multimodal, 두가지 데이터를 처리하는 모델을 설계했습니다. 그리고 Transformer도 이용했다는 사실을 짐작할 수 있습니다. </p>\\n<p> 그러면 지금부터 논문 흐름에 맞춰 리뷰를 해보도록 하겠습니다. </p>\\n<h2 id=\"introduction\">Introduction</h2>\\n<hr />\\n<p> 이 부분에서는 이전까지 자율주행 모델이 사용한 방식들을 소개 후 저자가 소개하는 모델 \\'transfuser\\'에 대해 설명합니다. </p>\\n<h3 id=\"한가지-입력값만-받는-모델\">한가지 입력값만 받는 모델</h3>\\n<p> 이전에 Image-only model과 LiDAR-only model이 등장했고 이는 자율주행의 성능을 올리는데 많이 기여했습니다. 허나 이렇게 한가지 데이터만 입력값으로 사용한 모델은 <strong>near-ideal한 움직임을 보이는 객체</strong>들만 있는 환경에서 <strong>제한된 움직임만 필요한 경로</strong>에 주행해야만 높은 성능을 보여준다는 것이었죠. 굉장히 사용하기 까다로웠습니다. </p>\\n<p> 논문에서는 이를 두고 다음과 같이 말했습니다. </p>\\n<blockquote>\\n<p>adversarial scenarios에서 만족스럽지 못한 성능을 보여준다</p>\\n</blockquote>\\n<p>여기서 adversarial scenarios는 운전에 변수가 많이 생기는 환경을 말합니다. 예를 들면 비보호 회전을 해야하는 교차로, 랜덤하게 등장하는 자동차와 보행자 등이 운전에 변수를 주는 요소라 볼 수 있죠.<br />\\n그러면 이런 부분이 왜 낮은 성능이 나오게끔 하는걸까요? 다음의 그림을 보며 설명해 드리도록 하겠습니다. </p>\\n<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fcda53439-1ba7-461e-a3d2-7b6805019556%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%208.10.17.png\" /></p>\\n<p>위 사진은 논문에서 말한 adversarial scenarios 중 하나입니다.<br />\\n여기서 초록색 박스 안에 있는 자동차(Ego-Vehicle)와 왼쪽 도로에서 건너오는 빨간색 박스 속 자동차들(Traffic), 그리고 노란색 박스 안에 있는 신호등(Traffic Lights)이 있습니다. 여기서 Ego-Vehicle이 자율주행을 하는 자동차죠.</p>\\n<p>이 상황에서 Ego-Vehicle이 카메라와 LiDAR에서 얻은 데이터를 살펴봅시다. LiDAR의 정의는 다음과 같습니다.</p>\\n<blockquote>\\n<p>LiDAR : Light Detection And Ranging, 레이저를 발사 후 돌아오는 시간을 계산해 주변 물체를 검출하는 센서</p>\\n</blockquote>\\n<p>LiDAR는 3D 데이터인 Point Cloud를 생산하며 여기엔 카메라가 관측할 수 없는 넓은 범위에 존재하는 객체에 대한 정보가 포함되어 있습니다. 그림을 보면 카메라 뷰에서 보이지 않는 자동차(Traffic)을 검출했다는 사실을 확인할 수 있습니다. </p>\\n<p>허나 LiDAR는 카메라가 검출한 신호등을 찾지 못했습니다. 즉, 각 센서별로 얻을 수 있는 정보가 다릅니다. </p>\\n<p>이러한 상황에서 Image-only 혹은 LiDAR-only model을 사용해 자율주행을 한다고 가정해봅시다.<br />\\n그러면 아래와 같은 문제가 생길 확률이 높습니다.</p>\\n<ul>\\n<li>Image-only model : 왼쪽에서 건너오는 자동차들을 고려하지 않고 운전 -&gt; 추돌 사고</li>\\n<li>LiDAR-only model : 전방에 있는 신호등의 신호를 고려하지 않고 운전 -&gt; 신호 위반</li>\\n</ul>\\n<p>이건 꽤 큰 단점이죠. 그래서 사람들은 이를 해결하기 위한 방법을 찾고자 했습니다. </p>\\n<h3 id=\"두가지-입력값을-함께-사용해보자\">두가지 입력값을 함께 사용해보자</h3>\\n<p>사람들은 자율주행 자동차에 있는 센서에 주목했습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fed409fbd-f733-4294-a832-2410a12035b2%2F0*PjdSdGyiEB6Yg1UX.png\" /><br />\\n(출처 : <a href=\"https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f\">https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f</a>)</p>\\n<p>위 사진은 자율주행 자동차에 들어있는 센서를 나타낸 그림입니다. 보시면 알겠지만 자율주행 자동차 안에는 수많은 센서들이 들어있습니다. </p>\\n<p>이렇게 많은 센서를 보고 사람들이 생각한게 있습니다. </p>\\n<blockquote>\\n<p>\"자동차에 있는 두개의 센서를 함께 사용해보는건 어떨까?\"</p>\\n</blockquote>\\n<p>그래서 두가지 데이터를 함께 써보자는 아이디어를 떠올렸죠. 그리고 다음과 같은 질문을 남겼습니다. </p>\\n<blockquote>\\n<ul>\\n<li>두가지 데이터를 어떤 방식으로 합쳐서 사용하지?</li>\\n<li>두가지 데이터로 어떤걸 선택하지? </li>\\n</ul>\\n</blockquote>\\n<p>이 질문에 답하기 위해 수많은 논문들이 나왔습니다. 그 중 한가지 논문에 나온 모델 구조에 대해 간단히 소개해드리겠습니다. </p>\\n<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F74c12e61-7d7c-46aa-844e-21a9991b62fd%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%2010.19.35.png\" /><br />\\n(출처 : Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proc. IEEE Conf. on Computer Vision and Pat- tern Recognition (CVPR), 2017)</p>\\n<p>위 그림에 나온 구조가 두가지 데이터를 처리하는 대부분의 모델이 사용하는 구조입니다. 각 데이터별로 CNN에 넣어 특성맵을 추출한 뒤 원소 단위로 평균값을 낸다든지 더한다든지 하는 방식으로 Fusion해 하나의 출력값으로 만드는 방식이죠. </p>\\n<h3 id=\"여전히-아쉽다\">여전히 아쉽다!</h3>\\n<p>두가지 데이터를 이용하는 방식은 한가지 데이터를 사용하는 방식보다 성능이 좋았습니다. 허나 여전히 단점이 있었습니다. </p>\\n<p>바로 도심 속 운전같이 복잡한 상황에서 운전하기 힘들다는 점이었습니다. </p>\\n<p>교차로에서 운전할 때를 고려해봅시다. 위에 제가 올린 사진과 같은 상황이죠. 여기서 자율주행을 하는 자동차(Ego-Vehicle)는 왼쪽에서 오는 자동차(Traffic)과 신호등의 신호(Traffic Lights) 사이의 연관성을 고려하며 운전을 해야합니다. 허나 각 데이터별로 특성맵을 추출하면 특성을 추출하는 과정에서 모든 정보를 고려할 수 없게 됩니다. </p>\\n<p>즉, 모든 정보를 고려하지 않고 얻어낸 정보를 가지고 운전하기 때문에 사고가 날 확률이 높은 것이죠.</p>\\n<p>이는 데이터의 문제가 아니라 데이터를 처리하는 모델 구조의 문제였습니다. </p>\\n<h3 id=\"transformer\">Transformer</h3>\\n<p>그래서 저자는 Attention mechanism만 사용해 데이터를 처리하는 Transformer를 특성 추출 과정에서 사용하기로 했습니다. </p>\\n<p>Transformer의 self-attention는 입력 값의 각 원소가 전체적인 입력값의 어느 부분을 더 주목해야 하는지 반영하게 해주니 이를 이용해 이미지와 LiDAR 데이터를 전체적으로 고려하며 특성맵을 추출하는 방식을 생각한 것입니다.</p>\\n<p>\"두가지 데이터를 어떤 방식으로 합쳐서 사용하지?\" 에 대한 답변은 Transforemr였습니다.</p>\\n<h3 id=\"single-view-image-and-lidar-inputs\">Single-view image and LiDAR inputs</h3>\\n<p>그리고 \"두가지 데이터로 어떤걸 선택하지?\"에 대한 답변을 해야합니다. </p>\\n<p>저자는 이에 \"Single-view image and LiDAR를 입력 데이터로 사용한다\"고 말했습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F74af93a1-93f3-4d49-a6e9-dc0fa9a07905%2F%EC%9E%90%EB%A3%8C.png\" /><br />\\n이 둘을 사용하겠다는 것이죠.</p>\\n<p>왜 Single-view image and LiDAR를 선택한 걸까요? 저자는 이 둘이 서로가 서로에게 부족한 점을 채워주는 상호보완성이 있기 때문에 선택했다고 말했습니다. </p>\\n<p>즉, 이 둘을 입력데이터로 사용해 얻는 정보의 양이 제일 많다고 판단한 것이죠. </p>\\n<h3 id=\"transfuser\">Transfuser</h3>\\n<p>이제 저자가 생각해낸 모델을 정리해봅시다. </p>\\n<blockquote>\\n<p>입력 데이터로 Single-view image and LiDAR를 받아 특성을 추출하는 과정에서 Transformer를 사용해 전체적인 정보를 고려하는 모델</p>\\n</blockquote>\\n<p>한문장으로 간단히 정리됩니다. 저자는 이렇게 설계된 모델을 <strong>Transfuser</strong>라고 정의했습니다.</p>\\n<p>여기까지 모델의 Introduction 부분이었습니다. 깔끔히 쓰고 싶었는데 쉽지않네요. 허허...</p>\\n<p>그럼 이제 Transfuser가 포함된 자율주행 모델이 만들어지는 과정을 소개한 Method 항목을 소개해 드리도록 하겠습니다. </p>\\n<h2 id=\"method\">Method</h2>\\n<hr />\\n<p>원래 Releated work를 슥 살펴보고 Method로 넘어가야 하는데 그러면 분량이 너무 많아져서 바로 Method로 건너왔습니다. 저도 자율주행 모델에 대해 잘 감이 안잡힌 상태에서 이 논문을 읽어서 Related work 부분이 논문 이해에 꽤나 도움이 되었습니다. 관심 있으신 분들은 따로 찾아서 읽어보시는걸 추천드립니다. </p>\\n<p>아무튼, 이제 Method에 대해 설명해 드리도록 하겠습니다.</p>\\n<p>Method에는 Transformer를 이용해 자율주행 모델을 만드는 일련의 과정이 적혀있습니다. </p>\\n<p>모델을 만드는 과정은 다음과 같이 3단계로 나눌 수 있습니다. </p>\\n<ol>\\n<li>Task 설정, 데이터셋 구성(Problem Setting)</li>\\n<li>데이터셋 전처리(Input and Output Parameterization)</li>\\n<li>모델 설계(Multi-Modal Fusion Transformer + Waypoint Prediction Network)</li>\\n</ol>\\n<p>그러면 \\'Task 설정\\'부터 설명해 드리도록 하겠습니다.</p>\\n<h3 id=\"1-problem-setting\">1. Problem Setting</h3>\\n<p>모델이 해결할 Task를 설정하고 이를 위한 학습법, 그리고 필요한 데이터셋을 설명하는 부분입니다. </p>\\n<p>저자는 <strong>point-to-point navigation</strong>를 모델이 수행할 Task로 설정했습니다. </p>\\n<p>저자는 point to point navigation이 목표지점까지 waypoint를 따라 사고 없이 완주하는 것이라 말했습니다. 여기서 사고는 다른 객체(자동차, 사람 등)과 충돌하거나 교통법규를 어기는 것을 말하죠. </p>\\n<p>그리고 이를 학습하는 방법으로 imitation learning을 선택했습니다. imitation learning이란 강화학습의 일종인데요, 의미 그대로 해당 task에서 전문가(Expert)가 하는걸 따라하는 학습법입니다. </p>\\n<p>강화 학습은 학습 주체인 agent와 agent가 행동하는데 규범이 되는 policy, 행동의 결과인 action, action으로 인한 상태 state, 그리고 state에 대한 보상 reward가 있습니다.여기서 보상 reward를 가장 많이 받는 방향으로 학습시키는 것이 목표죠. </p>\\n<p>reward를 많이 받도록 만드는 방식은 여러가지가 있습니다. 그중 하나가 행동 규범힌 policy를 학습가능한 상태(parameterize)로 만드는 것이죠. </p>\\n<p>imitation learning도 그 방식을 사용하고 있으며 논문에서는 다음과 같이 설명합니다. </p>\\n<blockquote>\\n<p>Policy를 Expert의 policy를 따라하게끔 학습하는 것</p>\\n</blockquote>\\n<p>그런데 여기서 궁금증이 생겼습니다. 왜 imiation learning을 선택한거지? 그래서 찾아봤습니다.<br />\\n찾아보니까 이렇게 policy를 학습 대상으로 삼아 학습시키는 방식은 <strong>고차원 데이터를 처리하고 연속된 action을 해야하는 모델의 학습에 적합</strong>하다고 합니다. </p>\\n<p>이미지라는 고차원 데이터를 처리해 연속된 action이 필요한 운전을 하는 자율주행 모델에 적합한방식이라 선택한게 아닌가 싶습니다. </p>\\n<p>그러면 이제 저자가 imitation learning을 사용한 학습과정을 설명해 드리도록 하겠습니다.</p>\\n<h4 id=\"데이터셋-수집\">데이터셋 수집</h4>\\n<p>우선 데이터셋을 수집해야하죠? 학습을 위한 학습 데이터셋과 평가를 위한 테스트 데이터셋이 필요합니다. </p>\\n<p>데이터셋은 자율주행 오픈소스 시뮬레이터 CARLA(<a href=\"https://carla.org\">https://carla.org</a>)에 있는 가상 환경에서 수집<br />\\n합니다. 별다른 이유는 적지 않았지만 아무래도 사고가 날 수 있는 상황에 대한 데이터도 모으기 때문에 그런게 아닌가 싶네요. </p>\\n<p>여튼, CARLA에 있는 가상환경에서 Expert가 주행하며 데이터를 모읍니다. imitation learning에서 말씀드린 Expert 맞습니다. </p>\\n<p>Expert는 가상환경을 주행하며 입력 데이터와 출력 데이터를 수집합니다. 그렇게 해서<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fbf940494-966f-4a2d-ab3e-15adb7e16afe%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.06.20.png\" /><br />\\n위와 같은 데이터셋 D를 만들어줍니다. </p>\\n<p>여기서 X는 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 한 시점(single time step)에 이미지 한장, point cloud 하나가 있는 것이죠.</p>\\n<p>그리고 W는 T개의 waypoint가 모인 w로 이루어져 있습니다. 즉, 이미지와 point cloud를 하나씩 넣으면 출력값으로 T개의 Waypoint가 나오는 모델을 만들겠다는 뜻이죠.</p>\\n<h4 id=\"학습-방법\">학습 방법</h4>\\n<p>이렇게 데이터셋을 모았으니 학습을 시켜봅시다. 학습 방식은 다음과 같이 정의할 수 있습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F42199532-a602-4a20-89e2-8a21126a3759%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.11.08.png\" /><br />\\n여기서 L은 Loss함수입니다. 그러니까 Expert가 주행한 경로와 우리가 만든 agent의 policy에 따른 action, 다시 말해 <strong>우리가 만든 모델이 예측한 주행 경로 사이의 loss가 최소가 되게끔 policy를 학습시키겠다</strong>는 뜻이죠. </p>\\n<p>저자는 이러한 학습 방식을 지도학습의 방식이라고 말했습니다. Expert의 데이터를 label data, 내가 만든 모델의 데이터가 prediction data라고 보면 저자의 말이 이해가 되시지 않을까 싶습니다. </p>\\n<p>그래서 강화학습은 어떻게 학습 시키는걸까 찾아봤습니다. 강화학습은 데이터셋을 사용하지 않고 학습하기 때문에 매 순간 자기 자신이 만든 state와 reward를 보고 다음 action에 반영하며 점점 높은 reward만 받는 모델로 학습되는 방식을 사용한다는 사실을 알아냈습니다. 지도학습으로만 모델을 학습시켜본 저에게 있어서 강화학습은 상당히 신기한 방식입니다. </p>\\n<h4 id=\"자율-주행\">자율 주행</h4>\\n<p>저자는 학습 이후 어떻게 자율주행에 사용할지도 설명해 주었습니다.<br />\\n저자는 모델이 예측한 경로를 inverse dynamics model에 넣어 얻은 action으로 주행을 한다고 말했고 이 때 inverse dynamics model을 PID controller로 구현했다고 설명했습니다. </p>\\n<p>PID controller는 간단한게 말해 주어진 출력값을 위해 필요한 제어값(가속, 감속, 회전 등)을 구하는 요소라고 보시면 됩니다. 자세한 설명은 <a href=\"https://ko.wikipedia.org/wiki/PID_%EC%A0%9C%EC%96%B4%EA%B8%B0\">여기</a>서 확인하실 수 있습니다. </p>\\n<p>저자는 이러한 과정을 다음과 같은 식으로 나타냈습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fa7c85e89-258f-4110-991f-1a7316121323%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.23.16.png\" /><br />\\naction = PID(예측 경로)인 것이죠. 여기서 action은 agent가 행한 action과 동일한 개념입니다. </p>\\n<h4 id=\"global-planner\">Global planner</h4>\\n<p>마지막에 등장하는 문단인데 처음에는 이게 왜 있는건가 싶었습니다. </p>\\n<p>읽어보니 저자들은 CARLA의 표준 프로토콜을 따르고 목표 지점이 GPS 좌표로 제공되며 목표 지점과 자동차가 안내한 지점이 몇백미터 떨어질 수 있다고 나와있습니다. </p>\\n<p>다른 부분은 그러려니 하고 읽었는데 마지막 부분 \\'목표 지점과 안내 지점이 몇백미터 떨어질 수 있다\\'는 말이 거슬렸습니다. 도대체 뭔 뜻이지? </p>\\n<p>제가 논문 세미나를 할 때 이 논문을 가지고 했는데요, 이에 관해 세미나 계신 분들께 여쭤보고 답을 들었는데도 이해가 제대로 안되서 구글에 검색까지 해봤습니다.</p>\\n<p>구글에 검색을 해보니 다음과 같은 글을 발견했습니다. </p>\\n<blockquote>\\n<p>The global planner plans a global path around obstacles</p>\\n</blockquote>\\n<p>대충 번역하면 장애물을 돌아가는 global path를 생성하는게 global planner라고 하네요. </p>\\n<p>아마 <strong>목표 지점에 가기 힘들면 그 근처로 안내할 수 있음</strong>을 말하고 싶어서 이 부분을 추가한게 아닌가 싶습니다.</p>\\n<p>여기까지 Problem Setting이었습니다.</p>\\n<h3 id=\"2-input-and-output-parameterization\">2. Input and Output Parameterization</h3>\\n<p>이제 데이터셋을 어떻게 만들었는지? 정확히는 모델의 학습에 사용하기 위해 어떤 작업을 했는지 설명해 드리도록 하겠습니다.</p>\\n<h4 id=\"input-representation\">Input Representation</h4>\\n<p>우선 입력 데이터부터 설명해 드리고자 합니다.</p>\\n<p>입력 데이터는 앞서 말씀드렸듯 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 카메라 이미지는 2D 데이터고 Point cloud는 3D 데이터라 각자 처리방식이 다릅니다. </p>\\n<ol>\\n<li>\\n<p>카메라 이미지<br />\\n카메라에서 촬영된 이미지는 400X300 사이즈인데요, 여기서 가운데 256X256 영역만 추출해서 사용합니다. 왜냐하면 렌즈 구조상 외곽 이미지는 왜곡 되어있기 때문입니다. 이렇게 <strong>256X256X3</strong> 사이즈의 데이터를 얻습니다. </p>\\n</li>\\n<li>\\n<p>LiDAR Point Cloud<br />\\n저자는 LiDAR에서 얻은 Point Cloud 중 자동차의 전면 32m, 좌우 측면 각 16m씩 해서 총 32m X 32m 영역만 사용합니다. 그리고 이를 2D 데이터로 변환해주는데요, 한 셀당 0.125m X 0.125m로 해서 256 X 256 픽셀 데이터로 변환해줍니다.<br />\\n그리고 Point Cloud는 3D 데이터라 높이에 관한 데이터도 있는데요, 저자는 이를 2개의 채널에 담았습니다. 하나는 지면 위(+) 높이 데이터, 다른 하나는 지면 밑(-) 높이 데이터를 담았죠.<br />\\n이렇게 <strong>256X256X2</strong> 사이즈의 데이터를 얻습니다.</p>\\n</li>\\n</ol>\\n<h4 id=\"output-representation\">Output Representation</h4>\\n<p>출력값 양식을 정의하는 부분입니다. </p>\\n<p>출력값, 즉 waypoint는 BEV space에서 (x,y)의 양식을 지닙니다. </p>\\n<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F143364fc-ea4f-4738-8c28-ad2d826983ed%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.59.06.png\" /><br />\\n이런 방식으로 나온다는 뜻이죠. 중심에 자동차가 있고 앞에 빨간 점으로 자동차가 이동할 waypoint가 나와 있습니다. 이 때 waypoint의 집합 trajectory는 다음과 같이 정의됩니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fe1e69200-2870-4820-87fb-71022c6b7fa2%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%2010.05.40.png\" /></p>\\n<p>앞서 데이터셋을 구성할 때 T개의 waypoint 예측값이 모인 데이터셋을 만든다고 말씀드렸는데요, 저자는 T를 4로 정의했습니다. 왜 T를 4로 정의했냐면 예측 궤적을 가기 위한 제어값을 얻는 PID controller가 요구하는 waypoint의 default number가 4라서 T를 4로 설정했다고 말했습니다.</p>\\n<p>여기까지 Input and Output Parameterization였습니다. </p>\\n<h3 id=\"3-모델-설계\">3. 모델 설계</h3>\\n<p>다음으로 모델의 구조에 대해 설명해 드리고자 합니다. </p>\\n<p>모델의 구조는 크게 두 가지로 나눌 수 있습니다. 하나는 <strong>Multi-Modal Fusion Transformer</strong>고 다른 하나는 <strong>Waypoint Prediction Network</strong>입니다. </p>\\n<p>Multi-Modal Fusion Transformer는 저자가 새로운 제안한 Transfuser를 말하는 것이구요, Waypoint Prediction Network는 Transfuser에서 얻은 값을 가지고 경로를 예측하는 모델입니다. </p>\\n<p>우선 Transfuser부터 먼저 설명해 드리도록 하겠습니다. </p>\\n<h4 id=\"1-multi-modal-fusion-transformertransfuser\">1. Multi-Modal Fusion Transformer(Transfuser)</h4>\\n<p>Transfuser는 다음과 같은 구조를 가지고 있습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F98673fc0-6990-40b0-869c-3052443d7086%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.46.13.png\" /><br />\\n제가 Trnafuser는 특성을 추출하는 과정에서 Transformer를 이용해 전체 데이터를 고려하는 모델이라고 말씀드렸는데요, 이 그림을 보시면 \"아...이런 뜻이구나\" 이해하시지 않을까 싶습니다. </p>\\n<p>여기서 눈여겨볼 항목은 당연히 저자가 강조한 Transformer를 이용해 전체 데이터 정보를 각 특성맵에 반영해주는 부분입니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F09f43877-9853-4ba7-8912-21a2f59d9700%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.51.55.png\" /> <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F9faf9fb5-3e84-4ddd-9beb-79600e08b92f%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.55.19.png\" /><br />\\n이 부분을 말하는 것이죠. 아래 그림은 윗 그림에서 Transformer 부분을 강조한 그림입니다.</p>\\n<p>여기서 진행되는 연산의 순서를 말씀드리면 다음과 같습니다. </p>\\n<ol>\\n<li>Conv + Pool 연산으로 특성맵 추출</li>\\n<li>추출한 특성맵의 사이즈를 8 X 8로 압축 후 Transformer에 입력값으로 보냄</li>\\n<li>각 데이터에서 보내준 8 X 8 크기의 특성맵 2개를 합체 = 16 X 8 사이즈의 특성맵 생성</li>\\n<li>16X8 벡터를 Positional Embedding 후 Linear layer를 이용해 자동차의 현재 속도를 Embedding vector에 projection</li>\\n<li>Transformer에 넣어 self-attention 연산 =&gt; Embedding vector내 원소별로 전체 데이터(이미지 + LiDAR)에 대한 Attention이 반영됨. 사이즈는 16 X 8로 같음</li>\\n<li>Attention이 반영된 Embedding vector를 Image, LiDAR별로 나눔 -&gt; 8 X 8 사이즈의 벡터가 2개 생성</li>\\n<li>8 X 8 사이즈의 벡터를 압축하기 전의 크기로 scale up </li>\\n<li>원래 특성맵과(1에서 추출한 특성맵) element-wise summation(원소끼리 더함)</li>\\n</ol>\\n<br />\\n<p>코드로 나타내면 상당히 간단해집니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Ff0cdda7c-89a7-4c60-8d4d-4e8d4826652d%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.09.01.png\" /><br />\\n아무튼 간단해집니다. </p>\\n<p>여튼, 이런 과정을 총 4번 반복합니다. 더 해도 안된다는 법은 없는데 저자는 4번 반복하라고 말했습니다. </p>\\n<p>4번 반복한 뒤 마지막에 Average Pooling + Flatten연산을 해서 1 X 1 X 512 벡터를 2개 생성합니다. 이미지에서 얻고 LiDAR에서 얻으니까 총 2개를 얻는 것이죠. </p>\\n<p>이 2개의 벡터를 element-wise summation해서 하나의 1 X 1 X 512 벡터로 만들어줍니다. </p>\\n<p>이렇게 우리는 최종 출력값 1 X 1 X 512 벡터를 얻었습니다. 이제 Waypoint Prediction Network를 확인해보도록 합시다. </p>\\n<h4 id=\"2-waypoint-prediction-network\">2. Waypoint Prediction Network</h4>\\n<p>앞서 우리는 Transfuser에서 1 X 1 X 512 사이즈의 벡터를 얻었습니다. </p>\\n<p>이 벡터는 Waypoint Prediction Network에 쓰입니다. </p>\\n<p>Waypoint Predictoin Network는 다음과 같은 구조를 가지고 있습니다. </p>\\n<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fe2a83385-fdf5-4e03-9f20-8ae87396a950%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.47.15.png\" /></p>\\n<p>보시면 MLP와 GRU로 이루어졌다는 사실을 확인하실 수 있습니다. </p>\\n<ol>\\n<li>\\n<p>MLP<br />\\nMLP는 3개의 Linear Layer로 이루어져 있습니다. MLP는 입력값으로 들어오는 1 X 1 X 512 사이즈의 벡터를 1 X 1 X 64 벡터로 압축해줍니다. 계산의 효율성을 위해 줄여주는 겁니다.<br />\\n코드는 다음과 같습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fcd1db45c-1c0c-4fe5-b9bc-64866cb05b21%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.20.57.png\" /></p>\\n</li>\\n<li>\\n<p>GRU<br />\\nGRU는 RNN에서 많이 쓰였던 LSTM을 개선한 알고리즘 입니다. 시계열 데이터를 처리하는데 적합한 알고리즘이죠. 이걸 레이어 형식으로 추가했습니다.<br />\\nGRU는 현 시점의 입력 데이터와 hidden state를 받아 연산을 처리합니다. waypoint prediction network에서는 자동차의 좌표와 목표 지점의 좌표를 더한 값을 입력 값으로 하였습니다. 이 때 좌표의 단위는 gps입니다.<br />\\n여기서 흥미로운 점이 있습니다. 바로 첫 시점의 입력 데이터 중 자동차의 좌표가 (0,0)이라는 점입니다. 이는 자동차가 좌표계의 원점에 있다고 가정했기 때문입니다.<br />\\n그러니까 <strong>입력 데이터를 넣는 시점에서 자동차의 위치가 x = (0,0)에 있다고 보는 것이고 (0,0)를 기준으로 향후 4 time의 waypoint를 예측하는 것</strong>이라 보시면 되겠습니다.<br />\\n다시 본론으로 돌아옵시다. 입력 데이터를 알아봤으니 이제 hidden state로 넘어가야죠. hidden state는 앞서 얻은 1 X 1 X 64 벡터로 초기화해줍니다. 우리가 입력 데이터로 얻은 특성을 hidden state를 초기화하는데 사용하는 겁니다.<br />\\n이렇게 입력값을 넣어주면 출력값이 나올겁니다. 이 출력값을 Linear layer에 넣으면 현 시점의 자동차에서 움직여야할 좌표 dx가 생성됩니다.<br />\\n이 dx에 기존 자동차의 좌표 x에 더하면 이제 다음 시점에 이동할 waypoint가 되는 겁니다.<br />\\n이 waypoints는 다음 시점에서 현재 좌표가 되겠죠? next_x = x + dx인 겁니다.<br />\\n여튼 이 과정을 4번 반복해 waypoint 4개를 얻습니다.</p>\\n</li>\\n</ol>\\n<h4 id=\"plus--pid-controller\">Plus : PID controller</h4>\\n<p>모델의 구조에는 없지만 자율주행을 수행하기 위해 꼭 있어야할 PID controller입니다.<br />\\n앞서 예측한 경로를 PID controller에 넣어 주행에 필요한 제어값을 얻는다고 말씀드렸습니다.<br />\\n실은 그 이상으로 설명드릴게 없습니다. 그러니 여기서는 구현된 코드를 보여드리고 넘어가도록 하겠습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F3fa43398-54ed-4ef2-ac1d-9e34b8896814%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.57.46.png\" /><br />\\n코드의 return 부분을 보시면 운전에 필요한 데이터들이 나와있습니다. steer는 차를 얼마나 회전할지 나타낸거고 throttle는 엔진에 들어갈 공기량을 제어하니까 가속을 얼마나 할지 나타낸거고 brake는 감속을 얼마나 할지 나타내는 것이죠. </p>\\n<p>그런데 낯선 데이터가 하나 있습니다. 바로 metadata입니다. 슥 살펴보니 steer, throttle, brake만으로 설명이 안되는 정보를 보충 설명해주는 데이터인듯 합니다. 아마 저자가 실험했을 때 제어값의 정보 부족으로 좀 애먹었던게 아닌가 싶네요. 제 추측입니다. </p>\\n<p>여기까지 모델의 구조를 살펴봤습니다. </p>\\n<h2 id=\"experiment\">Experiment</h2>\\n<hr />\\n<p>이제 실험 부분을 설명해 드리고자 합니다. </p>\\n<p>여기서는 실험 세팅(experimental setup), 성능 비교(Results), 입력 데이터간 상호보완성 비교(Attention Map Visualizations), 구성 요소를 하나씩 빼면서 성능 확인(Ablation Study) 순으로 내용이 전개됩니다. </p>\\n<h3 id=\"1-실험-세팅experimental-setup\">1. 실험 세팅(experimental setup)</h3>\\n<p>여기서는 성능 측정을 위해 모델이 해야할 task와 이를 위해 필요한 데이터셋, 평가 지표와 성능을 비교할 모델을 소개하고 있습니다. </p>\\n<h4 id=\"task\">Task</h4>\\n<p>모델이 수행할 task는 다양한 주행 환경에서 제한 시간 안에 운전 규정을 시키며 주행하는 것입니다. </p>\\n<p>여기서 주행 경로는 gps좌표 형식의 waypoint의 집합으로 제공되며 주행 도중에 일정 확률로 자동차나 보행자가 등장할 수 있고 차선 변경, 회전 등 주행 중에 충분히 일어날 수 있는 상황도 경로에 포함되어 있습니다. </p>\\n<p>앞서 논문에서 말한 \\'복잡한 운전 상황\\'속 주행 성능을 평가하는거라 생각하시면 됩니다. </p>\\n<h4 id=\"dataset\">Dataset</h4>\\n<p>데이터셋을 모으는 방법이 적혀있습니다. </p>\\n<p>앞서 말씀드렸듯 Expert가 CARLA에 있는 가상환경에서 주행하며 데이터를 모은다고 말씀드렸습니다. 여기서 더 자세히 써보도록 하겠습니다. </p>\\n<p>CARLA에는 주행을 할 수 있는 8개의 Town이 있습니다. 8개의 가상환경이 있는 것이죠. 각 town의 특성은 다음과 같습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Ff9052600-3c62-40b6-bea6-c9dfb0c40ade%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%207.26.46.png\" /><br />\\n각자 특성을 가지고 있죠. Expert는 여기서 Town 01, 02, 03, 04, 06, 07, 10에 사전 정의된 경로들을 달리며 학습용 데이터셋을 수집합니다. </p>\\n<p>그리고 학습용 데이터셋으로 모델을 훈련시키고 난 뒤 Town05에서 주행 성능을 평가합니다. </p>\\n<p>Town05는 1차선부터 n차선, 그리고 일반도로부터 고속도로까지 다양한 도로가 있기 때문에 주행 성능을 평가하는 맵으로 선정했다고 말했습니다. </p>\\n<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F7fe65901-ef85-46ef-b802-861ba297b5e9%2FTown05.jpg\" /><br />\\nTown05에 깔려있는 도로를 나타낸 사진입니다. 다양한 도로로 구성되어 있음을 확인할 수 있습니다. </p>\\n<p>저자는 어떠한 주행 경로에서 성능을 평가하는지도 설명했습니다. 저자는 단거리 경로와 장거리 경로를 각 10개씩 뽑았고 이를 Town05 Short, Town05 Long이라 이름 지었습니다. 특징은 다음과 같습니다.</p>\\n<ul>\\n<li>Town05 Short : 주행 거리 100~500m, 교차로 3개</li>\\n<li>Town05 Long : 주행거리 1~2km, 교차로 10개</li>\\n</ul>\\n<p>그리고 주행 중에 자동차나 사람이 등장할 수 있다는 공통점이 있습니다. </p>\\n<p>마지막으로 날씨입니다. 맑은 날 주행하는거랑 비오는 날에 주행하는건 난이도가 어느정도 차이가 나는데요, 저자는 <strong>동적인 객체와 신호등에 대한 주행 성능 평가에 집중할 것이기 때문에</strong> 날씨는 \\'항상 맑음\\'으로 고정한다고 말했습니다. </p>\\n<p>개인적으로 아쉬운 부분이었습니다. 날씨도 변수를 줘서 실험을 했으면 더 좋지 않았을까 생각합니다. </p>\\n<h4 id=\"metrics\">Metrics</h4>\\n<p>구글에 검색해보니 \\'측정 수단\\'이라는 뜻으로 해석됩니다. 즉, 평가지표입니다. </p>\\n<p>저자는 평가 지표로 RC, DS, Infraction Count를 선택했습니다. 하나씩 설명해 드리도록 하겠습니다. </p>\\n<ol>\\n<li>RC(Route Completion) : 주행 경로를 몇%나 주행했는지 나타내는 수치입니다. </li>\\n<li>DS(Driving Score) : RC에 infraction multiplier를 곱한 값입니다. 여기서 infraction multiplier는 객체와의 충돌, 경로 이탈, 차선 침법, 신호 위반을 설명하는 수치라고 합니다. </li>\\n<li>Infraction Count : 따로 설명은 해놓지 않았지만 사고 종류별 발생 횟수를 측정한게 아닐까 싶습니다. </li>\\n</ol>\\n<h4 id=\"baselines\">Baselines</h4>\\n<p>Transfuser가 포함된 자율주행 모델과 성능을 비교할 모델을 적어놓았습니다. 5개의 모델과 비교합니다. </p>\\n<p>모델 종류는 다음과 같습니다. </p>\\n<ul>\\n<li>CILRS : 카메라 이미지만 입력값으로 받으며 navigational command의 통제 아래 자율주행을 수행합니다. </li>\\n<li>LBC : 원래 Bird\\'s view image와 front image를 받았는데 논문(LBC)의 저자가 왼쪽 45도, 오른쪽 45도 각도에서 찍은 전면 카메라 이미지와 target heatmap을 입력값으로 받는걸로 바꿨습니다. </li>\\n<li>AIM : 전면 카메라 이미지만 입력데이터로 받습니다. 단일 입력값을 받는 모델 중 가장 성능이 좋습니다. </li>\\n<li>Late Fusion : 이제부터 두가지 입력값을 함께 처리하는 모델입니다. Late Fusion은 image와 LiDAR에서 얻은 값을 각각 Convolution Layer로 특성맵을 뽑아낸 후 element-wise summation해줍니다. </li>\\n<li>Geometric Fusion : image와 LiDAR에서 얻은 값을 각각 Convolution Layer로 특성맵을 뽑을 때마다 서로 projection해 서로의 정보를 반영합니다. 이렇게 뽑은 두 특성맵을 element-wise summation 해줍니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fde2f3a7e-32cc-4294-8330-9be27248df91%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%209.41.56.png\" /><br />\\n위 사진은 구현코드입니다. 보시면 각자 특성을 추출 후 서로 projection하는걸 확인하실 수 있습니다. </li>\\n</ul>\\n<h3 id=\"2-실험-결과results\">2. 실험 결과(Results)</h3>\\n<p>실험 결과는 다음과 같습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F38b6e380-d752-4841-bac0-409e94f3ee8d%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%209.45.13.png\" /><br />\\n왼쪽 사진은 Short, Long 경로에서 모델별 RC, DS를 나타낸거고 오른쪽 사진은 사고율을 나타낸 겁니다. </p>\\n<h4 id=\"driving-performance\">Driving Performance</h4>\\n<p>우선 왼쪽 표에 대해서 설명을 해드리도록 하겠습니다. </p>\\n<p>여기서 눈여겨볼 부분은 한가지 입력값을 받는 CILRS, LBC, AIM보다 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능이 더 좋다는 겁니다. 두가지 입력값을 쓰기만 해도 한가지 입력값을 쓰는 것보다 성능이 좋다는 사실을 알 수 있습니다. </p>\\n<p>그리고 또다시 눈여겨볼 부분은 Transfuser가 Late Fusion, Geometric Fusion보다 RC는 낮은데 DS가 높다는 것입니다. 즉, Transfuser는 주행 거리는 짧지만 안전운전을 더 잘한다는 뜻이죠. </p>\\n<p>저자는 이를 보고 \\'Late Fusion, Geometric Fusion는 안전하게 운전하는 것보다 목표 지점에 가는데 중점을 뒀기 때문에 이런 결과가 나왔다\\'고 말했습니다. </p>\\n<p>그리고 Expert의 점수도 나와있는데요, Expert도 장거리 운전에서는 그리 좋지 못한 성적을 얻었습니다. 신기합니다. </p>\\n<h4 id=\"infraction\">Infraction</h4>\\n<p>모델별 평균 사고율이 나옵니다. 초록색 막대가 Transfuser인데요, 모든 사고 항목에서 가장 낮습니다. 그런데  빨간불 신호 위반에서 다른 모델보다 낮긴 하지만 그래도 다른 사고 항목에 비하면 굉장히 높은 수치를 보입니다. 왜 그런걸까요? </p>\\n<h4 id=\"limitations\">Limitations</h4>\\n<p>여기선 모델의 한계점에 대해 저자가 얘기하는 부분입니다. 저자는 모델의 한계점으로 <strong>빨간불 신호 위반의 확률이 높은 것</strong>을 꼽았습니다. </p>\\n<p>높은 신호위반 확률을 보이는 이유는 성능 평가를 위해 주행하던 경로에서 신호등이 카메라 구석에 찍혔는데 이 때문에 신호등의 빨간 불빛을 감지하기가 힘들어 빨간불에서 정차하지 않고 주행하는 일이 많았다고 합니다. </p>\\n<p>그리고 이러한 문제를 해결할 additional supervision을 기대해본다고 말했습니다. </p>\\n<h3 id=\"3-attention-map-visualizations\">3. Attention Map Visualizations</h3>\\n<p>여기서는 카메라 이미지와 LiDAR point cloud간 상호보완성을 보여줍니다. </p>\\n<p>어떻게 보여주냐면 교차로에서 신호대기중인 차량에서 얻은 이미지, Point cloud를 Transfuser로 특성을 추출하는 과정에서 self-attention을 통해 나온 16X8 사이즈의 벡터를 통해 설명합니다.</p>\\n<p>여기서 반은 이미지쪽 벡터고 나머지 반은 LiDAR쪽 벡터입니다. 여기서 각각 자동차와 신호등에 대한 정보가 담긴 부분만 추출해 서로 얼마나 attention을 했는지 확인해봅니다. attention이 반영된 정도는 각 요소별 곱해진 score를 보고 알 수 있죠. </p>\\n<p>그렇게 attention된 정도를 확인한 결과, 다음의 사실을 알 수 있었습니다. </p>\\n<ul>\\n<li>이미지 토큰의 62.75%가 attention을 가장 많이 한 5개의 token이 LiDAR에서 나온 토큰</li>\\n<li>LiDAR 토큰의 78.45%가 attention을 가장 많이 한 5개의 token이 이미지에서 나온 토큰</li>\\n</ul>\\n<p>여기서 토큰은 transformer에 입력값으로 들어가는 데이터 단위를 말합니다. 출력값 역시 토큰의 집합이죠. 토큰을 데이터로 바꾼 뒤 읽으셔도 의미의 차이는 없을듯 합니다. </p>\\n<p>아무튼, 이렇게 서로 상호보완하는 부분이 많습니다. 특성을 추출할 때 상대 데이터를 많이 고려한다는 뜻이죠. </p>\\n<h3 id=\"4-ablation-study\">4. Ablation Study</h3>\\n<p>여기서는 Transfuser의 Transformer에 대해 값을 수정해가며 성능의 변화를 관측한걸 얘기합니다. 저자는 Town05 Short에서 성능 평가를 했는데요, 성능표는 다음과 같았습니다.<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F3060d95b-e30f-41f8-a83b-b79cf1877329%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%2011.02.23.png\" /><br />\\n하나씩 설명해드리도록 하겠습니다. </p>\\n<ol>\\n<li>Scale : Transformer 이후 Fusion 횟수를 나타냅니다. 원래 4번 Fusion했는데 이 횟수를 줄여보며 성능을 비교해봤습니다. Scale이 1이면 마지막에 추출한 feature map(8X8X512)에서만 fusion하고 2면 16X16X256 feature map과 8X8X512 feature map에서 fusion하는거죠. </li>\\n<li>Shared Transformer : 원래 각 사이즈의 특성맵마다 다른 Transformer를 사용합니다. 그러면 모든 특성맵에서 다같은 Transformer를 사용하면 어떻게 될까요? 성능이 떨어졌습니다. 저자는 각 convolution layer에서 얻은 특성맵이 갖고 있는 성질이 다 다르기 때문에 각기 다른 Transformer에서 처리해야 한다고 말했습니다.(different convolutional layers in ResNet learn different types of features due to which each transformer has to focus on fusing different types of features)</li>\\n<li>Attention layers : 원래 각 Transfomer에는 8개의 Attention layer가 있습니다. 이를 1개, 4개로 만든 뒤 성능을 측정해봤습니다. </li>\\n<li>No Pos. Embd : Transformer에 넣기전에 Positional Embedding을 안했을 경우입니다. </li>\\n</ol>\\n<p>이렇게 각 요소를 제거한 뒤 성능을 비교했습니다. Scale을 제외한 나머지 부분에서 하나의 공통점이 있는데요, 바로 RC는 증가하지만 DS가 떨어졌다는 점입니다. </p>\\n<p>저자는 이를 보고 \\'Attention횟수가 많아질 수록 더 조심히 운전하게 된다\\'고 말했습니다. </p>\\n<h2 id=\"conclusion\">Conclusion</h2>\\n<hr />\\n<p>논문의 결말입니다. 저자는 앞서 말한 것을 conclusion에서 총체적으로 정리했습니다. 그리고 마지막에 자신들이 만든 모델에 다른 센서의 입력값을 추가해서 쓰거나 다른 AI task에 사용할 수 있다고 말하며 논문을 끝냈습니다.<br />\\n<br /></p>\\n<h2 id=\"후기\">후기</h2>\\n<hr />\\n<p>이렇게 길고 긴 논문 리뷰가 끝났습니다. 최선을 다해 리뷰해봤는데 미숙한 부분이 많았습니다. 이런식으로 데이터를 받아서 처리하는 모델도 처음 접했고 자율주행 task를 수행하는 모델도 처음이라 읽는데 많은 시간이 걸렸습니다. 그래도 리뷰하고 나니 뿌듯하네요. </p>\\n<p>3주 뒤에 다른 논문을 세미나에서 발표하는데 그 논문도 velog에 올릴 계획입니다. 개강이 얼마 남지 않은 시기라 쓰기 힘들겠지만 하...할 수 있겠죠? </p>\\n<p>마지막으로 제가 이 논문을 읽고 느낀점을 쓰고자 합니다. 제가 느낀 점은 다음과 같습니다.</p>\\n<ul>\\n<li>\\n<p>두 종류의 입력값을 특성 추출 과정에서 반영함으로써 안전한 운전을 구현했다는 사실이 흥미로웠다.</p>\\n</li>\\n<li>\\n<p>허나 Transformer가 전체 입력값을 모두 고려하며 계산하기 때문에 연산량이 좀 많을텐데 실시간으로 판단이 필요한 운전에서 이런 점이 부담이 되지 않을까 싶다.</p>\\n</li>\\n<li>\\n<p>추후 주행 속도도 개선하며 안전운전을 추구하는 모델이 나왔으면 좋겠다.</p>\\n</li>\\n</ul>\\n<p>그리고 제가 이걸 세미나에서 발표했을 때 교수님께서 \"꼭 두가지 데이터를 사용했어야 했을까, LiDAR에서 얻은 정보를 사용할 때 2D 데이터로 변환하는 과정에서 많은 데이터 손실이 있을텐데 그걸 감수하면서까지 사용할 이유가 있을지 모르겠다, 차라리 시야각이 넓은 이미지를 사용하면 데이터 손실도 없이 사용할 수 있지 않을까\" 라고 저에게 말씀하셨습니다. </p>\\n<p>실은 저는 입력값에 대한 어떠한 의문도 가지지 않았는데 교수님의 말씀을 듣고 의문이 들었습니다. 실제로 표를 봤을 때<br />\\n<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fd919d9ce-64eb-4d23-9e83-c67e9f7b4ca7%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.06.23.png\" /><br />\\n여기 보시면 한가지 입력값만 받는 AIM과 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능차이가 크게 없다는 사실을 확인할 수 있습니다. 물론 장거리 주행에서는 DS에서 차이가 나긴 하지만 다들 점수가 낮기 때문에 큰 상관은 없다고 생각합니다. </p>\\n<p>아무튼, 많은 공부가 되었고 재밌게 읽은 논문이었습니다. 다음 논문 리뷰에서 뵙겠습니다!</p></div></div></div><div class=\"sc-dvQaRk ijHvhk sc-gfqkcP hpspee\"><div class=\"sc-TBWPX ePkhDB\"><div class=\"sc-jIkXHa iQZhhJ\"><a href=\"/@minkyu4506\"><img src=\"https://velog.velcdn.com/images/minkyu4506/profile/3d19426f-f141-4188-b23a-254ce14fce5a/Untitled.png\" alt=\"profile\"/></a><div class=\"sc-ZOtfp eYREua\"><div class=\"name\"><a href=\"/@minkyu4506\">Minguinho_zeze</a></div><div class=\"description\">안녕하세요. 딥러닝 알고리즘에 관심이 많은 학부생입니다. </div></div></div><div class=\"sc-jOxtWs fWmBKb\"></div><div class=\"sc-hmjpVf fBgOP\"><a href=\"https://github.com/MinkyuKim26\" target=\"_blank\" rel=\"noopener noreferrer\" data-testid=\"github\"><svg width=\"20\" height=\"20\" fill=\"currentColor\" viewBox=\"0 0 20 20\"><mask id=\"github\" width=\"20\" height=\"20\" x=\"0\" y=\"0\" maskUnits=\"userSpaceOnUse\"><path fill=\"#ffffff\" fill-rule=\"evenodd\" d=\"M6.69 15.944c0 .08-.093.145-.21.145-.133.012-.226-.053-.226-.145 0-.081.093-.146.21-.146.12-.012.226.053.226.146zm-1.255-.182c-.028.08.053.173.174.198.105.04.226 0 .25-.081.024-.08-.053-.173-.174-.21-.104-.028-.221.012-.25.093zm1.783-.068c-.117.028-.198.104-.186.197.012.08.117.133.238.105.117-.028.198-.105.186-.186-.012-.076-.121-.129-.238-.116zM9.87.242C4.278.242 0 4.488 0 10.08c0 4.471 2.815 8.298 6.835 9.645.516.093.697-.226.697-.488 0-.25-.012-1.63-.012-2.476 0 0-2.822.605-3.415-1.202 0 0-.46-1.173-1.121-1.475 0 0-.924-.633.064-.621 0 0 1.004.08 1.557 1.04.883 1.557 2.363 1.109 2.94.843.092-.645.354-1.093.645-1.36-2.255-.25-4.529-.576-4.529-4.455 0-1.109.307-1.665.952-2.375-.105-.262-.448-1.342.105-2.738C5.56 4.157 7.5 5.51 7.5 5.51a9.474 9.474 0 0 1 2.532-.344c.86 0 1.726.117 2.533.343 0 0 1.939-1.355 2.782-1.089.552 1.4.21 2.476.105 2.738.645.714 1.04 1.27 1.04 2.375 0 3.891-2.375 4.202-4.63 4.456.372.319.686.923.686 1.87 0 1.36-.012 3.041-.012 3.372 0 .262.186.58.698.488C17.266 18.379 20 14.552 20 10.08 20 4.488 15.464.24 9.871.24zM3.919 14.149c-.052.04-.04.133.029.21.064.064.157.093.21.04.052-.04.04-.133-.029-.21-.064-.064-.157-.092-.21-.04zm-.435-.326c-.028.052.012.117.093.157.064.04.145.028.173-.028.028-.053-.012-.117-.093-.158-.08-.024-.145-.012-.173.029zm1.306 1.435c-.064.053-.04.174.053.25.092.093.21.105.262.04.052-.052.028-.173-.053-.25-.088-.092-.21-.104-.262-.04zm-.46-.593c-.064.04-.064.146 0 .238.065.093.174.133.226.093.065-.053.065-.157 0-.25-.056-.093-.16-.133-.225-.08z\" clip-rule=\"evenodd\"></path></mask><g mask=\"url(#github)\"><path fill=\"currentColor\" d=\"M0 0h20v20H0z\"></path></g></svg></a><a href=\"https://twitter.com/minguinho_zeze\" target=\"_blank\" rel=\"noopener noreferrer\" data-testid=\"twitter\"><svg width=\"32\" height=\"32\" fill=\"none\" viewBox=\"0 0 32 32\"><g clip-path=\"url(#twitter)\"><path fill=\"currentColor\" d=\"M32 6.076a13.108 13.108 0 0 1-3.77 1.033 6.576 6.576 0 0 0 2.886-3.632 13.151 13.151 0 0 1-4.17 1.594 6.554 6.554 0 0 0-4.791-2.074c-4.239 0-7.354 3.955-6.396 8.06C10.304 10.784 5.467 8.171 2.228 4.2a6.574 6.574 0 0 0 2.03 8.765 6.538 6.538 0 0 1-2.971-.821c-.072 3.041 2.108 5.886 5.265 6.52-.924.25-1.936.309-2.965.112a6.57 6.57 0 0 0 6.133 4.558A13.2 13.2 0 0 1 0 26.053a18.585 18.585 0 0 0 10.064 2.95c12.19 0 19.076-10.295 18.66-19.528A13.366 13.366 0 0 0 32 6.076z\"></path></g><defs><clipPath id=\"twitter\"><path fill=\"#fff\" d=\"M0 0h32v32H0z\"></path></clipPath></defs></svg></a><a href=\"mailto:minkyu4506@gmail.com\"><svg width=\"32\" height=\"32\" fill=\"none\" viewBox=\"0 0 32 32\" data-testid=\"email\"><path fill=\"currentColor\" d=\"M16 16.871L1.019 5H30.98L16 16.871zm0 3.146L1 8.131V27h30V8.131L16 20.017z\"></path></svg></a></div></div></div><div class=\"sc-dvQaRk ijHvhk sc-fTQvRK eMFVHd\"><div class=\"sc-bUhFKy cOfbyG\"><a class=\"sc-lhMiDA gkzonb\" href=\"/@minkyu4506/Faster-R-CNN-리뷰-with-Code\"><div class=\"sc-hJhJFJ crTinq\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 24 24\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M20 11H7.83l5.59-5.59L12 4l-8 8 8 8 1.41-1.41L7.83 13H20v-2z\"></path></svg></div><div class=\"sc-cvlWTT lasECz\"><div class=\"description\">이전<!-- --> 포스트</div><h3>[논문리뷰]Faster R-CNN 리뷰 + 코드구현(TensorFlow2)</h3></div></a></div><div class=\"sc-bUhFKy cOfbyG\"><a class=\"sc-lhMiDA jOoREI\" href=\"/@minkyu4506/YOLO-v1-리뷰-코드-구현tensorflow2\"><div class=\"sc-hJhJFJ NTSqV\"><svg stroke=\"currentColor\" fill=\"currentColor\" stroke-width=\"0\" viewBox=\"0 0 24 24\" height=\"1em\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M12 4l-1.41 1.41L16.17 11H4v2h12.17l-5.58 5.59L12 20l8-8z\"></path></svg></div><div class=\"sc-cvlWTT cQnPYI\"><div class=\"description\">다음<!-- --> 포스트</div><h3>[논문리뷰] YOLO v1 리뷰 + 코드 구현(TensorFlow2)</h3></div></a></div></div><div class=\"sc-dvQaRk ijHvhk sc-hKTqa iA-dFHq\"><ins class=\"adsbygoogle\" style=\"display:block;text-align:center\" data-ad-layout=\"in-article\" data-ad-format=\"fluid\" data-ad-client=\"ca-pub-9161852896103498\" data-ad-slot=\"6869845586\"></ins></div><div class=\"sc-dvQaRk ijHvhk sc-edERGn ewkRvR\"><h4>1<!-- -->개의 댓글</h4><div class=\"sc-jlsrNB\"><div class=\"sc-iWBNLc ioCAmf\"><textarea placeholder=\"댓글을 작성하세요\" class=\"sc-hYQoXb jjhhWc\" style=\"height:0\"></textarea><div class=\"buttons-wrapper\"><button color=\"teal\" class=\"sc-jrQzAO hSMJOX\">댓글 <!-- -->작성</button></div></div><div class=\"sc-gnnDb jGGkyw\"><div class=\"sc-fydGpi\"><div class=\"sc-cVAmsi eAtqhB comment\"><div class=\"sc-kHxTfl iNiviY\"><div class=\"profile\"><a href=\"/@nopannogain\"><img src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAASbSURBVHgB7Z0tTytBFIYP914BDiQ4cIADB0EhwYFE8ifq7g/hJ2CRSCQ4kOCobF3ruHk3maS5aSnbdnfPOe/7JE0oCTvTnmc+dvbMsNbr9b5M0PLLBDUSgBwJQI4EIEcCkCMByJEA5EgAciQAORKAHAlAjgQgRwKQIwHIkQDkSAByJAA5EoAcCUCOBCBHApAjAciRAORIAHIkADkSgBwJQI4EIEcCkCMByJEA5EgAciQAOX+MhPX1dTs+Prbt7W3b3d21jY2N6ndgPB7bYDCw4XBor6+v9vHxUb1nIL0Ae3t7dn5+XgV9FhABYuC1v79f/Q4SPD8/28vLi2UmrQA/Cfx34O/wwjXu7u7S9gi/z87O/loyELTr62vb2tqyZcFQcXp6Wv2MXiEb6SaBCDwEWDVFqmykEgABOjo6sqbAtbNJkEaAi4uLRoNfQBmXl5eWhRQCIChlnG6Dk5OTVstrkvACYKLXxJg/D5RZ1hEiE14ABGIVs/26IPgZeoHQAiDwbYz7s4AA0XuB0AIsusizKsrycmRCC+Dhyz84OLDIhBUAra/rHgCgDpGHgbAC7OzsmBc81aUuYQXY3Nw0L3iqS13CCtDFrd8sPNWlLsoIIkcCkBNWAE8JGpGTRcIKgPw9L3iqS13CCvD5+Wle8FSXuoQVAJm8HlK0UAfUJSqhJ4Fvb2/WNcgcjkxoAfDld936oieKhhYAwX96erKuwJ6B6Oni4dcBIEAXvQAC//j4aNEJLwCC30UgUGaGzSIpVgLRC7Q5FKCsLFvG0iwFPzw8tBIUlIGyspDqWcD9/X2jEuDaKCMT6R4GIUBNzAlwzWzBByl3ByNYaK23t7dLP6vHfT6u9/7+bhlZ6/V6X5YYpI0jebRu/mD2wBfSHxCBngAv9ASQ4PDwsErhwvvJE0JGo1EV9H6/72KFsS1SCDAZyFngnh2vVUwSUV4WQUILULZnlR06aMGYqDW1QDN56khZho6+Ghh2DoBgXF1dTZ3koZWvcqWubECdtg0NZUQ+QiakAGjxOA9gHhABj4wXeWyMHgX5/j85Zwi9AXoeD4+n6xJOAASk7nbwkjyCGT0meXg/mcWDYOMsIJwShtaO3mWRHT/odaINCaHmAIsEHyCQOP6tHAHXFKVukSQIsxK4aPDbBnWMdG5ACAHwhUYIfgHzEwwjEXAvQFdHwCzLzc1NiC1jrgXA2I31/Ijbr1HnCEfKuRagq/N/VgXuJLzPB9wKgMBnOITJu8RuBUDXnwHvQ4FLAbDkGrnr/x8MBV7vClwKEHHWPw+vn8mdANlaf8FrL+BOgIytv+Dxs7kSAC0kY+sveOwFXAnQ5bGvbdH0A6m6uBLAw8GPTePtaFk3AmTv/gtYF/A0DLgRgKH1Fzx9VjcCIBuHBU89nRsBkKrFgqfNJm5SwpBGVc7fz/CvWKZRUsk9bS1PvzVMfI+OiiVHApAjAciRAORIAHIkADkSgBwJQI4EIEcCkCMByJEA5EgAciQAORKAHAlAjgQgRwKQIwHIkQDkSAByJAA5EoAcCUCOBCBHApAjAciRAORIAHIkADkSgBwJQI4EIOcfGjV2tEfztqEAAAAASUVORK5CYII=\" alt=\"comment-user-thumbnail\"/></a><div class=\"comment-info\"><div class=\"username\"><a href=\"/@nopannogain\">nopannogain</a></div><div class=\"date\">2023년 3월 16일</div></div></div></div><div class=\"sc-bQtKYq ehISJN\"><div class=\"sc-ksHpcM iYgFNI\"><div class=\"sc-bQtKYq ehISJN\"><div class=\"sc-fXEqDS jlUmJL atom-one\"><p>꼼꼼한 논문 리뷰 잘 보았습니다. 저도 논문 리서치 중인데, 논문 리뷰는 이렇게 하는 것이군요.ㅎㅎ 본받아서 저도 열심히 조사해야겠어요. 감사합니다:)</p></div></div></div></div><div class=\"sc-gXRojI mIalr\"><div class=\"sc-bGaVxB kbaMiN\"><svg width=\"12\" height=\"12\" fill=\"none\" viewBox=\"0 0 12 12\"><path fill=\"currentColor\" d=\"M5.5 2.5h1v3h3v1h-3v3h-1v-3h-3v-1h3v-3z\"></path><path fill=\"currentColor\" fill-rule=\"evenodd\" d=\"M1 0a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h10a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1H1zm10 1H1v10h10V1z\" clip-rule=\"evenodd\"></path></svg><span>답글 달기</span></div></div></div></div></div></div></div></div><div class=\"Toastify\"></div></div><script>window.__APOLLO_STATE__={\"Post:040abdbb-a10b-4690-bcf8-060c67dd94d5\":{\"id\":\"040abdbb-a10b-4690-bcf8-060c67dd94d5\",\"title\":\"[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving \",\"released_at\":\"2021-08-05T15:14:35.674Z\",\"updated_at\":\"2023-09-08T15:24:22.379Z\",\"tags\":{\"type\":\"json\",\"json\":[\"autonomous driving\",\"multimodal learning\",\"paper_review\"]},\"body\":\" 안녕하세요. 밍기뉴와제제입니다. \\\\n \\\\n정말 오랜만에 돌아왔습니다. 논문은 여러개 봤는데 리뷰할 정도로 깊게 탐구한 논문이 별로 없어 한동안 글을 안쓰다 이번에 논문 세미나를 하다보니 꼼꼼히 살펴본 논문이 생겼습니다. \\\\n\\\\n 이번에 리뷰를 하려는 논문은 \\'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving \\'라는 논문입니다. 자율주행에 관한 논문이죠. \\\\n \\\\n 이름을 보면 대충 짐작 가시겠지만 이 논문은 multimodal, 두가지 데이터를 처리하는 모델을 설계했습니다. 그리고 Transformer도 이용했다는 사실을 짐작할 수 있습니다. \\\\n \\\\n 그러면 지금부터 논문 흐름에 맞춰 리뷰를 해보도록 하겠습니다. \\\\n \\\\n ## Introduction\\\\n ---\\\\n 이 부분에서는 이전까지 자율주행 모델이 사용한 방식들을 소개 후 저자가 소개하는 모델 \\'transfuser\\'에 대해 설명합니다. \\\\n \\\\n ### 한가지 입력값만 받는 모델\\\\n \\\\n 이전에 Image-only model과 LiDAR-only model이 등장했고 이는 자율주행의 성능을 올리는데 많이 기여했습니다. 허나 이렇게 한가지 데이터만 입력값으로 사용한 모델은 **near-ideal한 움직임을 보이는 객체**들만 있는 환경에서 **제한된 움직임만 필요한 경로**에 주행해야만 높은 성능을 보여준다는 것이었죠. 굉장히 사용하기 까다로웠습니다. \\\\n \\\\n 논문에서는 이를 두고 다음과 같이 말했습니다. \\\\n >adversarial scenarios에서 만족스럽지 못한 성능을 보여준다\\\\n \\\\n여기서 adversarial scenarios는 운전에 변수가 많이 생기는 환경을 말합니다. 예를 들면 비보호 회전을 해야하는 교차로, 랜덤하게 등장하는 자동차와 보행자 등이 운전에 변수를 주는 요소라 볼 수 있죠. \\\\n그러면 이런 부분이 왜 낮은 성능이 나오게끔 하는걸까요? 다음의 그림을 보며 설명해 드리도록 하겠습니다. \\\\n\\\\n![](https://images.velog.io/images/minkyu4506/post/cda53439-1ba7-461e-a3d2-7b6805019556/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%208.10.17.png)\\\\n\\\\n위 사진은 논문에서 말한 adversarial scenarios 중 하나입니다. \\\\n여기서 초록색 박스 안에 있는 자동차(Ego-Vehicle)와 왼쪽 도로에서 건너오는 빨간색 박스 속 자동차들(Traffic), 그리고 노란색 박스 안에 있는 신호등(Traffic Lights)이 있습니다. 여기서 Ego-Vehicle이 자율주행을 하는 자동차죠.\\\\n\\\\n이 상황에서 Ego-Vehicle이 카메라와 LiDAR에서 얻은 데이터를 살펴봅시다. LiDAR의 정의는 다음과 같습니다.\\\\n>LiDAR : Light Detection And Ranging, 레이저를 발사 후 돌아오는 시간을 계산해 주변 물체를 검출하는 센서\\\\n\\\\nLiDAR는 3D 데이터인 Point Cloud를 생산하며 여기엔 카메라가 관측할 수 없는 넓은 범위에 존재하는 객체에 대한 정보가 포함되어 있습니다. 그림을 보면 카메라 뷰에서 보이지 않는 자동차(Traffic)을 검출했다는 사실을 확인할 수 있습니다. \\\\n\\\\n허나 LiDAR는 카메라가 검출한 신호등을 찾지 못했습니다. 즉, 각 센서별로 얻을 수 있는 정보가 다릅니다. \\\\n\\\\n이러한 상황에서 Image-only 혹은 LiDAR-only model을 사용해 자율주행을 한다고 가정해봅시다. \\\\n그러면 아래와 같은 문제가 생길 확률이 높습니다.\\\\n\\\\n* Image-only model : 왼쪽에서 건너오는 자동차들을 고려하지 않고 운전 -> 추돌 사고\\\\n* LiDAR-only model : 전방에 있는 신호등의 신호를 고려하지 않고 운전 -> 신호 위반\\\\n\\\\n이건 꽤 큰 단점이죠. 그래서 사람들은 이를 해결하기 위한 방법을 찾고자 했습니다. \\\\n\\\\n### 두가지 입력값을 함께 사용해보자\\\\n\\\\n사람들은 자율주행 자동차에 있는 센서에 주목했습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/ed409fbd-f733-4294-a832-2410a12035b2/0*PjdSdGyiEB6Yg1UX.png)\\\\n(출처 : https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f)\\\\n\\\\n위 사진은 자율주행 자동차에 들어있는 센서를 나타낸 그림입니다. 보시면 알겠지만 자율주행 자동차 안에는 수많은 센서들이 들어있습니다. \\\\n\\\\n이렇게 많은 센서를 보고 사람들이 생각한게 있습니다. \\\\n>\\\\\"자동차에 있는 두개의 센서를 함께 사용해보는건 어떨까?\\\\\"\\\\n\\\\n그래서 두가지 데이터를 함께 써보자는 아이디어를 떠올렸죠. 그리고 다음과 같은 질문을 남겼습니다. \\\\n>* 두가지 데이터를 어떤 방식으로 합쳐서 사용하지?\\\\n* 두가지 데이터로 어떤걸 선택하지? \\\\n\\\\n이 질문에 답하기 위해 수많은 논문들이 나왔습니다. 그 중 한가지 논문에 나온 모델 구조에 대해 간단히 소개해드리겠습니다. \\\\n\\\\n![](https://images.velog.io/images/minkyu4506/post/74c12e61-7d7c-46aa-844e-21a9991b62fd/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%2010.19.35.png)\\\\n(출처 : Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proc. IEEE Conf. on Computer Vision and Pat- tern Recognition (CVPR), 2017)\\\\n\\\\n위 그림에 나온 구조가 두가지 데이터를 처리하는 대부분의 모델이 사용하는 구조입니다. 각 데이터별로 CNN에 넣어 특성맵을 추출한 뒤 원소 단위로 평균값을 낸다든지 더한다든지 하는 방식으로 Fusion해 하나의 출력값으로 만드는 방식이죠. \\\\n\\\\n### 여전히 아쉽다!\\\\n\\\\n두가지 데이터를 이용하는 방식은 한가지 데이터를 사용하는 방식보다 성능이 좋았습니다. 허나 여전히 단점이 있었습니다. \\\\n\\\\n바로 도심 속 운전같이 복잡한 상황에서 운전하기 힘들다는 점이었습니다. \\\\n\\\\n교차로에서 운전할 때를 고려해봅시다. 위에 제가 올린 사진과 같은 상황이죠. 여기서 자율주행을 하는 자동차(Ego-Vehicle)는 왼쪽에서 오는 자동차(Traffic)과 신호등의 신호(Traffic Lights) 사이의 연관성을 고려하며 운전을 해야합니다. 허나 각 데이터별로 특성맵을 추출하면 특성을 추출하는 과정에서 모든 정보를 고려할 수 없게 됩니다. \\\\n\\\\n즉, 모든 정보를 고려하지 않고 얻어낸 정보를 가지고 운전하기 때문에 사고가 날 확률이 높은 것이죠.\\\\n\\\\n이는 데이터의 문제가 아니라 데이터를 처리하는 모델 구조의 문제였습니다. \\\\n\\\\n### Transformer\\\\n\\\\n그래서 저자는 Attention mechanism만 사용해 데이터를 처리하는 Transformer를 특성 추출 과정에서 사용하기로 했습니다. \\\\n\\\\nTransformer의 self-attention는 입력 값의 각 원소가 전체적인 입력값의 어느 부분을 더 주목해야 하는지 반영하게 해주니 이를 이용해 이미지와 LiDAR 데이터를 전체적으로 고려하며 특성맵을 추출하는 방식을 생각한 것입니다.\\\\n\\\\n\\\\\"두가지 데이터를 어떤 방식으로 합쳐서 사용하지?\\\\\" 에 대한 답변은 Transforemr였습니다.\\\\n\\\\n### Single-view image and LiDAR inputs\\\\n\\\\n그리고 \\\\\"두가지 데이터로 어떤걸 선택하지?\\\\\"에 대한 답변을 해야합니다. \\\\n\\\\n저자는 이에 \\\\\"Single-view image and LiDAR를 입력 데이터로 사용한다\\\\\"고 말했습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/74af93a1-93f3-4d49-a6e9-dc0fa9a07905/%EC%9E%90%EB%A3%8C.png)\\\\n이 둘을 사용하겠다는 것이죠.\\\\n\\\\n왜 Single-view image and LiDAR를 선택한 걸까요? 저자는 이 둘이 서로가 서로에게 부족한 점을 채워주는 상호보완성이 있기 때문에 선택했다고 말했습니다. \\\\n\\\\n즉, 이 둘을 입력데이터로 사용해 얻는 정보의 양이 제일 많다고 판단한 것이죠. \\\\n\\\\n### Transfuser\\\\n\\\\n이제 저자가 생각해낸 모델을 정리해봅시다. \\\\n\\\\n>입력 데이터로 Single-view image and LiDAR를 받아 특성을 추출하는 과정에서 Transformer를 사용해 전체적인 정보를 고려하는 모델\\\\n\\\\n한문장으로 간단히 정리됩니다. 저자는 이렇게 설계된 모델을 **Transfuser**라고 정의했습니다.\\\\n\\\\n여기까지 모델의 Introduction 부분이었습니다. 깔끔히 쓰고 싶었는데 쉽지않네요. 허허...\\\\n\\\\n\\\\n그럼 이제 Transfuser가 포함된 자율주행 모델이 만들어지는 과정을 소개한 Method 항목을 소개해 드리도록 하겠습니다. \\\\n\\\\n## Method\\\\n---\\\\n원래 Releated work를 슥 살펴보고 Method로 넘어가야 하는데 그러면 분량이 너무 많아져서 바로 Method로 건너왔습니다. 저도 자율주행 모델에 대해 잘 감이 안잡힌 상태에서 이 논문을 읽어서 Related work 부분이 논문 이해에 꽤나 도움이 되었습니다. 관심 있으신 분들은 따로 찾아서 읽어보시는걸 추천드립니다. \\\\n\\\\n아무튼, 이제 Method에 대해 설명해 드리도록 하겠습니다.\\\\n\\\\nMethod에는 Transformer를 이용해 자율주행 모델을 만드는 일련의 과정이 적혀있습니다. \\\\n\\\\n모델을 만드는 과정은 다음과 같이 3단계로 나눌 수 있습니다. \\\\n\\\\n1. Task 설정, 데이터셋 구성(Problem Setting)\\\\n2. 데이터셋 전처리(Input and Output Parameterization)\\\\n3. 모델 설계(Multi-Modal Fusion Transformer + Waypoint Prediction Network)\\\\n\\\\n그러면 \\'Task 설정\\'부터 설명해 드리도록 하겠습니다.\\\\n\\\\n### 1. Problem Setting\\\\n\\\\n모델이 해결할 Task를 설정하고 이를 위한 학습법, 그리고 필요한 데이터셋을 설명하는 부분입니다. \\\\n\\\\n저자는 **point-to-point navigation**를 모델이 수행할 Task로 설정했습니다. \\\\n\\\\n저자는 point to point navigation이 목표지점까지 waypoint를 따라 사고 없이 완주하는 것이라 말했습니다. 여기서 사고는 다른 객체(자동차, 사람 등)과 충돌하거나 교통법규를 어기는 것을 말하죠. \\\\n\\\\n그리고 이를 학습하는 방법으로 imitation learning을 선택했습니다. imitation learning이란 강화학습의 일종인데요, 의미 그대로 해당 task에서 전문가(Expert)가 하는걸 따라하는 학습법입니다. \\\\n\\\\n강화 학습은 학습 주체인 agent와 agent가 행동하는데 규범이 되는 policy, 행동의 결과인 action, action으로 인한 상태 state, 그리고 state에 대한 보상 reward가 있습니다.여기서 보상 reward를 가장 많이 받는 방향으로 학습시키는 것이 목표죠. \\\\n\\\\nreward를 많이 받도록 만드는 방식은 여러가지가 있습니다. 그중 하나가 행동 규범힌 policy를 학습가능한 상태(parameterize)로 만드는 것이죠. \\\\n\\\\nimitation learning도 그 방식을 사용하고 있으며 논문에서는 다음과 같이 설명합니다. \\\\n>Policy를 Expert의 policy를 따라하게끔 학습하는 것\\\\n\\\\n그런데 여기서 궁금증이 생겼습니다. 왜 imiation learning을 선택한거지? 그래서 찾아봤습니다. \\\\n찾아보니까 이렇게 policy를 학습 대상으로 삼아 학습시키는 방식은 **고차원 데이터를 처리하고 연속된 action을 해야하는 모델의 학습에 적합**하다고 합니다. \\\\n\\\\n이미지라는 고차원 데이터를 처리해 연속된 action이 필요한 운전을 하는 자율주행 모델에 적합한방식이라 선택한게 아닌가 싶습니다. \\\\n\\\\n그러면 이제 저자가 imitation learning을 사용한 학습과정을 설명해 드리도록 하겠습니다.\\\\n\\\\n#### 데이터셋 수집 \\\\n우선 데이터셋을 수집해야하죠? 학습을 위한 학습 데이터셋과 평가를 위한 테스트 데이터셋이 필요합니다. \\\\n\\\\n데이터셋은 자율주행 오픈소스 시뮬레이터 CARLA(https://carla.org)에 있는 가상 환경에서 수집\\\\n합니다. 별다른 이유는 적지 않았지만 아무래도 사고가 날 수 있는 상황에 대한 데이터도 모으기 때문에 그런게 아닌가 싶네요. \\\\n\\\\n여튼, CARLA에 있는 가상환경에서 Expert가 주행하며 데이터를 모읍니다. imitation learning에서 말씀드린 Expert 맞습니다. \\\\n\\\\nExpert는 가상환경을 주행하며 입력 데이터와 출력 데이터를 수집합니다. 그렇게 해서 \\\\n![](https://images.velog.io/images/minkyu4506/post/bf940494-966f-4a2d-ab3e-15adb7e16afe/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.06.20.png)\\\\n위와 같은 데이터셋 D를 만들어줍니다. \\\\n\\\\n여기서 X는 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 한 시점(single time step)에 이미지 한장, point cloud 하나가 있는 것이죠.\\\\n\\\\n그리고 W는 T개의 waypoint가 모인 w로 이루어져 있습니다. 즉, 이미지와 point cloud를 하나씩 넣으면 출력값으로 T개의 Waypoint가 나오는 모델을 만들겠다는 뜻이죠.\\\\n\\\\n#### 학습 방법\\\\n이렇게 데이터셋을 모았으니 학습을 시켜봅시다. 학습 방식은 다음과 같이 정의할 수 있습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/42199532-a602-4a20-89e2-8a21126a3759/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.11.08.png)\\\\n여기서 L은 Loss함수입니다. 그러니까 Expert가 주행한 경로와 우리가 만든 agent의 policy에 따른 action, 다시 말해 **우리가 만든 모델이 예측한 주행 경로 사이의 loss가 최소가 되게끔 policy를 학습시키겠다**는 뜻이죠. \\\\n\\\\n저자는 이러한 학습 방식을 지도학습의 방식이라고 말했습니다. Expert의 데이터를 label data, 내가 만든 모델의 데이터가 prediction data라고 보면 저자의 말이 이해가 되시지 않을까 싶습니다. \\\\n\\\\n그래서 강화학습은 어떻게 학습 시키는걸까 찾아봤습니다. 강화학습은 데이터셋을 사용하지 않고 학습하기 때문에 매 순간 자기 자신이 만든 state와 reward를 보고 다음 action에 반영하며 점점 높은 reward만 받는 모델로 학습되는 방식을 사용한다는 사실을 알아냈습니다. 지도학습으로만 모델을 학습시켜본 저에게 있어서 강화학습은 상당히 신기한 방식입니다. \\\\n\\\\n#### 자율 주행 \\\\n저자는 학습 이후 어떻게 자율주행에 사용할지도 설명해 주었습니다. \\\\n저자는 모델이 예측한 경로를 inverse dynamics model에 넣어 얻은 action으로 주행을 한다고 말했고 이 때 inverse dynamics model을 PID controller로 구현했다고 설명했습니다. \\\\n\\\\nPID controller는 간단한게 말해 주어진 출력값을 위해 필요한 제어값(가속, 감속, 회전 등)을 구하는 요소라고 보시면 됩니다. 자세한 설명은 [여기](https://ko.wikipedia.org/wiki/PID_제어기)서 확인하실 수 있습니다. \\\\n\\\\n저자는 이러한 과정을 다음과 같은 식으로 나타냈습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/a7c85e89-258f-4110-991f-1a7316121323/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.23.16.png)\\\\naction = PID(예측 경로)인 것이죠. 여기서 action은 agent가 행한 action과 동일한 개념입니다. \\\\n\\\\n#### Global planner\\\\n마지막에 등장하는 문단인데 처음에는 이게 왜 있는건가 싶었습니다. \\\\n\\\\n읽어보니 저자들은 CARLA의 표준 프로토콜을 따르고 목표 지점이 GPS 좌표로 제공되며 목표 지점과 자동차가 안내한 지점이 몇백미터 떨어질 수 있다고 나와있습니다. \\\\n\\\\n다른 부분은 그러려니 하고 읽었는데 마지막 부분 \\'목표 지점과 안내 지점이 몇백미터 떨어질 수 있다\\'는 말이 거슬렸습니다. 도대체 뭔 뜻이지? \\\\n\\\\n제가 논문 세미나를 할 때 이 논문을 가지고 했는데요, 이에 관해 세미나 계신 분들께 여쭤보고 답을 들었는데도 이해가 제대로 안되서 구글에 검색까지 해봤습니다.\\\\n\\\\n구글에 검색을 해보니 다음과 같은 글을 발견했습니다. \\\\n>\\\\nThe global planner plans a global path around obstacles\\\\n\\\\n대충 번역하면 장애물을 돌아가는 global path를 생성하는게 global planner라고 하네요. \\\\n\\\\n아마 **목표 지점에 가기 힘들면 그 근처로 안내할 수 있음**을 말하고 싶어서 이 부분을 추가한게 아닌가 싶습니다.\\\\n\\\\n여기까지 Problem Setting이었습니다.\\\\n\\\\n### 2. Input and Output Parameterization\\\\n\\\\n이제 데이터셋을 어떻게 만들었는지? 정확히는 모델의 학습에 사용하기 위해 어떤 작업을 했는지 설명해 드리도록 하겠습니다.\\\\n\\\\n#### Input Representation\\\\n\\\\n우선 입력 데이터부터 설명해 드리고자 합니다.\\\\n\\\\n입력 데이터는 앞서 말씀드렸듯 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 카메라 이미지는 2D 데이터고 Point cloud는 3D 데이터라 각자 처리방식이 다릅니다. \\\\n\\\\n1. 카메라 이미지\\\\n카메라에서 촬영된 이미지는 400X300 사이즈인데요, 여기서 가운데 256X256 영역만 추출해서 사용합니다. 왜냐하면 렌즈 구조상 외곽 이미지는 왜곡 되어있기 때문입니다. 이렇게 **256X256X3** 사이즈의 데이터를 얻습니다. \\\\n\\\\n2. LiDAR Point Cloud\\\\n저자는 LiDAR에서 얻은 Point Cloud 중 자동차의 전면 32m, 좌우 측면 각 16m씩 해서 총 32m X 32m 영역만 사용합니다. 그리고 이를 2D 데이터로 변환해주는데요, 한 셀당 0.125m X 0.125m로 해서 256 X 256 픽셀 데이터로 변환해줍니다. \\\\n그리고 Point Cloud는 3D 데이터라 높이에 관한 데이터도 있는데요, 저자는 이를 2개의 채널에 담았습니다. 하나는 지면 위(+) 높이 데이터, 다른 하나는 지면 밑(-) 높이 데이터를 담았죠.\\\\n이렇게 **256X256X2** 사이즈의 데이터를 얻습니다.\\\\n\\\\n#### Output Representation\\\\n출력값 양식을 정의하는 부분입니다. \\\\n\\\\n출력값, 즉 waypoint는 BEV space에서 (x,y)의 양식을 지닙니다. \\\\n\\\\n![](https://images.velog.io/images/minkyu4506/post/143364fc-ea4f-4738-8c28-ad2d826983ed/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.59.06.png)\\\\n이런 방식으로 나온다는 뜻이죠. 중심에 자동차가 있고 앞에 빨간 점으로 자동차가 이동할 waypoint가 나와 있습니다. 이 때 waypoint의 집합 trajectory는 다음과 같이 정의됩니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/e1e69200-2870-4820-87fb-71022c6b7fa2/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%2010.05.40.png)\\\\n\\\\n앞서 데이터셋을 구성할 때 T개의 waypoint 예측값이 모인 데이터셋을 만든다고 말씀드렸는데요, 저자는 T를 4로 정의했습니다. 왜 T를 4로 정의했냐면 예측 궤적을 가기 위한 제어값을 얻는 PID controller가 요구하는 waypoint의 default number가 4라서 T를 4로 설정했다고 말했습니다.\\\\n\\\\n여기까지 Input and Output Parameterization였습니다. \\\\n\\\\n### 3. 모델 설계\\\\n다음으로 모델의 구조에 대해 설명해 드리고자 합니다. \\\\n\\\\n모델의 구조는 크게 두 가지로 나눌 수 있습니다. 하나는 **Multi-Modal Fusion Transformer**고 다른 하나는 **Waypoint Prediction Network**입니다. \\\\n\\\\nMulti-Modal Fusion Transformer는 저자가 새로운 제안한 Transfuser를 말하는 것이구요, Waypoint Prediction Network는 Transfuser에서 얻은 값을 가지고 경로를 예측하는 모델입니다. \\\\n\\\\n우선 Transfuser부터 먼저 설명해 드리도록 하겠습니다. \\\\n\\\\n#### 1. Multi-Modal Fusion Transformer(Transfuser)\\\\nTransfuser는 다음과 같은 구조를 가지고 있습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/98673fc0-6990-40b0-869c-3052443d7086/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.46.13.png)\\\\n제가 Trnafuser는 특성을 추출하는 과정에서 Transformer를 이용해 전체 데이터를 고려하는 모델이라고 말씀드렸는데요, 이 그림을 보시면 \\\\\"아...이런 뜻이구나\\\\\" 이해하시지 않을까 싶습니다. \\\\n\\\\n여기서 눈여겨볼 항목은 당연히 저자가 강조한 Transformer를 이용해 전체 데이터 정보를 각 특성맵에 반영해주는 부분입니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/09f43877-9853-4ba7-8912-21a2f59d9700/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.51.55.png) ![](https://images.velog.io/images/minkyu4506/post/9faf9fb5-3e84-4ddd-9beb-79600e08b92f/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.55.19.png)\\\\n이 부분을 말하는 것이죠. 아래 그림은 윗 그림에서 Transformer 부분을 강조한 그림입니다.\\\\n\\\\n여기서 진행되는 연산의 순서를 말씀드리면 다음과 같습니다. \\\\n\\\\n1. Conv + Pool 연산으로 특성맵 추출\\\\n2. 추출한 특성맵의 사이즈를 8 X 8로 압축 후 Transformer에 입력값으로 보냄\\\\n3. 각 데이터에서 보내준 8 X 8 크기의 특성맵 2개를 합체 = 16 X 8 사이즈의 특성맵 생성\\\\n4. 16X8 벡터를 Positional Embedding 후 Linear layer를 이용해 자동차의 현재 속도를 Embedding vector에 projection\\\\n5. Transformer에 넣어 self-attention 연산 => Embedding vector내 원소별로 전체 데이터(이미지 + LiDAR)에 대한 Attention이 반영됨. 사이즈는 16 X 8로 같음\\\\n6. Attention이 반영된 Embedding vector를 Image, LiDAR별로 나눔 -> 8 X 8 사이즈의 벡터가 2개 생성\\\\n7. 8 X 8 사이즈의 벡터를 압축하기 전의 크기로 scale up \\\\n8. 원래 특성맵과(1에서 추출한 특성맵) element-wise summation(원소끼리 더함)\\\\n\\\\n\\\\u003cbr>\\\\n\\\\n코드로 나타내면 상당히 간단해집니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/f0cdda7c-89a7-4c60-8d4d-4e8d4826652d/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.09.01.png)\\\\n아무튼 간단해집니다. \\\\n\\\\n여튼, 이런 과정을 총 4번 반복합니다. 더 해도 안된다는 법은 없는데 저자는 4번 반복하라고 말했습니다. \\\\n\\\\n4번 반복한 뒤 마지막에 Average Pooling + Flatten연산을 해서 1 X 1 X 512 벡터를 2개 생성합니다. 이미지에서 얻고 LiDAR에서 얻으니까 총 2개를 얻는 것이죠. \\\\n\\\\n이 2개의 벡터를 element-wise summation해서 하나의 1 X 1 X 512 벡터로 만들어줍니다. \\\\n\\\\n이렇게 우리는 최종 출력값 1 X 1 X 512 벡터를 얻었습니다. 이제 Waypoint Prediction Network를 확인해보도록 합시다. \\\\n\\\\n#### 2. Waypoint Prediction Network\\\\n\\\\n앞서 우리는 Transfuser에서 1 X 1 X 512 사이즈의 벡터를 얻었습니다. \\\\n\\\\n이 벡터는 Waypoint Prediction Network에 쓰입니다. \\\\n\\\\nWaypoint Predictoin Network는 다음과 같은 구조를 가지고 있습니다. \\\\n\\\\n![](https://images.velog.io/images/minkyu4506/post/e2a83385-fdf5-4e03-9f20-8ae87396a950/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.47.15.png)\\\\n\\\\n보시면 MLP와 GRU로 이루어졌다는 사실을 확인하실 수 있습니다. \\\\n\\\\n1. MLP\\\\nMLP는 3개의 Linear Layer로 이루어져 있습니다. MLP는 입력값으로 들어오는 1 X 1 X 512 사이즈의 벡터를 1 X 1 X 64 벡터로 압축해줍니다. 계산의 효율성을 위해 줄여주는 겁니다. \\\\n코드는 다음과 같습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/cd1db45c-1c0c-4fe5-b9bc-64866cb05b21/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.20.57.png)\\\\n\\\\n2. GRU\\\\nGRU는 RNN에서 많이 쓰였던 LSTM을 개선한 알고리즘 입니다. 시계열 데이터를 처리하는데 적합한 알고리즘이죠. 이걸 레이어 형식으로 추가했습니다. \\\\nGRU는 현 시점의 입력 데이터와 hidden state를 받아 연산을 처리합니다. waypoint prediction network에서는 자동차의 좌표와 목표 지점의 좌표를 더한 값을 입력 값으로 하였습니다. 이 때 좌표의 단위는 gps입니다. \\\\n여기서 흥미로운 점이 있습니다. 바로 첫 시점의 입력 데이터 중 자동차의 좌표가 (0,0)이라는 점입니다. 이는 자동차가 좌표계의 원점에 있다고 가정했기 때문입니다. \\\\n그러니까 **입력 데이터를 넣는 시점에서 자동차의 위치가 x = (0,0)에 있다고 보는 것이고 (0,0)를 기준으로 향후 4 time의 waypoint를 예측하는 것**이라 보시면 되겠습니다. \\\\n다시 본론으로 돌아옵시다. 입력 데이터를 알아봤으니 이제 hidden state로 넘어가야죠. hidden state는 앞서 얻은 1 X 1 X 64 벡터로 초기화해줍니다. 우리가 입력 데이터로 얻은 특성을 hidden state를 초기화하는데 사용하는 겁니다. \\\\n이렇게 입력값을 넣어주면 출력값이 나올겁니다. 이 출력값을 Linear layer에 넣으면 현 시점의 자동차에서 움직여야할 좌표 dx가 생성됩니다. \\\\n이 dx에 기존 자동차의 좌표 x에 더하면 이제 다음 시점에 이동할 waypoint가 되는 겁니다. \\\\n이 waypoints는 다음 시점에서 현재 좌표가 되겠죠? next_x = x + dx인 겁니다. \\\\n여튼 이 과정을 4번 반복해 waypoint 4개를 얻습니다.\\\\n\\\\n#### Plus : PID controller\\\\n모델의 구조에는 없지만 자율주행을 수행하기 위해 꼭 있어야할 PID controller입니다. \\\\n앞서 예측한 경로를 PID controller에 넣어 주행에 필요한 제어값을 얻는다고 말씀드렸습니다. \\\\n실은 그 이상으로 설명드릴게 없습니다. 그러니 여기서는 구현된 코드를 보여드리고 넘어가도록 하겠습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/3fa43398-54ed-4ef2-ac1d-9e34b8896814/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.57.46.png)\\\\n코드의 return 부분을 보시면 운전에 필요한 데이터들이 나와있습니다. steer는 차를 얼마나 회전할지 나타낸거고 throttle는 엔진에 들어갈 공기량을 제어하니까 가속을 얼마나 할지 나타낸거고 brake는 감속을 얼마나 할지 나타내는 것이죠. \\\\n\\\\n그런데 낯선 데이터가 하나 있습니다. 바로 metadata입니다. 슥 살펴보니 steer, throttle, brake만으로 설명이 안되는 정보를 보충 설명해주는 데이터인듯 합니다. 아마 저자가 실험했을 때 제어값의 정보 부족으로 좀 애먹었던게 아닌가 싶네요. 제 추측입니다. \\\\n\\\\n여기까지 모델의 구조를 살펴봤습니다. \\\\n\\\\n## Experiment\\\\n---\\\\n이제 실험 부분을 설명해 드리고자 합니다. \\\\n\\\\n여기서는 실험 세팅(experimental setup), 성능 비교(Results), 입력 데이터간 상호보완성 비교(Attention Map Visualizations), 구성 요소를 하나씩 빼면서 성능 확인(Ablation Study) 순으로 내용이 전개됩니다. \\\\n\\\\n### 1. 실험 세팅(experimental setup)\\\\n\\\\n여기서는 성능 측정을 위해 모델이 해야할 task와 이를 위해 필요한 데이터셋, 평가 지표와 성능을 비교할 모델을 소개하고 있습니다. \\\\n\\\\n#### Task\\\\n모델이 수행할 task는 다양한 주행 환경에서 제한 시간 안에 운전 규정을 시키며 주행하는 것입니다. \\\\n\\\\n여기서 주행 경로는 gps좌표 형식의 waypoint의 집합으로 제공되며 주행 도중에 일정 확률로 자동차나 보행자가 등장할 수 있고 차선 변경, 회전 등 주행 중에 충분히 일어날 수 있는 상황도 경로에 포함되어 있습니다. \\\\n\\\\n앞서 논문에서 말한 \\'복잡한 운전 상황\\'속 주행 성능을 평가하는거라 생각하시면 됩니다. \\\\n\\\\n#### Dataset\\\\n데이터셋을 모으는 방법이 적혀있습니다. \\\\n\\\\n앞서 말씀드렸듯 Expert가 CARLA에 있는 가상환경에서 주행하며 데이터를 모은다고 말씀드렸습니다. 여기서 더 자세히 써보도록 하겠습니다. \\\\n\\\\nCARLA에는 주행을 할 수 있는 8개의 Town이 있습니다. 8개의 가상환경이 있는 것이죠. 각 town의 특성은 다음과 같습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/f9052600-3c62-40b6-bea6-c9dfb0c40ade/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%207.26.46.png)\\\\n각자 특성을 가지고 있죠. Expert는 여기서 Town 01, 02, 03, 04, 06, 07, 10에 사전 정의된 경로들을 달리며 학습용 데이터셋을 수집합니다. \\\\n\\\\n그리고 학습용 데이터셋으로 모델을 훈련시키고 난 뒤 Town05에서 주행 성능을 평가합니다. \\\\n\\\\nTown05는 1차선부터 n차선, 그리고 일반도로부터 고속도로까지 다양한 도로가 있기 때문에 주행 성능을 평가하는 맵으로 선정했다고 말했습니다. \\\\n\\\\n![](https://images.velog.io/images/minkyu4506/post/7fe65901-ef85-46ef-b802-861ba297b5e9/Town05.jpg)\\\\nTown05에 깔려있는 도로를 나타낸 사진입니다. 다양한 도로로 구성되어 있음을 확인할 수 있습니다. \\\\n\\\\n저자는 어떠한 주행 경로에서 성능을 평가하는지도 설명했습니다. 저자는 단거리 경로와 장거리 경로를 각 10개씩 뽑았고 이를 Town05 Short, Town05 Long이라 이름 지었습니다. 특징은 다음과 같습니다.\\\\n\\\\n* Town05 Short : 주행 거리 100~500m, 교차로 3개\\\\n* Town05 Long : 주행거리 1~2km, 교차로 10개\\\\n\\\\n그리고 주행 중에 자동차나 사람이 등장할 수 있다는 공통점이 있습니다. \\\\n\\\\n마지막으로 날씨입니다. 맑은 날 주행하는거랑 비오는 날에 주행하는건 난이도가 어느정도 차이가 나는데요, 저자는 **동적인 객체와 신호등에 대한 주행 성능 평가에 집중할 것이기 때문에** 날씨는 \\'항상 맑음\\'으로 고정한다고 말했습니다. \\\\n\\\\n개인적으로 아쉬운 부분이었습니다. 날씨도 변수를 줘서 실험을 했으면 더 좋지 않았을까 생각합니다. \\\\n\\\\n#### Metrics\\\\n\\\\n구글에 검색해보니 \\'측정 수단\\'이라는 뜻으로 해석됩니다. 즉, 평가지표입니다. \\\\n\\\\n저자는 평가 지표로 RC, DS, Infraction Count를 선택했습니다. 하나씩 설명해 드리도록 하겠습니다. \\\\n\\\\n1. RC(Route Completion) : 주행 경로를 몇%나 주행했는지 나타내는 수치입니다. \\\\n2. DS(Driving Score) : RC에 infraction multiplier를 곱한 값입니다. 여기서 infraction multiplier는 객체와의 충돌, 경로 이탈, 차선 침법, 신호 위반을 설명하는 수치라고 합니다. \\\\n3. Infraction Count : 따로 설명은 해놓지 않았지만 사고 종류별 발생 횟수를 측정한게 아닐까 싶습니다. \\\\n\\\\n#### Baselines\\\\n\\\\nTransfuser가 포함된 자율주행 모델과 성능을 비교할 모델을 적어놓았습니다. 5개의 모델과 비교합니다. \\\\n\\\\n모델 종류는 다음과 같습니다. \\\\n* CILRS : 카메라 이미지만 입력값으로 받으며 navigational command의 통제 아래 자율주행을 수행합니다. \\\\n* LBC : 원래 Bird\\'s view image와 front image를 받았는데 논문(LBC)의 저자가 왼쪽 45도, 오른쪽 45도 각도에서 찍은 전면 카메라 이미지와 target heatmap을 입력값으로 받는걸로 바꿨습니다. \\\\n* AIM : 전면 카메라 이미지만 입력데이터로 받습니다. 단일 입력값을 받는 모델 중 가장 성능이 좋습니다. \\\\n* Late Fusion : 이제부터 두가지 입력값을 함께 처리하는 모델입니다. Late Fusion은 image와 LiDAR에서 얻은 값을 각각 Convolution Layer로 특성맵을 뽑아낸 후 element-wise summation해줍니다. \\\\n* Geometric Fusion : image와 LiDAR에서 얻은 값을 각각 Convolution Layer로 특성맵을 뽑을 때마다 서로 projection해 서로의 정보를 반영합니다. 이렇게 뽑은 두 특성맵을 element-wise summation 해줍니다.\\\\n![](https://images.velog.io/images/minkyu4506/post/de2f3a7e-32cc-4294-8330-9be27248df91/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%209.41.56.png)\\\\n위 사진은 구현코드입니다. 보시면 각자 특성을 추출 후 서로 projection하는걸 확인하실 수 있습니다. \\\\n\\\\n### 2. 실험 결과(Results)\\\\n실험 결과는 다음과 같습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/38b6e380-d752-4841-bac0-409e94f3ee8d/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%209.45.13.png)\\\\n왼쪽 사진은 Short, Long 경로에서 모델별 RC, DS를 나타낸거고 오른쪽 사진은 사고율을 나타낸 겁니다. \\\\n\\\\n#### Driving Performance\\\\n우선 왼쪽 표에 대해서 설명을 해드리도록 하겠습니다. \\\\n\\\\n여기서 눈여겨볼 부분은 한가지 입력값을 받는 CILRS, LBC, AIM보다 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능이 더 좋다는 겁니다. 두가지 입력값을 쓰기만 해도 한가지 입력값을 쓰는 것보다 성능이 좋다는 사실을 알 수 있습니다. \\\\n\\\\n그리고 또다시 눈여겨볼 부분은 Transfuser가 Late Fusion, Geometric Fusion보다 RC는 낮은데 DS가 높다는 것입니다. 즉, Transfuser는 주행 거리는 짧지만 안전운전을 더 잘한다는 뜻이죠. \\\\n\\\\n저자는 이를 보고 \\'Late Fusion, Geometric Fusion는 안전하게 운전하는 것보다 목표 지점에 가는데 중점을 뒀기 때문에 이런 결과가 나왔다\\'고 말했습니다. \\\\n\\\\n그리고 Expert의 점수도 나와있는데요, Expert도 장거리 운전에서는 그리 좋지 못한 성적을 얻었습니다. 신기합니다. \\\\n\\\\n#### Infraction\\\\n모델별 평균 사고율이 나옵니다. 초록색 막대가 Transfuser인데요, 모든 사고 항목에서 가장 낮습니다. 그런데  빨간불 신호 위반에서 다른 모델보다 낮긴 하지만 그래도 다른 사고 항목에 비하면 굉장히 높은 수치를 보입니다. 왜 그런걸까요? \\\\n\\\\n#### Limitations\\\\n여기선 모델의 한계점에 대해 저자가 얘기하는 부분입니다. 저자는 모델의 한계점으로 **빨간불 신호 위반의 확률이 높은 것**을 꼽았습니다. \\\\n\\\\n높은 신호위반 확률을 보이는 이유는 성능 평가를 위해 주행하던 경로에서 신호등이 카메라 구석에 찍혔는데 이 때문에 신호등의 빨간 불빛을 감지하기가 힘들어 빨간불에서 정차하지 않고 주행하는 일이 많았다고 합니다. \\\\n\\\\n그리고 이러한 문제를 해결할 additional supervision을 기대해본다고 말했습니다. \\\\n\\\\n### 3. Attention Map Visualizations\\\\n여기서는 카메라 이미지와 LiDAR point cloud간 상호보완성을 보여줍니다. \\\\n\\\\n어떻게 보여주냐면 교차로에서 신호대기중인 차량에서 얻은 이미지, Point cloud를 Transfuser로 특성을 추출하는 과정에서 self-attention을 통해 나온 16X8 사이즈의 벡터를 통해 설명합니다.\\\\n\\\\n여기서 반은 이미지쪽 벡터고 나머지 반은 LiDAR쪽 벡터입니다. 여기서 각각 자동차와 신호등에 대한 정보가 담긴 부분만 추출해 서로 얼마나 attention을 했는지 확인해봅니다. attention이 반영된 정도는 각 요소별 곱해진 score를 보고 알 수 있죠. \\\\n\\\\n그렇게 attention된 정도를 확인한 결과, 다음의 사실을 알 수 있었습니다. \\\\n* 이미지 토큰의 62.75%가 attention을 가장 많이 한 5개의 token이 LiDAR에서 나온 토큰\\\\n* LiDAR 토큰의 78.45%가 attention을 가장 많이 한 5개의 token이 이미지에서 나온 토큰\\\\n\\\\n여기서 토큰은 transformer에 입력값으로 들어가는 데이터 단위를 말합니다. 출력값 역시 토큰의 집합이죠. 토큰을 데이터로 바꾼 뒤 읽으셔도 의미의 차이는 없을듯 합니다. \\\\n\\\\n아무튼, 이렇게 서로 상호보완하는 부분이 많습니다. 특성을 추출할 때 상대 데이터를 많이 고려한다는 뜻이죠. \\\\n\\\\n### 4. Ablation Study\\\\n여기서는 Transfuser의 Transformer에 대해 값을 수정해가며 성능의 변화를 관측한걸 얘기합니다. 저자는 Town05 Short에서 성능 평가를 했는데요, 성능표는 다음과 같았습니다. \\\\n![](https://images.velog.io/images/minkyu4506/post/3060d95b-e30f-41f8-a83b-b79cf1877329/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%2011.02.23.png)\\\\n하나씩 설명해드리도록 하겠습니다. \\\\n\\\\n1. Scale : Transformer 이후 Fusion 횟수를 나타냅니다. 원래 4번 Fusion했는데 이 횟수를 줄여보며 성능을 비교해봤습니다. Scale이 1이면 마지막에 추출한 feature map(8X8X512)에서만 fusion하고 2면 16X16X256 feature map과 8X8X512 feature map에서 fusion하는거죠. \\\\n2. Shared Transformer : 원래 각 사이즈의 특성맵마다 다른 Transformer를 사용합니다. 그러면 모든 특성맵에서 다같은 Transformer를 사용하면 어떻게 될까요? 성능이 떨어졌습니다. 저자는 각 convolution layer에서 얻은 특성맵이 갖고 있는 성질이 다 다르기 때문에 각기 다른 Transformer에서 처리해야 한다고 말했습니다.(different convolutional layers in ResNet learn different types of features due to which each transformer has to focus on fusing different types of features)\\\\n3. Attention layers : 원래 각 Transfomer에는 8개의 Attention layer가 있습니다. 이를 1개, 4개로 만든 뒤 성능을 측정해봤습니다. \\\\n4. No Pos. Embd : Transformer에 넣기전에 Positional Embedding을 안했을 경우입니다. \\\\n\\\\n이렇게 각 요소를 제거한 뒤 성능을 비교했습니다. Scale을 제외한 나머지 부분에서 하나의 공통점이 있는데요, 바로 RC는 증가하지만 DS가 떨어졌다는 점입니다. \\\\n\\\\n저자는 이를 보고 \\'Attention횟수가 많아질 수록 더 조심히 운전하게 된다\\'고 말했습니다. \\\\n\\\\n## Conclusion\\\\n---\\\\n논문의 결말입니다. 저자는 앞서 말한 것을 conclusion에서 총체적으로 정리했습니다. 그리고 마지막에 자신들이 만든 모델에 다른 센서의 입력값을 추가해서 쓰거나 다른 AI task에 사용할 수 있다고 말하며 논문을 끝냈습니다. \\\\n\\\\u003cbr>\\\\n## 후기\\\\n---\\\\n이렇게 길고 긴 논문 리뷰가 끝났습니다. 최선을 다해 리뷰해봤는데 미숙한 부분이 많았습니다. 이런식으로 데이터를 받아서 처리하는 모델도 처음 접했고 자율주행 task를 수행하는 모델도 처음이라 읽는데 많은 시간이 걸렸습니다. 그래도 리뷰하고 나니 뿌듯하네요. \\\\n\\\\n3주 뒤에 다른 논문을 세미나에서 발표하는데 그 논문도 velog에 올릴 계획입니다. 개강이 얼마 남지 않은 시기라 쓰기 힘들겠지만 하...할 수 있겠죠? \\\\n\\\\n마지막으로 제가 이 논문을 읽고 느낀점을 쓰고자 합니다. 제가 느낀 점은 다음과 같습니다.\\\\n\\\\n* 두 종류의 입력값을 특성 추출 과정에서 반영함으로써 안전한 운전을 구현했다는 사실이 흥미로웠다.\\\\n\\\\n* 허나 Transformer가 전체 입력값을 모두 고려하며 계산하기 때문에 연산량이 좀 많을텐데 실시간으로 판단이 필요한 운전에서 이런 점이 부담이 되지 않을까 싶다.\\\\n\\\\n* 추후 주행 속도도 개선하며 안전운전을 추구하는 모델이 나왔으면 좋겠다.\\\\n\\\\n그리고 제가 이걸 세미나에서 발표했을 때 교수님께서 \\\\\"꼭 두가지 데이터를 사용했어야 했을까, LiDAR에서 얻은 정보를 사용할 때 2D 데이터로 변환하는 과정에서 많은 데이터 손실이 있을텐데 그걸 감수하면서까지 사용할 이유가 있을지 모르겠다, 차라리 시야각이 넓은 이미지를 사용하면 데이터 손실도 없이 사용할 수 있지 않을까\\\\\" 라고 저에게 말씀하셨습니다. \\\\n\\\\n실은 저는 입력값에 대한 어떠한 의문도 가지지 않았는데 교수님의 말씀을 듣고 의문이 들었습니다. 실제로 표를 봤을 때\\\\n![](https://images.velog.io/images/minkyu4506/post/d919d9ce-64eb-4d23-9e83-c67e9f7b4ca7/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.06.23.png)\\\\n여기 보시면 한가지 입력값만 받는 AIM과 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능차이가 크게 없다는 사실을 확인할 수 있습니다. 물론 장거리 주행에서는 DS에서 차이가 나긴 하지만 다들 점수가 낮기 때문에 큰 상관은 없다고 생각합니다. \\\\n\\\\n아무튼, 많은 공부가 되었고 재밌게 읽은 논문이었습니다. 다음 논문 리뷰에서 뵙겠습니다!\\\\n\\\\n\",\"short_description\":\" 안녕하세요. 밍기뉴와제제입니다.\\\\n\\\\n정말 오랜만에 돌아왔습니다. 이번에 리뷰하는 논문은 \\'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving\\'입니다.\\\\n\",\"is_markdown\":true,\"is_private\":false,\"is_temp\":false,\"thumbnail\":\"https://images.velog.io/images/minkyu4506/post/18537d03-8701-4bc7-90aa-f1cd4b26a51a/스크린샷 2021-08-06 오전 12.14.18.png\",\"comments_count\":1,\"url_slug\":\"논문리뷰-Multi-Modal-Fusion-Transformer-for-End-to-End-Autonomous-Driving\",\"likes\":6,\"liked\":false,\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"comments\":[{\"type\":\"id\",\"generated\":false,\"id\":\"Comment:16148570-8807-4fbe-9310-cf7cf3328a7a\",\"typename\":\"Comment\"}],\"__typename\":\"Post\",\"series\":{\"type\":\"id\",\"generated\":false,\"id\":\"Series:178ca26f-74db-41d1-b5a0-178dd836bd01\",\"typename\":\"Series\"},\"linked_posts\":{\"type\":\"id\",\"generated\":true,\"id\":\"$Post:040abdbb-a10b-4690-bcf8-060c67dd94d5.linked_posts\",\"typename\":\"LinkedPosts\"}},\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\":{\"id\":\"552ae1d0-fbd5-416e-81fb-acf301305d29\",\"username\":\"minkyu4506\",\"profile\":{\"type\":\"id\",\"generated\":false,\"id\":\"UserProfile:78c52242-365e-41ea-b3c4-75d5efd3ccbe\",\"typename\":\"UserProfile\"},\"velog_config\":{\"type\":\"id\",\"generated\":true,\"id\":\"$User:552ae1d0-fbd5-416e-81fb-acf301305d29.velog_config\",\"typename\":\"VelogConfig\"},\"__typename\":\"User\"},\"UserProfile:78c52242-365e-41ea-b3c4-75d5efd3ccbe\":{\"id\":\"78c52242-365e-41ea-b3c4-75d5efd3ccbe\",\"display_name\":\"Minguinho_zeze\",\"thumbnail\":\"https://images.velog.io/images/minkyu4506/profile/3d19426f-f141-4188-b23a-254ce14fce5a/Untitled.png\",\"short_bio\":\"안녕하세요. 딥러닝 알고리즘에 관심이 많은 학부생입니다. \",\"profile_links\":{\"type\":\"json\",\"json\":{\"email\":\"minkyu4506@gmail.com\",\"github\":\"MinkyuKim26\",\"twitter\":\"minguinho_zeze\"}},\"__typename\":\"UserProfile\"},\"$User:552ae1d0-fbd5-416e-81fb-acf301305d29.velog_config\":{\"title\":\"Minguinho_zeze.log\",\"__typename\":\"VelogConfig\"},\"Comment:16148570-8807-4fbe-9310-cf7cf3328a7a\":{\"id\":\"16148570-8807-4fbe-9310-cf7cf3328a7a\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:d9b8f8d1-1394-4e24-b896-edc0ed2ef6db\",\"typename\":\"User\"},\"text\":\"꼼꼼한 논문 리뷰 잘 보았습니다. 저도 논문 리서치 중인데, 논문 리뷰는 이렇게 하는 것이군요.ㅎㅎ 본받아서 저도 열심히 조사해야겠어요. 감사합니다:)\",\"replies_count\":0,\"level\":0,\"created_at\":\"2023-03-16T06:28:05.132Z\",\"deleted\":false,\"__typename\":\"Comment\"},\"User:d9b8f8d1-1394-4e24-b896-edc0ed2ef6db\":{\"id\":\"d9b8f8d1-1394-4e24-b896-edc0ed2ef6db\",\"username\":\"nopannogain\",\"profile\":{\"type\":\"id\",\"generated\":false,\"id\":\"UserProfile:c36ec24f-75e8-4a17-a323-3a2f97dcb4c0\",\"typename\":\"UserProfile\"},\"__typename\":\"User\"},\"UserProfile:c36ec24f-75e8-4a17-a323-3a2f97dcb4c0\":{\"id\":\"c36ec24f-75e8-4a17-a323-3a2f97dcb4c0\",\"thumbnail\":null,\"__typename\":\"UserProfile\"},\"Series:178ca26f-74db-41d1-b5a0-178dd836bd01\":{\"id\":\"178ca26f-74db-41d1-b5a0-178dd836bd01\",\"name\":\"논문 리뷰 + 구현\",\"url_slug\":\"논문-리뷰-구현\",\"series_posts\":[{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:2481b6f8-1a05-4325-bb59-886c7ed8a28f\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:6d0361d6-f3b1-43f7-a7d0-56f666687121\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:637c8f6b-abe2-4267-8f33-4c36b73f4632\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:ee72d632-dca9-44dd-8e12-c51a02367a17\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:c9de7822-2404-41fa-a656-400820f49f20\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:3ecb7f15-c79b-4f1a-b3df-62e2eba99a08\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:bb764c3c-14e6-4d00-9702-c78d36d69e1e\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:bc541266-5027-43fe-9702-5920cdbe5848\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:281a0201-84cf-45ca-bc6f-9a471088f055\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:ea7a6ef4-0395-402b-a3e7-ce3defaee215\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:f58d70bd-fc61-4bcb-a040-9dd6a83e0cda\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:fbe4d33c-08f6-4ae2-b9f4-4320d312b11b\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:2bf8abde-583f-40f8-b4ec-17cf20452600\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:5b3a3783-9ede-415f-9718-99895f53a06c\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:10f557e8-ec24-405e-9f5c-70aec262babd\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:6bbb2f85-556d-4a75-b863-48e79c1eec57\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:9c2661f7-08ab-4754-85fb-b916c8a25587\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:8d4dd3de-a6b2-4c03-b8aa-1f3028ebf4bc\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:8c9aefb2-03c9-4867-bfe4-1326b5262d1e\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:8c119007-0ca8-46bb-8e08-1b9ed1bbc85a\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:3a3eb1ce-2fbd-43a2-96df-f6faa2d95b39\",\"typename\":\"SeriesPost\"}],\"__typename\":\"Series\"},\"SeriesPost:2481b6f8-1a05-4325-bb59-886c7ed8a28f\":{\"id\":\"2481b6f8-1a05-4325-bb59-886c7ed8a28f\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:672f3ed1-14c7-437c-9b71-45d3c62bc8f1\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:672f3ed1-14c7-437c-9b71-45d3c62bc8f1\":{\"id\":\"672f3ed1-14c7-437c-9b71-45d3c62bc8f1\",\"title\":\"[논문리뷰]Faster R-CNN 리뷰 + 코드구현(TensorFlow2)\",\"url_slug\":\"Faster-R-CNN-리뷰-with-Code\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:6d0361d6-f3b1-43f7-a7d0-56f666687121\":{\"id\":\"6d0361d6-f3b1-43f7-a7d0-56f666687121\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:040abdbb-a10b-4690-bcf8-060c67dd94d5\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"SeriesPost:637c8f6b-abe2-4267-8f33-4c36b73f4632\":{\"id\":\"637c8f6b-abe2-4267-8f33-4c36b73f4632\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:edc905f6-4fcf-492e-ad82-ec39eaaeb1de\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:edc905f6-4fcf-492e-ad82-ec39eaaeb1de\":{\"id\":\"edc905f6-4fcf-492e-ad82-ec39eaaeb1de\",\"title\":\"[논문리뷰] YOLO v1 리뷰 + 코드 구현(TensorFlow2)\",\"url_slug\":\"YOLO-v1-리뷰-코드-구현tensorflow2\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:ee72d632-dca9-44dd-8e12-c51a02367a17\":{\"id\":\"ee72d632-dca9-44dd-8e12-c51a02367a17\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:de387f0c-24db-4dde-a358-1046ab498f74\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:de387f0c-24db-4dde-a358-1046ab498f74\":{\"id\":\"de387f0c-24db-4dde-a358-1046ab498f74\",\"title\":\"[논문리뷰] Dynamic Head: Unifying Object Detection Heads with Attentions\",\"url_slug\":\"논문리뷰-Dynamic-Head-Unifying-Object-Detection-Heads-with-Attentions\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:c9de7822-2404-41fa-a656-400820f49f20\":{\"id\":\"c9de7822-2404-41fa-a656-400820f49f20\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:2c88e843-ccec-47dc-8895-b9c5a822b977\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:2c88e843-ccec-47dc-8895-b9c5a822b977\":{\"id\":\"2c88e843-ccec-47dc-8895-b9c5a822b977\",\"title\":\"[논문리뷰] CovidCTNet리뷰\",\"url_slug\":\"논문리뷰-CovidCTNet리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:3ecb7f15-c79b-4f1a-b3df-62e2eba99a08\":{\"id\":\"3ecb7f15-c79b-4f1a-b3df-62e2eba99a08\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:3b07b75b-ff53-4b53-9eb6-a9582649db1d\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:3b07b75b-ff53-4b53-9eb6-a9582649db1d\":{\"id\":\"3b07b75b-ff53-4b53-9eb6-a9582649db1d\",\"title\":\"[논문 리뷰] SSD(Single Shot MultiBox Detector)\",\"url_slug\":\"논문-리뷰-SSDSingle-Shot-MultiBox-Detector\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:bb764c3c-14e6-4d00-9702-c78d36d69e1e\":{\"id\":\"bb764c3c-14e6-4d00-9702-c78d36d69e1e\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:928c7e72-7b7c-4e5b-a9b0-a331beda119a\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:928c7e72-7b7c-4e5b-a9b0-a331beda119a\":{\"id\":\"928c7e72-7b7c-4e5b-a9b0-a331beda119a\",\"title\":\"[논문 리뷰] U-Net 리뷰\",\"url_slug\":\"논문-리뷰-U-Net-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:bc541266-5027-43fe-9702-5920cdbe5848\":{\"id\":\"bc541266-5027-43fe-9702-5920cdbe5848\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:0d78a78d-c132-4e2d-a70f-e64ff900dcaa\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:0d78a78d-c132-4e2d-a70f-e64ff900dcaa\":{\"id\":\"0d78a78d-c132-4e2d-a70f-e64ff900dcaa\",\"title\":\"[논문리뷰]GAN(Generative Adversarial Nets) 리뷰\",\"url_slug\":\"논문리뷰GANGenerative-Adversarial-Nets-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:281a0201-84cf-45ca-bc6f-9a471088f055\":{\"id\":\"281a0201-84cf-45ca-bc6f-9a471088f055\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:e1f57e7f-ef7a-4131-9ea4-0a38a07dc6d7\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:e1f57e7f-ef7a-4131-9ea4-0a38a07dc6d7\":{\"id\":\"e1f57e7f-ef7a-4131-9ea4-0a38a07dc6d7\",\"title\":\"[데이터셋 리뷰]  ‘DiLiGenT’ Photometric Stereo Dataset\",\"url_slug\":\"데이터셋-리뷰-DiLiGenT-Photometric-Stereo-Dataset\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:ea7a6ef4-0395-402b-a3e7-ce3defaee215\":{\"id\":\"ea7a6ef4-0395-402b-a3e7-ce3defaee215\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:bfe9ccde-c6c4-4d32-b99b-d757fa8a018a\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:bfe9ccde-c6c4-4d32-b99b-d757fa8a018a\":{\"id\":\"bfe9ccde-c6c4-4d32-b99b-d757fa8a018a\",\"title\":\"PyTorch로 YOLOv1  구현하기\",\"url_slug\":\"PyTorch로-YOLOv1-구현하기\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:f58d70bd-fc61-4bcb-a040-9dd6a83e0cda\":{\"id\":\"f58d70bd-fc61-4bcb-a040-9dd6a83e0cda\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:032c5d02-0a19-4166-af6d-6c40d05865bf\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:032c5d02-0a19-4166-af6d-6c40d05865bf\":{\"id\":\"032c5d02-0a19-4166-af6d-6c40d05865bf\",\"title\":\"[논문리뷰] Densely Connected Convolutional Networks(DenseNet)\",\"url_slug\":\"논문리뷰-Densely-Connected-Convolutional-NetworksDenseNet\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:fbe4d33c-08f6-4ae2-b9f4-4320d312b11b\":{\"id\":\"fbe4d33c-08f6-4ae2-b9f4-4320d312b11b\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:ae403834-c84e-46e5-a5e3-e5b8c39d04e9\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:ae403834-c84e-46e5-a5e3-e5b8c39d04e9\":{\"id\":\"ae403834-c84e-46e5-a5e3-e5b8c39d04e9\",\"title\":\"[논문 리뷰] Efficient Module Based Single Image Super Resolution for Multiple Problems\",\"url_slug\":\"논문-리뷰-Efficient-Module-Based-Single-Image-Super-Resolution-for-Multiple-Problems\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:2bf8abde-583f-40f8-b4ec-17cf20452600\":{\"id\":\"2bf8abde-583f-40f8-b4ec-17cf20452600\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:3e7c0d59-aac3-439e-a85a-8fe3935c94a8\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:3e7c0d59-aac3-439e-a85a-8fe3935c94a8\":{\"id\":\"3e7c0d59-aac3-439e-a85a-8fe3935c94a8\",\"title\":\"[논문리뷰] Extending Stein’s unbiased risk estimator to train deep denoisers with correlated pairs of noisy images\",\"url_slug\":\"논문리뷰-Extending-Steins-unbiased-risk-estimator-to-train-deep-denoisers-with-correlated-pairs-of-noisy-images\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:5b3a3783-9ede-415f-9718-99895f53a06c\":{\"id\":\"5b3a3783-9ede-415f-9718-99895f53a06c\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:59a95946-8c7d-4a0e-a6ab-1d7fa9dfc62e\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:59a95946-8c7d-4a0e-a6ab-1d7fa9dfc62e\":{\"id\":\"59a95946-8c7d-4a0e-a6ab-1d7fa9dfc62e\",\"title\":\"[논문리뷰] Multi-Temporal Recurrent Neural Networks For Progressive Non-Uniform Single Image Deblurring With Incremental Temporal Training\",\"url_slug\":\"논문리뷰-Multi-Temporal-Recurrent-Neural-Networks-For-Progressive-Non-Uniform-Single-Image-Deblurring-With-Incremental-Temporal-Training\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:10f557e8-ec24-405e-9f5c-70aec262babd\":{\"id\":\"10f557e8-ec24-405e-9f5c-70aec262babd\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:39a9ae37-abfe-4f76-b664-836f247b3164\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:39a9ae37-abfe-4f76-b664-836f247b3164\":{\"id\":\"39a9ae37-abfe-4f76-b664-836f247b3164\",\"title\":\"[논문리뷰] FEDPARA- LOW-RANK HADAMARD PRODUCT FOR COMMUNICATION-EFFICIENT FEDERATED LEARNING\",\"url_slug\":\"논문리뷰-FEDPARA-LOW-RANK-HADAMARD-PRODUCT-FOR-COMMUNICATION-EFFICIENT-FEDERATED-LEARNING\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:6bbb2f85-556d-4a75-b863-48e79c1eec57\":{\"id\":\"6bbb2f85-556d-4a75-b863-48e79c1eec57\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:b142364f-8e50-4e8b-aee2-56069c9591ac\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:b142364f-8e50-4e8b-aee2-56069c9591ac\":{\"id\":\"b142364f-8e50-4e8b-aee2-56069c9591ac\",\"title\":\"[논문리뷰] YOLOv2, YOLOv3 리뷰\",\"url_slug\":\"논문리뷰-YOLOv2-YOLOv3-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:9c2661f7-08ab-4754-85fb-b916c8a25587\":{\"id\":\"9c2661f7-08ab-4754-85fb-b916c8a25587\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:4ef447b8-2c67-4983-a2f5-a2509008e374\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:4ef447b8-2c67-4983-a2f5-a2509008e374\":{\"id\":\"4ef447b8-2c67-4983-a2f5-a2509008e374\",\"title\":\"[논문리뷰]NeRF: Representing Scenes as\\\\nNeural Radiance Fields for View Synthesis 리뷰\",\"url_slug\":\"NeRF-Representing-Scenes-asNeural-Radiance-Fields-for-View-Synthesis-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:8d4dd3de-a6b2-4c03-b8aa-1f3028ebf4bc\":{\"id\":\"8d4dd3de-a6b2-4c03-b8aa-1f3028ebf4bc\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:bea4ca63-cd86-4b37-a58e-a97659423e5a\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:bea4ca63-cd86-4b37-a58e-a97659423e5a\":{\"id\":\"bea4ca63-cd86-4b37-a58e-a97659423e5a\",\"title\":\"[논문리뷰] \\'MLP-Mixer: An all-MLP Architecture for Vision\\' 리뷰 + 구현(PyTorch)\\\\n\",\"url_slug\":\"논문리뷰-MLP-Mixer-An-all-MLP-Architecture-for-Vision-리뷰-구현\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:8c9aefb2-03c9-4867-bfe4-1326b5262d1e\":{\"id\":\"8c9aefb2-03c9-4867-bfe4-1326b5262d1e\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:ccaa8ef1-263f-4fbb-b682-45406080ad57\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:ccaa8ef1-263f-4fbb-b682-45406080ad57\":{\"id\":\"ccaa8ef1-263f-4fbb-b682-45406080ad57\",\"title\":\"[논문리뷰] \\'DiffusionDet: Diffusion Model for Object Detection\\' 리뷰\",\"url_slug\":\"논문리뷰-DiffusionDet-Diffusion-Model-for-Object-Detection-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:8c119007-0ca8-46bb-8e08-1b9ed1bbc85a\":{\"id\":\"8c119007-0ca8-46bb-8e08-1b9ed1bbc85a\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:4edba77a-e19c-4569-a7dc-22443fcb2dcb\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:4edba77a-e19c-4569-a7dc-22443fcb2dcb\":{\"id\":\"4edba77a-e19c-4569-a7dc-22443fcb2dcb\",\"title\":\"[논문리뷰] \\'Compressing Neural Networks: Towards Determining the Optimal Layer-wise Decomposition\\' 리뷰\",\"url_slug\":\"논문리뷰-Compressing-Neural-Networks-Towards-Determining-the-Optimal-Layer-wise-Decomposition-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:3a3eb1ce-2fbd-43a2-96df-f6faa2d95b39\":{\"id\":\"3a3eb1ce-2fbd-43a2-96df-f6faa2d95b39\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:9a35ca2c-725a-4641-838b-a2f480bd1262\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:9a35ca2c-725a-4641-838b-a2f480bd1262\":{\"id\":\"9a35ca2c-725a-4641-838b-a2f480bd1262\",\"title\":\"[논문리뷰] \\'EfficientFormer: Vision Transformers at MobileNet Speed\\' 리뷰\",\"url_slug\":\"논문리뷰-EfficientFormer-Vision-Transformers-at-MobileNet-Speed-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"$Post:040abdbb-a10b-4690-bcf8-060c67dd94d5.linked_posts\":{\"previous\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:672f3ed1-14c7-437c-9b71-45d3c62bc8f1\",\"typename\":\"Post\"},\"next\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:edc905f6-4fcf-492e-ad82-ec39eaaeb1de\",\"typename\":\"Post\"},\"__typename\":\"LinkedPosts\"},\"ROOT_QUERY\":{\"post({\\\\\"url_slug\\\\\":\\\\\"논문리뷰-Multi-Modal-Fusion-Transformer-for-End-to-End-Autonomous-Driving\\\\\",\\\\\"username\\\\\":\\\\\"minkyu4506\\\\\"})\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:040abdbb-a10b-4690-bcf8-060c67dd94d5\",\"typename\":\"Post\"},\"velog_config({\\\\\"username\\\\\":\\\\\"minkyu4506\\\\\"})\":{\"type\":\"id\",\"generated\":true,\"id\":\"$ROOT_QUERY.velog_config({\\\\\"username\\\\\":\\\\\"minkyu4506\\\\\"})\",\"typename\":\"VelogConfig\"},\"auth\":null},\"$ROOT_QUERY.velog_config({\\\\\"username\\\\\":\\\\\"minkyu4506\\\\\"})\":{\"title\":\"Minguinho_zeze.log\",\"logo_image\":null,\"__typename\":\"VelogConfig\"}};</script><script>window.__REDUX_STATE__={\"core\":{\"layer\":false,\"auth\":{\"visible\":false,\"mode\":\"LOGIN\"},\"user\":null,\"popup\":{\"visible\":false,\"title\":\"\",\"message\":\"\"}},\"write\":{\"mode\":\"MARKDOWN\",\"markdown\":\"\",\"title\":\"\",\"html\":\"\",\"tags\":[],\"publish\":false,\"textBody\":\"\",\"defaultDescription\":\"\",\"description\":\"\",\"isPrivate\":false,\"urlSlug\":\"\",\"thumbnail\":null,\"editSeries\":false,\"selectedSeries\":null,\"postId\":null,\"isTemp\":false,\"initialTitle\":\"\",\"initialBody\":\"\"},\"header\":{\"custom\":true,\"userLogo\":{\"title\":\"Minguinho_zeze.log\",\"logo_image\":null},\"username\":\"minkyu4506\"},\"post\":{\"id\":null},\"error\":{\"errorType\":null},\"scroll\":{\"main\":0,\"user/posts\":0},\"home\":{\"timeframe\":\"week\"},\"darkMode\":{\"theme\":\"default\",\"systemTheme\":\"not-ready\"}};</script><script id=\"__LOADABLE_REQUIRED_CHUNKS__\" type=\"application/json\">[18,0,23,1,3]</script><script id=\"__LOADABLE_REQUIRED_CHUNKS___ext\" type=\"application/json\">{\"namedChunks\":[\"pages-velog-VelogPage\",\"PostPage\"]}</script><script async=\"\" data-chunk=\"main\" src=\"https://static.velog.io/static/js/runtime-main.5e039cd5.js\"></script><script async=\"\" data-chunk=\"main\" src=\"https://static.velog.io/static/js/20.357f3aca.chunk.js\"></script><script async=\"\" data-chunk=\"main\" src=\"https://static.velog.io/static/js/main.7e8cf780.chunk.js\"></script><script async=\"\" data-chunk=\"pages-velog-VelogPage\" src=\"https://static.velog.io/static/js/pages-velog-VelogPage.ebd63700.chunk.js\"></script><script async=\"\" data-chunk=\"PostPage\" src=\"https://static.velog.io/static/js/0.1f8bb2ed.chunk.js\"></script><script async=\"\" data-chunk=\"PostPage\" src=\"https://static.velog.io/static/js/23.3869d1a9.chunk.js\"></script><script async=\"\" data-chunk=\"PostPage\" src=\"https://static.velog.io/static/js/1.5cd4e340.chunk.js\"></script><script async=\"\" data-chunk=\"PostPage\" src=\"https://static.velog.io/static/js/PostPage.3dee536f.chunk.js\"></script></body></html>'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup = BeautifulSoup(html, 'lxml')\n",
        "soup"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8T83WRS8H3NT",
        "outputId": "a9e36201-b37e-4aca-b03b-eab5e9e20481"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<!DOCTYPE html>\n",
              "<html><head><title data-rh=\"true\">[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving </title><link data-rh=\"true\" href=\"https://velog.io/@minkyu4506/논문리뷰-Multi-Modal-Fusion-Transformer-for-End-to-End-Autonomous-Driving\" rel=\"canonical\"/><meta content=\"203040656938507\" data-rh=\"true\" property=\"fb:app_id\"/><meta content=\" 안녕하세요. 밍기뉴와제제입니다.\n",
              "\n",
              "정말 오랜만에 돌아왔습니다. 이번에 리뷰하는 논문은 'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving'입니다.\n",
              "\" data-rh=\"true\" name=\"description\"/><meta content=\"https://velog.io/@minkyu4506/논문리뷰-Multi-Modal-Fusion-Transformer-for-End-to-End-Autonomous-Driving\" data-rh=\"true\" property=\"og:url\"/><meta content=\"article\" data-rh=\"true\" property=\"og:type\"/><meta content=\"[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving \" data-rh=\"true\" property=\"og:title\"/><meta content=\" 안녕하세요. 밍기뉴와제제입니다.\n",
              "\n",
              "정말 오랜만에 돌아왔습니다. 이번에 리뷰하는 논문은 'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving'입니다.\n",
              "\" data-rh=\"true\" property=\"og:description\"/><meta content=\"https://velog.velcdn.com/images/minkyu4506/post/18537d03-8701-4bc7-90aa-f1cd4b26a51a/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.14.18.png\" data-rh=\"true\" property=\"og:image\"/><meta content=\"summary_large_image\" data-rh=\"true\" name=\"twitter:card\"/><meta content=\"[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving \" data-rh=\"true\" name=\"twitter:title\"/><meta content=\" 안녕하세요. 밍기뉴와제제입니다.\n",
              "\n",
              "정말 오랜만에 돌아왔습니다. 이번에 리뷰하는 논문은 'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving'입니다.\n",
              "\" data-rh=\"true\" name=\"twitter:description\"/><meta content=\"https://images.velog.io/images/minkyu4506/post/18537d03-8701-4bc7-90aa-f1cd4b26a51a/스크린샷 2021-08-06 오전 12.14.18.png\" data-rh=\"true\" name=\"twitter:image\"/><style data-styled=\"\" data-styled-version=\"5.3.3\">.hSMJOX{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;font-weight:bold;cursor:pointer;outline:none;border:none;color:white;background:var(--primary1);color:var(--button-text);border-radius:4px;padding-top:0;padding-bottom:0;height:2rem;padding-left:1.25rem;padding-right:1.25rem;font-size:1rem;}/*!sc*/\n",
              ".hSMJOX:hover,.hSMJOX:focus{background:var(--primary2);}/*!sc*/\n",
              ".sc-jrQzAO + .sc-jrQzAO{margin-left:0.5rem;}/*!sc*/\n",
              ".hSMJOX:disabled{cursor:not-allowed;background:var(--bg-element4);color:var(--text3);}/*!sc*/\n",
              ".hSMJOX:disabled:hover{background:var(--bg-element4);color:var(--text3);}/*!sc*/\n",
              "data-styled.g11[id=\"sc-jrQzAO\"]{content:\"hSMJOX,\"}/*!sc*/\n",
              "body{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,\"Helvetica Neue\",\"Apple SD Gothic Neo\",\"Malgun Gothic\",\"맑은 고딕\",나눔고딕,\"Nanum Gothic\",\"Noto Sans KR\",\"Noto Sans CJK KR\",arial,돋움,Dotum,Tahoma,Geneva,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:var(--text1);box-sizing:border-box;}/*!sc*/\n",
              "*{box-sizing:inherit;}/*!sc*/\n",
              "code{font-family:'Fira Mono',source-code-pro,Menlo,Monaco,Consolas,'Courier New', monospace;}/*!sc*/\n",
              "input,button,textarea{font-family:inherit;}/*!sc*/\n",
              "html,body,#root{height:100%;}/*!sc*/\n",
              "body{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\n",
              "@media (prefers-color-scheme:dark){body{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}}/*!sc*/\n",
              "body[data-theme='light']{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\n",
              "body[data-theme='dark']{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}/*!sc*/\n",
              "data-styled.g13[id=\"sc-global-gYCCRU1\"]{content:\"sc-global-gYCCRU1,\"}/*!sc*/\n",
              ".gflbJg{height:2rem;padding-left:1rem;padding-right:1rem;font-size:1rem;border-radius:1rem;background:none;border:none;outline:none;font-weight:bold;word-break:keep-all;background:var(--bg-element5);color:var(--button-text);-webkit-transition:0.125s all ease-in;transition:0.125s all ease-in;cursor:pointer;}/*!sc*/\n",
              ".gflbJg:hover{background:var(--bg-element6);}/*!sc*/\n",
              ".gflbJg:focus{box-shadow:0px 2px 12px #00000030;}/*!sc*/\n",
              ".gflbJg:disabled{background:var(--bg-element2);}/*!sc*/\n",
              "data-styled.g17[id=\"sc-egiyK\"]{content:\"gflbJg,\"}/*!sc*/\n",
              ".evafIC{width:1728px;margin-left:auto;margin-right:auto;}/*!sc*/\n",
              "@media (max-width:1919px){.evafIC{width:1376px;}}/*!sc*/\n",
              "@media (max-width:1440px){.evafIC{width:1024px;}}/*!sc*/\n",
              "@media (max-width:1056px){.evafIC{width:calc(100% - 2rem);}}/*!sc*/\n",
              "data-styled.g21[id=\"sc-fotOHu\"]{content:\"evafIC,\"}/*!sc*/\n",
              ".cdniDY{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;font-weight:bold;color:var(--text1);font-size:1.3125rem;-webkit-text-decoration:none;text-decoration:none;font-family:Fira Mono,monospace;}/*!sc*/\n",
              "@media (max-width:1024px){.cdniDY{font-size:1.125rem;}.cdniDY .velog-logo{height:1.25rem;}}/*!sc*/\n",
              ".cdniDY a{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\n",
              ".cdniDY .user-logo{display:block;max-width:calc(100vw - 200px);text-overflow:ellipsis;white-space:nowrap;overflow-x:hidden;overflow-y:hidden;}/*!sc*/\n",
              "data-styled.g26[id=\"sc-hGPBjI\"]{content:\"cdniDY,\"}/*!sc*/\n",
              ".eleXpO{color:inherit;}/*!sc*/\n",
              ".eleXpO svg{color:inherit;margin-right:1rem;width:1.75rem;height:1.75rem;display:block;}/*!sc*/\n",
              "@media (max-width:1024px){.eleXpO svg{width:1.5rem;height:1.5rem;margin-right:0.75rem;}}/*!sc*/\n",
              "data-styled.g27[id=\"sc-dlVxhl\"]{content:\"eleXpO,\"}/*!sc*/\n",
              ".hcjGyB{height:4rem;}/*!sc*/\n",
              "data-styled.g31[id=\"sc-iwjdpV\"]{content:\"hcjGyB,\"}/*!sc*/\n",
              ".iIPjQP{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background:transparent;border:none;width:2.5rem;height:2.5rem;outline:none;border-radius:50%;color:var(--text1);cursor:pointer;margin-right:0.5rem;}/*!sc*/\n",
              ".iIPjQP:hover{background:var(--slight-layer);}/*!sc*/\n",
              ".iIPjQP svg{width:1.125rem;height:1.125rem;}/*!sc*/\n",
              "data-styled.g32[id=\"sc-cxpSdN\"]{content:\"iIPjQP,\"}/*!sc*/\n",
              ".kYqaTx{height:100%;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/\n",
              "data-styled.g33[id=\"sc-llYSUQ\"]{content:\"kYqaTx,\"}/*!sc*/\n",
              ".cxmSXL{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;position:relative;}/*!sc*/\n",
              "@media (max-width:1024px){.cxmSXL .write-button{display:none;}}/*!sc*/\n",
              "data-styled.g34[id=\"sc-iJKOTD\"]{content:\"cxmSXL,\"}/*!sc*/\n",
              ".iZAesw{position:fixed;top:0;background:var(--bg-element1);width:100%;z-index:10;box-shadow:0px 0 8px rgba(0,0,0,0.08);}/*!sc*/\n",
              ".iZAesw .tab-wrapper{margin-top:-2rem;}/*!sc*/\n",
              "data-styled.g49[id=\"sc-efQSVx\"]{content:\"iZAesw,\"}/*!sc*/\n",
              ".cMpExe{padding-bottom:4rem;}/*!sc*/\n",
              "data-styled.g52[id=\"sc-dPiLbb\"]{content:\"cMpExe,\"}/*!sc*/\n",
              ".gihSnS{background:var(--bg-element4);-webkit-animation:gsdBxV 1s ease-in-out infinite;animation:gsdBxV 1s ease-in-out infinite;display:inline-block;border-radius:4px;height:1em;}/*!sc*/\n",
              ".sc-gSQFLo + .sc-gSQFLo{margin-left:0.5rem;}/*!sc*/\n",
              ".jbsFLX{background:var(--bg-element4);-webkit-animation:gsdBxV 1s ease-in-out infinite;animation:gsdBxV 1s ease-in-out infinite;display:inline-block;border-radius:4px;height:1em;}/*!sc*/\n",
              "data-styled.g59[id=\"sc-gSQFLo\"]{content:\"gihSnS,jbsFLX,\"}/*!sc*/\n",
              "body{background:var(--bg-page2);}/*!sc*/\n",
              "data-styled.g68[id=\"sc-global-iqNrnJ1\"]{content:\"sc-global-iqNrnJ1,\"}/*!sc*/\n",
              ".ijHvhk{width:768px;margin-left:auto;margin-right:auto;}/*!sc*/\n",
              "@media (max-width:768px){.ijHvhk{width:100%;}}/*!sc*/\n",
              "data-styled.g75[id=\"sc-dvQaRk\"]{content:\"ijHvhk,\"}/*!sc*/\n",
              "@media (max-width:1024px){.ePkhDB{padding-left:1rem;padding-right:1rem;}}/*!sc*/\n",
              "data-styled.g76[id=\"sc-TBWPX\"]{content:\"ePkhDB,\"}/*!sc*/\n",
              ".iQZhhJ{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n",
              "@media (max-width:768px){.iQZhhJ{-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;}}/*!sc*/\n",
              ".iQZhhJ img{display:block;width:8rem;height:8rem;border-radius:50%;object-fit:cover;box-shadow:0 0 4px 0 rgba(0,0,0,0.06);}/*!sc*/\n",
              "@media (max-width:768px){.iQZhhJ img{width:5rem;height:5rem;}}/*!sc*/\n",
              "data-styled.g77[id=\"sc-jIkXHa\"]{content:\"iQZhhJ,\"}/*!sc*/\n",
              ".eYREua{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;margin-left:1rem;}/*!sc*/\n",
              ".eYREua .name{font-size:1.5rem;line-height:1.5;font-weight:bold;color:var(--text1);}/*!sc*/\n",
              ".eYREua .name a{color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\n",
              ".eYREua .name a:hover{color:var(--text1);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n",
              ".eYREua .description{white-space:pre-wrap;font-size:1.125rem;line-height:1.5;margin-top:0.25rem;color:var(--text2);-webkit-letter-spacing:-0.004em;-moz-letter-spacing:-0.004em;-ms-letter-spacing:-0.004em;letter-spacing:-0.004em;}/*!sc*/\n",
              "@media (max-width:768px){.eYREua{margin-left:0;margin-top:1rem;}.eYREua .name{font-size:1.125rem;}.eYREua .description{margin-top:0.5rem;font-size:0.875rem;-webkit-letter-spacing:-0.004em;-moz-letter-spacing:-0.004em;-ms-letter-spacing:-0.004em;letter-spacing:-0.004em;}}/*!sc*/\n",
              "data-styled.g78[id=\"sc-ZOtfp\"]{content:\"eYREua,\"}/*!sc*/\n",
              ".fWmBKb{background:var(--bg-element3);width:100%;height:1px;margin-top:2rem;margin-bottom:1.5rem;}/*!sc*/\n",
              "@media (max-width:768px){.fWmBKb{margin-top:1rem;margin-bottom:1rem;}}/*!sc*/\n",
              "data-styled.g79[id=\"sc-jOxtWs\"]{content:\"fWmBKb,\"}/*!sc*/\n",
              ".fBgOP{color:var(--text3);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/\n",
              ".fBgOP svg{cursor:pointer;width:2rem;height:2rem;}/*!sc*/\n",
              ".fBgOP svg:hover{color:var(--text1);}/*!sc*/\n",
              "@media (max-width:768px){.fBgOP svg{width:1.5rem;height:1.5rem;}}/*!sc*/\n",
              ".fBgOP a{color:inherit;display:block;}/*!sc*/\n",
              ".fBgOP a + a,.fBgOP a + svg{margin-left:1rem;}/*!sc*/\n",
              "data-styled.g80[id=\"sc-hmjpVf\"]{content:\"fBgOP,\"}/*!sc*/\n",
              ".jhmYjy{margin-bottom:0.875rem;background:var(--bg-tag);padding-left:1rem;padding-right:1rem;height:2rem;border-radius:1rem;display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-right:0.875rem;color:var(--primary1);-webkit-text-decoration:none;text-decoration:none;font-weight:500;font-size:1rem;}/*!sc*/\n",
              "@media (max-width:768px){.jhmYjy{height:1.5rem;font-size:0.75rem;border-radius:0.75rem;padding-left:0.75rem;padding-right:0.75rem;margin-right:0.5rem;margin-bottom:0.5rem;}}/*!sc*/\n",
              ".jhmYjy:hover{opacity:0.75;}/*!sc*/\n",
              "data-styled.g90[id=\"sc-fbyfCU\"]{content:\"jhmYjy,\"}/*!sc*/\n",
              ".ehISJN{font-size:1.125rem;color:var(--text1);-webkit-transition:color 0.125s ease-in;transition:color 0.125s ease-in;line-height:1.7;-webkit-letter-spacing:-0.004em;-moz-letter-spacing:-0.004em;-ms-letter-spacing:-0.004em;letter-spacing:-0.004em;word-break:keep-all;word-wrap:break-word;}/*!sc*/\n",
              ".ehISJN ul b,.ehISJN ol b,.ehISJN p b{font-weight:400;}/*!sc*/\n",
              ".ehISJN ul code,.ehISJN ol code,.ehISJN p code{background:var(--bg-inline-code);padding:0.2em 0.4em;font-size:85%;border-radius:3px;}/*!sc*/\n",
              ".ehISJN ul a code,.ehISJN ol a code,.ehISJN p a code{color:var(--primary1);}/*!sc*/\n",
              ".ehISJN a{color:var(--primary1);-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\n",
              ".ehISJN a:hover{color:var(--primary1);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n",
              ".ehISJN code{font-family:'Fira Mono',source-code-pro,Menlo,Monaco,Consolas, 'Courier New',monospace;}/*!sc*/\n",
              ".ehISJN hr{border:none;height:1px;width:100%;background:var(--border3);margin-top:2rem;margin-bottom:2rem;}/*!sc*/\n",
              ".ehISJN p img{display:block;margin:0 auto;max-width:100%;margin-top:3rem;margin-bottom:3rem;}/*!sc*/\n",
              ".ehISJN h1{font-size:2.5rem;}/*!sc*/\n",
              ".ehISJN h2{font-size:2rem;}/*!sc*/\n",
              ".ehISJN h3{font-size:1.5rem;}/*!sc*/\n",
              ".ehISJN h4{font-size:1.125rem;}/*!sc*/\n",
              ".ehISJN h1,.ehISJN h2,.ehISJN h3,.ehISJN h4{line-height:1.5;margin-bottom:1rem;}/*!sc*/\n",
              ".ehISJN p + h1,.ehISJN p + h2,.ehISJN p + h3,.ehISJN p + h4{margin-top:2.5rem;}/*!sc*/\n",
              "@media (max-width:768px){.ehISJN{font-size:1rem;}.ehISJN h1{font-size:2.25rem;}.ehISJN h2{font-size:1.75rem;}.ehISJN h3{font-size:1.25rem;}.ehISJN h4{font-size:1rem;}.ehISJN h1,.ehISJN h2,.ehISJN h3,.ehISJN h4{margin-bottom:0.75rem;}.ehISJN p + h1,.ehISJN p + h2,.ehISJN p + h3,.ehISJN p + h4{margin-top:2rem;}}/*!sc*/\n",
              ".ehISJN blockquote{margin-top:2rem;margin-bottom:2rem;border-left:4px solid var(--primary2);border-top-right-radius:4px;border-bottom-right-radius:4px;background:var(--bg-element2);margin-left:0;margin-right:0;padding:1rem;padding-left:2rem;color:var(--text1);}/*!sc*/\n",
              ".ehISJN blockquote ul,.ehISJN blockquote ol{padding-left:1rem;}/*!sc*/\n",
              ".ehISJN blockquote *:first-child{margin-top:0;}/*!sc*/\n",
              ".ehISJN blockquote *:last-child{margin-bottom:0;}/*!sc*/\n",
              "data-styled.g113[id=\"sc-bQtKYq\"]{content:\"ehISJN,\"}/*!sc*/\n",
              ".jlUmJL.atom-one pre{background:var(--prism-bg);}/*!sc*/\n",
              ".jlUmJL.atom-one code[class*='language-'],.jlUmJL.atom-one pre[class*='language-']{color:var(--prism-default-text);background:none;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none;}/*!sc*/\n",
              ".jlUmJL.atom-one pre[class*='language-']::-moz-selection,.jlUmJL.atom-one pre[class*='language-'] ::-moz-selection,.jlUmJL.atom-one code[class*='language-']::-moz-selection,.jlUmJL.atom-one code[class*='language-'] ::-moz-selection{text-shadow:none;background:var(--prism-selection-bg);}/*!sc*/\n",
              ".jlUmJL.atom-one pre[class*='language-']::selection,.jlUmJL.atom-one pre[class*='language-'] ::selection,.jlUmJL.atom-one code[class*='language-']::selection,.jlUmJL.atom-one code[class*='language-'] ::selection{text-shadow:none;background:var(--prism-selection-bg);}/*!sc*/\n",
              "@media print{.jlUmJL.atom-one code[class*='language-'],.jlUmJL.atom-one pre[class*='language-']{text-shadow:none;}}/*!sc*/\n",
              ".jlUmJL.atom-one pre[class*='language-']{padding:1em;margin:0.5em 0;overflow:auto;}/*!sc*/\n",
              ".jlUmJL.atom-one:not(pre) > code[class*='language-'],.jlUmJL.atom-one pre[class*='language-']{background:var(--prism-code-block-bg);}/*!sc*/\n",
              ".jlUmJL.atom-one:not(pre) > code[class*='language-']{padding:0.1em;border-radius:0.3em;white-space:normal;}/*!sc*/\n",
              ".jlUmJL.atom-one .token.comment,.jlUmJL.atom-one .token.prolog,.jlUmJL.atom-one .token.doctype,.jlUmJL.atom-one .token.cdata{color:var(--prism-code-1);}/*!sc*/\n",
              ".jlUmJL.atom-one .token.punctuation{color:var(--prism-code-2);}/*!sc*/\n",
              ".jlUmJL.atom-one .token.selector,.jlUmJL.atom-one .token.tag{color:var(--prism-code-3);}/*!sc*/\n",
              ".jlUmJL.atom-one .token.property,.jlUmJL.atom-one .token.boolean,.jlUmJL.atom-one .token.number,.jlUmJL.atom-one .token.constant,.jlUmJL.atom-one .token.symbol,.jlUmJL.atom-one .token.attr-name,.jlUmJL.atom-one .token.deleted{color:var(--prism-code-4);}/*!sc*/\n",
              ".jlUmJL.atom-one .token.string,.jlUmJL.atom-one .token.char,.jlUmJL.atom-one .token.attr-value,.jlUmJL.atom-one .token.builtin,.jlUmJL.atom-one .token.inserted{color:var(--prism-code-6);}/*!sc*/\n",
              ".jlUmJL.atom-one .token.operator,.jlUmJL.atom-one .token.entity,.jlUmJL.atom-one .token.url,.jlUmJL.atom-one .language-css .token.string,.jlUmJL.atom-one .style .token.string{color:var(--prism-code-5);}/*!sc*/\n",
              ".jlUmJL.atom-one .token.atrule,.jlUmJL.atom-one .token.keyword{color:var(--prism-code-7);}/*!sc*/\n",
              ".jlUmJL.atom-one .token.function{color:var(--prism-code-8);}/*!sc*/\n",
              ".jlUmJL.atom-one .token.regex,.jlUmJL.atom-one .token.important,.jlUmJL.atom-one .token.variable{color:var(--prism-code-9);}/*!sc*/\n",
              ".jlUmJL.atom-one .token.important,.jlUmJL.atom-one .token.bold{font-weight:bold;}/*!sc*/\n",
              ".jlUmJL.atom-one .token.italic{font-style:italic;}/*!sc*/\n",
              ".jlUmJL.atom-one .token.entity{cursor:help;}/*!sc*/\n",
              ".jlUmJL.atom-one pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber;}/*!sc*/\n",
              ".jlUmJL.atom-one pre.line-numbers > code{position:relative;}/*!sc*/\n",
              ".jlUmJL.atom-one .line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:0;font-size:100%;left:-3.8em;width:3em;-webkit-letter-spacing:-1px;-moz-letter-spacing:-1px;-ms-letter-spacing:-1px;letter-spacing:-1px;border-right:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}/*!sc*/\n",
              ".jlUmJL.atom-one .line-numbers-rows > span{pointer-events:none;display:block;counter-increment:linenumber;}/*!sc*/\n",
              ".jlUmJL.atom-one .line-numbers-rows > span:before{content:counter(linenumber);color:var(--prism-line-number);display:block;padding-right:0.8em;text-align:right;}/*!sc*/\n",
              ".jlUmJL.github code,.jlUmJL.github code[class*='language-'],.jlUmJL.github pre[class*='language-']{color:#24292e;}/*!sc*/\n",
              ".jlUmJL.github pre{color:#24292e;background:#f6f8fa;}/*!sc*/\n",
              ".jlUmJL.github .token.function{color:#005cc5;}/*!sc*/\n",
              ".jlUmJL.github .token.comment,.jlUmJL.github .token.prolog,.jlUmJL.github .token.doctype,.jlUmJL.github .token.cdata{color:#969896;}/*!sc*/\n",
              ".jlUmJL.github .token.punctuation{color:#24292e;}/*!sc*/\n",
              ".jlUmJL.github .token.string{color:#032f62;}/*!sc*/\n",
              ".jlUmJL.github .token.atrule,.jlUmJL.github .token.attr-value{color:#183691;}/*!sc*/\n",
              ".jlUmJL.github .token.property,.jlUmJL.github .token.tag{color:#63a35c;}/*!sc*/\n",
              ".jlUmJL.github .token.boolean,.jlUmJL.github .token.number{color:#0086b3;}/*!sc*/\n",
              ".jlUmJL.github .token.selector,.jlUmJL.github .token.attr-name,.jlUmJL.github .token.attr-value .punctuation:first-child,.jlUmJL.github .token.keyword,.jlUmJL.github .token.regex,.jlUmJL.github .token.important{color:#d73a49;}/*!sc*/\n",
              ".jlUmJL.github .token.operator,.jlUmJL.github .token.entity,.jlUmJL.github .token.url,.jlUmJL.github .language-css{color:#d73a49;}/*!sc*/\n",
              ".jlUmJL.github .token.entity{cursor:help;}/*!sc*/\n",
              ".jlUmJL.github .namespace{opacity:0.7;}/*!sc*/\n",
              ".jlUmJL.monokai code[class*='language-'],.jlUmJL.monokai pre[class*='language-']{color:#f8f8f2;text-shadow:0 1px rgba(0,0,0,0.3);}/*!sc*/\n",
              ".jlUmJL.monokai:not(pre) > code[class*='language-'],.jlUmJL.monokai pre[class*='language-']{background:#272822;}/*!sc*/\n",
              ".jlUmJL.monokai pre{color:#f8f8f2;text-shadow:0 1px rgba(0,0,0,0.3);background:#272822;}/*!sc*/\n",
              ".jlUmJL.monokai .token.comment,.jlUmJL.monokai .token.prolog,.jlUmJL.monokai .token.doctype,.jlUmJL.monokai .token.cdata{color:#778090;}/*!sc*/\n",
              ".jlUmJL.monokai .token.punctuation{color:#f8f8f2;}/*!sc*/\n",
              ".jlUmJL.monokai .namespace{opacity:0.7;}/*!sc*/\n",
              ".jlUmJL.monokai .token.property,.jlUmJL.monokai .token.tag,.jlUmJL.monokai .token.constant,.jlUmJL.monokai .token.symbol,.jlUmJL.monokai .token.deleted{color:#f92672;}/*!sc*/\n",
              ".jlUmJL.monokai .token.boolean,.jlUmJL.monokai .token.number{color:#ae81ff;}/*!sc*/\n",
              ".jlUmJL.monokai .token.selector,.jlUmJL.monokai .token.attr-name,.jlUmJL.monokai .token.string,.jlUmJL.monokai .token.char,.jlUmJL.monokai .token.builtin,.jlUmJL.monokai .token.inserted{color:#a6e22e;}/*!sc*/\n",
              ".jlUmJL.monokai .token.operator,.jlUmJL.monokai .token.entity,.jlUmJL.monokai .token.url,.jlUmJL.monokai .language-css .token.string,.jlUmJL.monokai .style .token.string,.jlUmJL.monokai .token.variable{color:#f8f8f2;}/*!sc*/\n",
              ".jlUmJL.monokai .token.atrule,.jlUmJL.monokai .token.attr-value,.jlUmJL.monokai .token.function{color:#e6db74;}/*!sc*/\n",
              ".jlUmJL.monokai .token.keyword{color:#f92672;}/*!sc*/\n",
              ".jlUmJL.monokai .token.regex,.jlUmJL.monokai .token.important{color:#fd971f;}/*!sc*/\n",
              ".jlUmJL.monokai .token.important,.jlUmJL.monokai .token.bold{font-weight:bold;}/*!sc*/\n",
              ".jlUmJL.monokai .token.italic{font-style:italic;}/*!sc*/\n",
              ".jlUmJL.monokai .token.entity{cursor:help;}/*!sc*/\n",
              ".jlUmJL.dracula code[class*='language-'],.jlUmJL.dracula pre[class*='language-']{color:#ccc;background:rgb(40,41,54);}/*!sc*/\n",
              ".jlUmJL.dracula pre[class*='language-']::-moz-selection,.jlUmJL.dracula pre[class*='language-'] ::-moz-selection,.jlUmJL.dracula code[class*='language-']::-moz-selection,.jlUmJL.dracula code[class*='language-'] ::-moz-selection{text-shadow:none;background-color:#5a5f80;}/*!sc*/\n",
              ".jlUmJL.dracula pre[class*='language-']::selection,.jlUmJL.dracula pre[class*='language-'] ::selection,.jlUmJL.dracula code[class*='language-']::selection,.jlUmJL.dracula code[class*='language-'] ::selection{text-shadow:none;background-color:#5a5f80;}/*!sc*/\n",
              ".jlUmJL.dracula:not(pre) > code[class*='language-']{border-radius:0.3em;white-space:normal;}/*!sc*/\n",
              ".jlUmJL.dracula pre{color:#ccc;background:rgb(40,41,54);}/*!sc*/\n",
              ".jlUmJL.dracula .limit-300{height:300px !important;}/*!sc*/\n",
              ".jlUmJL.dracula .limit-400{height:400px !important;}/*!sc*/\n",
              ".jlUmJL.dracula .limit-500{height:500px !important;}/*!sc*/\n",
              ".jlUmJL.dracula .limit-600{height:600px !important;}/*!sc*/\n",
              ".jlUmJL.dracula .limit-700{height:700px !important;}/*!sc*/\n",
              ".jlUmJL.dracula .limit-800{height:800px !important;}/*!sc*/\n",
              ".jlUmJL.dracula .token.comment{color:rgba(98,114,164,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.prolog{color:rgba(207,207,194,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.tag{color:rgba(220,104,170,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.entity{color:rgba(139,233,253,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.atrule{color:rgba(98,239,117,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.url{color:rgba(102,217,239,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.selector{color:rgba(207,207,194,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.string{color:rgba(241,250,140,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.property{color:rgba(255,184,108,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.important{color:rgba(255,121,198,1);font-weight:bold;}/*!sc*/\n",
              ".jlUmJL.dracula .token.punctuation{color:rgba(230,219,116,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.number{color:rgba(189,147,249,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.function{color:rgba(80,250,123,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.class-name{color:rgba(255,184,108,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.keyword{color:rgba(255,121,198,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.boolean{color:rgba(255,184,108,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.operator{color:rgba(139,233,253,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.char{color:rgba(255,135,157,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.regex{color:rgba(80,250,123,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.variable{color:rgba(80,250,123,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.constant{color:rgba(255,184,108,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.symbol{color:rgba(255,184,108,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.builtin{color:rgba(255,121,198,1);}/*!sc*/\n",
              ".jlUmJL.dracula .token.attr-value{color:#7ec699;}/*!sc*/\n",
              ".jlUmJL.dracula .token.deleted{color:#e2777a;}/*!sc*/\n",
              ".jlUmJL.dracula .token.namespace{color:#e2777a;}/*!sc*/\n",
              ".jlUmJL.dracula .token.bold{font-weight:bold;}/*!sc*/\n",
              ".jlUmJL.dracula .token.italic{font-style:italic;}/*!sc*/\n",
              ".jlUmJL.dracula .token{color:#ff79c6;}/*!sc*/\n",
              ".jlUmJL.dracula .langague-cpp .token.string{color:#8be9fd;}/*!sc*/\n",
              ".jlUmJL.dracula .langague-c .token.string{color:#8be9fd;}/*!sc*/\n",
              ".jlUmJL.dracula .language-css .token.selector{color:rgba(80,250,123,1);}/*!sc*/\n",
              ".jlUmJL.dracula .language-css .token.property{color:rgba(255,184,108,1);}/*!sc*/\n",
              ".jlUmJL.dracula .language-java span.token.class-name{color:#8be9fd;}/*!sc*/\n",
              ".jlUmJL.dracula .language-java .token.class-name{color:#8be9fd;}/*!sc*/\n",
              ".jlUmJL.dracula .language-markup .token.attr-value{color:rgba(102,217,239,1);}/*!sc*/\n",
              ".jlUmJL.dracula .language-markup .token.tag{color:rgba(80,250,123,1);}/*!sc*/\n",
              ".jlUmJL.dracula .language-objectivec .token.property{color:#66d9ef;}/*!sc*/\n",
              ".jlUmJL.dracula .language-objectivec .token.string{color:#50fa7b;}/*!sc*/\n",
              ".jlUmJL.dracula .language-php .token.boolean{color:#8be9fd;}/*!sc*/\n",
              ".jlUmJL.dracula .language-php .token.function{color:#ff79c6;}/*!sc*/\n",
              ".jlUmJL.dracula .language-php .token.keyword{color:#66d9ef;}/*!sc*/\n",
              ".jlUmJL.dracula .language-ruby .token.symbol{color:#8be9fd;}/*!sc*/\n",
              ".jlUmJL.dracula .language-ruby .token.class-name{color:#cfcfc2;}/*!sc*/\n",
              ".jlUmJL.dracula pre.line-numbers{position:relative;padding-left:3.8em;counter-reset:linenumber;}/*!sc*/\n",
              ".jlUmJL.dracula pre.line-numbers > code{position:relative;white-space:inherit;}/*!sc*/\n",
              ".jlUmJL.dracula .line-numbers .line-numbers-rows{position:absolute;pointer-events:none;top:0;font-size:100%;left:-3.8em;width:3em;-webkit-letter-spacing:-1px;-moz-letter-spacing:-1px;-ms-letter-spacing:-1px;letter-spacing:-1px;border-right:1px solid #999;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}/*!sc*/\n",
              ".jlUmJL.dracula .line-numbers-rows > span{pointer-events:none;display:block;counter-increment:linenumber;}/*!sc*/\n",
              ".jlUmJL.dracula .line-numbers-rows > span:before{content:counter(linenumber);color:#999;display:block;padding-right:0.8em;text-align:right;}/*!sc*/\n",
              ".jlUmJL.dracula div.code-toolbar{position:relative;}/*!sc*/\n",
              ".jlUmJL.dracula div.code-toolbar > .toolbar{position:absolute;top:0.3em;right:0.2em;-webkit-transition:opacity 0.3s ease-in-out;transition:opacity 0.3s ease-in-out;opacity:0;}/*!sc*/\n",
              ".jlUmJL.dracula div.code-toolbar:hover > .toolbar{opacity:1;}/*!sc*/\n",
              ".jlUmJL.dracula div.code-toolbar > .toolbar .toolbar-item{display:inline-block;padding-right:20px;}/*!sc*/\n",
              ".jlUmJL.dracula div.code-toolbar > .toolbar a{cursor:pointer;}/*!sc*/\n",
              ".jlUmJL.dracula div.code-toolbar > .toolbar button{background:none;border:0;color:inherit;font:inherit;line-height:normal;overflow:visible;padding:0;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;}/*!sc*/\n",
              ".jlUmJL.dracula div.code-toolbar > .toolbar a,.jlUmJL.dracula div.code-toolbar > .toolbar button,.jlUmJL.dracula div.code-toolbar > .toolbar span{color:#ccc;font-size:0.8em;padding:0.5em;background:rgba(98,114,164,1);border-radius:0.5em;}/*!sc*/\n",
              ".jlUmJL.dracula div.code-toolbar > .toolbar a:hover,.jlUmJL.dracula div.code-toolbar > .toolbar a:focus,.jlUmJL.dracula div.code-toolbar > .toolbar button:hover,.jlUmJL.dracula div.code-toolbar > .toolbar button:focus,.jlUmJL.dracula div.code-toolbar > .toolbar span:hover,.jlUmJL.dracula div.code-toolbar > .toolbar span:focus{color:inherit;-webkit-text-decoration:none;text-decoration:none;background-color:var(--verde);}/*!sc*/\n",
              ".jlUmJL pre{font-family:'Fira Mono',source-code-pro,Menlo,Monaco,Consolas, 'Courier New',monospace;font-size:0.875rem;padding:1rem;border-radius:4px;line-height:1.5;overflow-x:auto;-webkit-letter-spacing:0px;-moz-letter-spacing:0px;-ms-letter-spacing:0px;letter-spacing:0px;}/*!sc*/\n",
              "@media (max-width:768px){.jlUmJL pre{font-size:0.75rem;padding:0.75rem;}}/*!sc*/\n",
              ".jlUmJL img{max-width:100%;height:auto;display:block;margin-top:1.5rem;margin-bottom:1.5rem;}/*!sc*/\n",
              ".jlUmJL iframe{width:768px;height:430px;max-width:100%;background:black;display:block;margin:auto;border:none;border-radius:4px;overflow:hidden;}/*!sc*/\n",
              ".jlUmJL .twitter-wrapper{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;border-left:none;background:none;padding:none;}/*!sc*/\n",
              ".jlUmJL table{min-width:40%;max-width:100%;border:1px solid var(--border2);border-collapse:collapse;font-size:0.875rem;}/*!sc*/\n",
              ".jlUmJL table thead > tr > th{border-bottom:4px solid var(--border2);}/*!sc*/\n",
              ".jlUmJL table th,.jlUmJL table td{word-break:break-word;padding:0.5rem;}/*!sc*/\n",
              ".jlUmJL table td + td,.jlUmJL table th + th{border-left:1px solid var(--border2);}/*!sc*/\n",
              ".jlUmJL table tr:nth-child(even){background:var(--bg-element2);}/*!sc*/\n",
              ".jlUmJL table tr:nth-child(odd){background:var(--bg-page1);}/*!sc*/\n",
              ".jlUmJL .katex-mathml{display:none;}/*!sc*/\n",
              "data-styled.g114[id=\"sc-fXEqDS\"]{content:\"jlUmJL,\"}/*!sc*/\n",
              "@-webkit-keyframes gsdBxV{0%{opacity:0.5;}50%{opacity:1;}100%{opacity:0.5;}}/*!sc*/\n",
              "@keyframes gsdBxV{0%{opacity:0.5;}50%{opacity:1;}100%{opacity:0.5;}}/*!sc*/\n",
              "data-styled.g124[id=\"sc-keyframes-gsdBxV\"]{content:\"gsdBxV,\"}/*!sc*/\n",
              "body{background:var(--bg-page2);}/*!sc*/\n",
              "data-styled.g149[id=\"sc-global-iqNrnJ2\"]{content:\"sc-global-iqNrnJ2,\"}/*!sc*/\n",
              "body{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,\"Helvetica Neue\",\"Apple SD Gothic Neo\",\"Malgun Gothic\",\"맑은 고딕\",나눔고딕,\"Nanum Gothic\",\"Noto Sans KR\",\"Noto Sans CJK KR\",arial,돋움,Dotum,Tahoma,Geneva,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:var(--text1);box-sizing:border-box;}/*!sc*/\n",
              "*{box-sizing:inherit;}/*!sc*/\n",
              "code{font-family:'Fira Mono',source-code-pro,Menlo,Monaco,Consolas,'Courier New', monospace;}/*!sc*/\n",
              "input,button,textarea{font-family:inherit;}/*!sc*/\n",
              "html,body,#root{height:100%;}/*!sc*/\n",
              "body{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\n",
              "@media (prefers-color-scheme:dark){body{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}}/*!sc*/\n",
              "body[data-theme='light']{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\n",
              "body[data-theme='dark']{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}/*!sc*/\n",
              "data-styled.g150[id=\"sc-global-gYCCRU2\"]{content:\"sc-global-gYCCRU2,\"}/*!sc*/\n",
              "body{background:var(--bg-page2);}/*!sc*/\n",
              "data-styled.g151[id=\"sc-global-iqNrnJ3\"]{content:\"sc-global-iqNrnJ3,\"}/*!sc*/\n",
              "body{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,\"Helvetica Neue\",\"Apple SD Gothic Neo\",\"Malgun Gothic\",\"맑은 고딕\",나눔고딕,\"Nanum Gothic\",\"Noto Sans KR\",\"Noto Sans CJK KR\",arial,돋움,Dotum,Tahoma,Geneva,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:var(--text1);box-sizing:border-box;}/*!sc*/\n",
              "*{box-sizing:inherit;}/*!sc*/\n",
              "code{font-family:'Fira Mono',source-code-pro,Menlo,Monaco,Consolas,'Courier New', monospace;}/*!sc*/\n",
              "input,button,textarea{font-family:inherit;}/*!sc*/\n",
              "html,body,#root{height:100%;}/*!sc*/\n",
              "body{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\n",
              "@media (prefers-color-scheme:dark){body{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}}/*!sc*/\n",
              "body[data-theme='light']{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\n",
              "body[data-theme='dark']{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}/*!sc*/\n",
              "data-styled.g152[id=\"sc-global-gYCCRU3\"]{content:\"sc-global-gYCCRU3,\"}/*!sc*/\n",
              ".fdAPYo{margin-top:2rem;padding:2rem 1.5rem;background:var(--bg-element2);border-radius:8px;box-shadow:0 0 4px 0 rgba(0,0,0,0.06);position:relative;}/*!sc*/\n",
              "@media (max-width:768px){.fdAPYo{padding:1rem;}}/*!sc*/\n",
              ".fdAPYo svg{color:var(--primary1);}/*!sc*/\n",
              ".fdAPYo h2{margin-top:0;color:var(--text2);font-weight:bold;padding-right:2rem;font-size:1.5rem;}/*!sc*/\n",
              ".fdAPYo h2 a{-webkit-text-decoration:none;text-decoration:none;color:inherit;}/*!sc*/\n",
              ".fdAPYo h2 a:hover{color:var(--text3);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n",
              "@media (max-width:768px){.fdAPYo h2{font-size:1.125rem;padding-right:2.5rem;margin-bottom:1.5rem;}}/*!sc*/\n",
              ".fdAPYo .series-corner-image{position:absolute;right:1.5rem;top:0px;}/*!sc*/\n",
              "@media (max-width:768px){.fdAPYo .series-corner-image{right:1rem;width:1.5rem;height:auto;}}/*!sc*/\n",
              "data-styled.g153[id=\"sc-fyrocj\"]{content:\"fdAPYo,\"}/*!sc*/\n",
              ".kHBljz{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n",
              ".kHBljz .series-number{font-size:0.875rem;color:var(--text3);}/*!sc*/\n",
              "data-styled.g154[id=\"sc-iWVNaa\"]{content:\"kHBljz,\"}/*!sc*/\n",
              ".iaYsmD{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:-5px;color:var(--text2);line-height:1;cursor:pointer;}/*!sc*/\n",
              ".iaYsmD svg{margin-right:0.25rem;color:var(--text1);font-size:1.5rem;}/*!sc*/\n",
              ".iaYsmD:hover{color:var(--text1);}/*!sc*/\n",
              ".iaYsmD:hover svg{color:var(--text1);}/*!sc*/\n",
              "data-styled.g155[id=\"sc-jKTccl\"]{content:\"iaYsmD,\"}/*!sc*/\n",
              ".bLPYpH{margin-top:3rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n",
              "data-styled.g156[id=\"sc-bUbRBg\"]{content:\"bLPYpH,\"}/*!sc*/\n",
              ".ezwaSR{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;margin-left:1.125rem;}/*!sc*/\n",
              "data-styled.g157[id=\"sc-tAExr\"]{content:\"ezwaSR,\"}/*!sc*/\n",
              ".eRIqao{width:1.5rem;height:1.5rem;border-radius:50%;outline:none;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;font-size:1.25rem;color:var(--primary1);background:var(--bg-element1);border:1px solid var(--border4);padding:0;cursor:pointer;}/*!sc*/\n",
              ".eRIqao:hover{background:var(--primary1);color:white;}/*!sc*/\n",
              ".sc-dSfdvi + .sc-dSfdvi{margin-left:0.375rem;}/*!sc*/\n",
              ".eRIqao:disabled{cursor:default;background:var(--bg-element2);border:1px solid var(--border4);color:var(--text3);opacity:0.3;}/*!sc*/\n",
              "data-styled.g158[id=\"sc-dSfdvi\"]{content:\"eRIqao,\"}/*!sc*/\n",
              ".homixB{margin-top:0.875rem;margin-bottom:-0.875rem;min-height:0.875rem;}/*!sc*/\n",
              "@media (max-width:768px){.homixB{margin-top:0.5rem;margin-bottom:-0.5rem;min-height:0.5rem;}}/*!sc*/\n",
              "data-styled.g160[id=\"sc-cHzqoD\"]{content:\"homixB,\"}/*!sc*/\n",
              ".cjEODL{margin-top:5.5rem;}/*!sc*/\n",
              "@media (max-width:1024px){.cjEODL .head-wrapper{padding-left:1rem;padding-right:1rem;}}/*!sc*/\n",
              ".cjEODL h1{font-size:3rem;line-height:1.5;-webkit-letter-spacing:-0.004em;-moz-letter-spacing:-0.004em;-ms-letter-spacing:-0.004em;letter-spacing:-0.004em;margin-top:0;font-weight:800;color:var(--text1);margin-bottom:2rem;word-break:keep-all;-webkit-transition:color 0.125s ease-in;transition:color 0.125s ease-in;}/*!sc*/\n",
              "@media (max-width:1024px){.cjEODL{margin-top:2rem;}.cjEODL h1{font-size:2.25rem;}}/*!sc*/\n",
              "data-styled.g161[id=\"sc-JkixQ\"]{content:\"cjEODL,\"}/*!sc*/\n",
              ".gIGUn{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;font-size:1rem;color:var(--text2);display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;}/*!sc*/\n",
              ".gIGUn .information .username{color:var(--text1);font-weight:bold;}/*!sc*/\n",
              ".gIGUn .information .username a{color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\n",
              ".gIGUn .information .username a:hover{color:var(--text2);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n",
              ".gIGUn .information .separator{margin-left:0.5rem;margin-right:0.5rem;}/*!sc*/\n",
              "@media (max-width:768px){.gIGUn .information{font-size:0.875rem;}}/*!sc*/\n",
              "@media (max-width:768px){.gIGUn{margin-bottom:0.75rem;}}/*!sc*/\n",
              "data-styled.g162[id=\"sc-gGPzkF\"]{content:\"gIGUn,\"}/*!sc*/\n",
              ".gNSMhR{max-height:100vh;max-width:100%;width:auto;margin:0 auto;height:auto;object-fit:contain;display:block;margin-top:2rem;}/*!sc*/\n",
              "@media (max-width:768px){.gNSMhR{margin-top:1.5rem;}}/*!sc*/\n",
              "data-styled.g164[id=\"sc-jivBlf\"]{content:\"gNSMhR,\"}/*!sc*/\n",
              ".lhyTWG{-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;display:none;}/*!sc*/\n",
              "@media (max-width:1024px){.lhyTWG{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}}/*!sc*/\n",
              "data-styled.g165[id=\"sc-hkgtus\"]{content:\"lhyTWG,\"}/*!sc*/\n",
              ".bBHgCY{width:768px;margin:0 auto;margin-top:5rem;}/*!sc*/\n",
              "@media (max-width:1024px){.bBHgCY{padding-left:1rem;padding-right:1rem;}}/*!sc*/\n",
              "@media (max-width:768px){.bBHgCY{width:100%;}}/*!sc*/\n",
              "data-styled.g167[id=\"sc-jvvksu\"]{content:\"bBHgCY,\"}/*!sc*/\n",
              ".ewkRvR{margin-top:3rem;color:var(--text1);}/*!sc*/\n",
              ".ewkRvR h4{font-size:1.125rem;line-height:1.5;font-weight:600;margin-bottom:1rem;}/*!sc*/\n",
              "@media (max-width:768px){.ewkRvR{padding-left:1rem;padding-right:1rem;}}/*!sc*/\n",
              "data-styled.g168[id=\"sc-edERGn\"]{content:\"ewkRvR,\"}/*!sc*/\n",
              ".ioCAmf > .buttons-wrapper{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;}/*!sc*/\n",
              "data-styled.g170[id=\"sc-iWBNLc\"]{content:\"ioCAmf,\"}/*!sc*/\n",
              ".jjhhWc{resize:none;padding:1rem;padding-bottom:1.5rem;outline:none;border:1px solid var(--border4);margin-bottom:1.5rem;width:100%;border-radius:4px;min-height:6.125rem;font-size:1rem;color:var(--text1);line-height:1.75;background:var(--bg-element1);}/*!sc*/\n",
              ".jjhhWc::-webkit-input-placeholder{color:var(--text3);}/*!sc*/\n",
              ".jjhhWc::-moz-placeholder{color:var(--text3);}/*!sc*/\n",
              ".jjhhWc:-ms-input-placeholder{color:var(--text3);}/*!sc*/\n",
              ".jjhhWc::placeholder{color:var(--text3);}/*!sc*/\n",
              "@media (max-width:768px){.jjhhWc{margin-bottom:1rem;}}/*!sc*/\n",
              "data-styled.g171[id=\"sc-hYQoXb\"]{content:\"jjhhWc,\"}/*!sc*/\n",
              ".eAtqhB{padding-top:1.5rem;padding-bottom:1.5rem;}/*!sc*/\n",
              ".sc-cVAmsi + .sc-cVAmsi{border-top:1px solid var(--border4);}/*!sc*/\n",
              "data-styled.g176[id=\"sc-cVAmsi\"]{content:\"eAtqhB,\"}/*!sc*/\n",
              ".iNiviY{margin-bottom:1.5rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:justify;-webkit-justify-content:space-between;-ms-flex-pack:justify;justify-content:space-between;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n",
              ".iNiviY .profile{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n",
              ".iNiviY .profile img{width:3.375rem;height:3.375rem;display:block;border-radius:50%;object-fit:cover;}/*!sc*/\n",
              "@media (max-width:768px){.iNiviY .profile img{width:2.5rem;height:2.5rem;}}/*!sc*/\n",
              ".iNiviY .profile .comment-info{margin-left:1rem;line-height:1;}/*!sc*/\n",
              "@media (max-width:768px){.iNiviY .profile .comment-info{margin-left:0.5rem;}}/*!sc*/\n",
              ".iNiviY .profile .comment-info .username{font-size:1rem;font-weight:bold;color:var(--text1);}/*!sc*/\n",
              "@media (max-width:768px){.iNiviY .profile .comment-info .username{font-size:0.875rem;}}/*!sc*/\n",
              ".iNiviY .profile .comment-info .username a{color:inherit;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\n",
              ".iNiviY .profile .comment-info .username a:hover{-webkit-text-decoration:underline;text-decoration:underline;color:var(--text2);}/*!sc*/\n",
              ".iNiviY .profile .comment-info .date{margin-top:0.5rem;color:var(--text3);font-size:0.875rem;}/*!sc*/\n",
              "@media (max-width:768px){.iNiviY .profile .comment-info .date{font-size:0.75rem;}}/*!sc*/\n",
              ".iNiviY .actions{font-size:0.875rem;color:var(--text3);}/*!sc*/\n",
              "@media (max-width:768px){.iNiviY .actions{font-size:0.75rem;}}/*!sc*/\n",
              ".iNiviY .actions span{cursor:pointer;}/*!sc*/\n",
              ".iNiviY .actions span:hover{color:var(--text3);-webkit-text-decoration:underline;text-decoration:underline;}/*!sc*/\n",
              ".iNiviY .actions span + span{margin-left:0.5rem;}/*!sc*/\n",
              "data-styled.g177[id=\"sc-kHxTfl\"]{content:\"iNiviY,\"}/*!sc*/\n",
              ".iYgFNI h1,.iYgFNI h2{font-size:1.75rem;}/*!sc*/\n",
              "@media (max-width:768px){.iYgFNI h1,.iYgFNI h2{font-size:1.5rem;}}/*!sc*/\n",
              "data-styled.g178[id=\"sc-ksHpcM\"]{content:\"iYgFNI,\"}/*!sc*/\n",
              ".mIalr{margin-top:2rem;}/*!sc*/\n",
              "data-styled.g179[id=\"sc-gXRojI\"]{content:\"mIalr,\"}/*!sc*/\n",
              ".kbaMiN{display:-webkit-inline-box;display:-webkit-inline-flex;display:-ms-inline-flexbox;display:inline-flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;color:var(--primary1);font-weight:bold;cursor:pointer;}/*!sc*/\n",
              ".kbaMiN svg{margin-right:0.5rem;}/*!sc*/\n",
              ".kbaMiN:hover{color:var(--primary2);}/*!sc*/\n",
              "data-styled.g180[id=\"sc-bGaVxB\"]{content:\"kbaMiN,\"}/*!sc*/\n",
              ".jGGkyw{margin-top:2.5rem;}/*!sc*/\n",
              "data-styled.g182[id=\"sc-gnnDb\"]{content:\"jGGkyw,\"}/*!sc*/\n",
              ".dhBvrx{position:relative;margin-top:2rem;}/*!sc*/\n",
              "@media (max-width:1024px){.dhBvrx{display:none;}}/*!sc*/\n",
              "data-styled.g184[id=\"sc-igXgud\"]{content:\"dhBvrx,\"}/*!sc*/\n",
              ".eiGuQF{position:absolute;left:-7rem;}/*!sc*/\n",
              "data-styled.g185[id=\"sc-JEhMO\"]{content:\"eiGuQF,\"}/*!sc*/\n",
              ".eRdeFp{width:4rem;background:var(--bg-element2);border:1px solid var(--border4);border-radius:2rem;padding:0.5rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;}/*!sc*/\n",
              "data-styled.g186[id=\"sc-gHjyzD\"]{content:\"eRdeFp,\"}/*!sc*/\n",
              ".SGCHT{height:3rem;width:3rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;background:var(--bg-element1);border:1px solid var(--border3);border-radius:1.5rem;color:var(--text3);cursor:pointer;z-index:5;}/*!sc*/\n",
              ".SGCHT svg{width:24px;height:24px;}/*!sc*/\n",
              ".SGCHT svg.share{width:20px;height:20px;}/*!sc*/\n",
              ".SGCHT:hover{color:var(--text1);border-color:var(--text1);}/*!sc*/\n",
              "data-styled.g187[id=\"sc-itWPBs\"]{content:\"SGCHT,\"}/*!sc*/\n",
              ".lpdPRq{margin-top:0.5rem;color:var(--text2);line-height:1;font-size:0.75rem;margin-bottom:1rem;font-weight:bold;}/*!sc*/\n",
              "data-styled.g188[id=\"sc-dcgwPl\"]{content:\"lpdPRq,\"}/*!sc*/\n",
              ".kPcWLl{position:relative;width:100%;z-index:5;}/*!sc*/\n",
              ".kPcWLl .positioner{position:absolute;}/*!sc*/\n",
              "data-styled.g189[id=\"sc-ehIJor\"]{content:\"kPcWLl,\"}/*!sc*/\n",
              ".jUaBPZ{top:0;left:0;position:absolute;width:48px;height:48px;}/*!sc*/\n",
              "data-styled.g190[id=\"sc-hGnimi\"]{content:\"jUaBPZ,\"}/*!sc*/\n",
              ".crTinq{width:32px;height:32px;border-radius:16px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border:1px solid var(--primary2);font-size:1.5rem;color:var(--primary2);margin-right:1rem;}/*!sc*/\n",
              ".NTSqV{width:32px;height:32px;border-radius:16px;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;border:1px solid var(--primary2);font-size:1.5rem;color:var(--primary2);margin-left:1rem;}/*!sc*/\n",
              "data-styled.g195[id=\"sc-hJhJFJ\"]{content:\"crTinq,NTSqV,\"}/*!sc*/\n",
              ".gkzonb{cursor:pointer;background:var(--bg-element2);box-shadow:0 0 4px 0 rgba(0,0,0,0.06);width:100%;padding-left:1rem;padding-right:1rem;height:4rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-text-decoration:none;text-decoration:none;}/*!sc*/\n",
              ".gkzonb:hover .sc-hJhJFJ{-webkit-animation-duration:0.35s;animation-duration:0.35s;-webkit-animation-name:dRQjsE;animation-name:dRQjsE;-webkit-animation-fill-mode:forwards;animation-fill-mode:forwards;-webkit-animation-timing-function:ease-out;animation-timing-function:ease-out;}/*!sc*/\n",
              ".jOoREI{cursor:pointer;background:var(--bg-element2);box-shadow:0 0 4px 0 rgba(0,0,0,0.06);width:100%;padding-left:1rem;padding-right:1rem;height:4rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;-webkit-text-decoration:none;text-decoration:none;-webkit-flex-direction:row-reverse;-ms-flex-direction:row-reverse;flex-direction:row-reverse;}/*!sc*/\n",
              ".jOoREI:hover .sc-hJhJFJ{-webkit-animation-duration:0.35s;animation-duration:0.35s;-webkit-animation-name:iyGUEJ;animation-name:iyGUEJ;-webkit-animation-fill-mode:forwards;animation-fill-mode:forwards;-webkit-animation-timing-function:ease-out;animation-timing-function:ease-out;}/*!sc*/\n",
              "data-styled.g196[id=\"sc-lhMiDA\"]{content:\"gkzonb,jOoREI,\"}/*!sc*/\n",
              ".lasECz{-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-start;-webkit-box-align:flex-start;-ms-flex-align:flex-start;align-items:flex-start;line-height:1;min-width:0;}/*!sc*/\n",
              ".lasECz .description{font-size:0.75rem;font-weight:bold;color:var(--text2);}/*!sc*/\n",
              ".lasECz h3{width:100%;font-size:1.125rem;color:var(--text2);line-height:1.15;margin:0;margin-top:0.5rem;text-overflow:ellipsis;white-space:nowrap;overflow-x:hidden;overflow-y:hidden;}/*!sc*/\n",
              "@media (max-width:768px){.lasECz h3{font-size:1rem;}}/*!sc*/\n",
              ".cQnPYI{-webkit-flex:1;-ms-flex:1;flex:1;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:flex-end;-webkit-box-align:flex-end;-ms-flex-align:flex-end;align-items:flex-end;line-height:1;min-width:0;}/*!sc*/\n",
              ".cQnPYI .description{font-size:0.75rem;font-weight:bold;color:var(--text2);}/*!sc*/\n",
              ".cQnPYI h3{text-align:right;width:100%;font-size:1.125rem;color:var(--text2);line-height:1.15;margin:0;margin-top:0.5rem;text-overflow:ellipsis;white-space:nowrap;overflow-x:hidden;overflow-y:hidden;}/*!sc*/\n",
              "@media (max-width:768px){.cQnPYI h3{font-size:1rem;}}/*!sc*/\n",
              "data-styled.g197[id=\"sc-cvlWTT\"]{content:\"lasECz,cQnPYI,\"}/*!sc*/\n",
              ".eMFVHd{margin-top:3rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/\n",
              "@media (max-width:768px){.eMFVHd{-webkit-flex-direction:column-reverse;-ms-flex-direction:column-reverse;flex-direction:column-reverse;padding-left:1rem;padding-right:1rem;}}/*!sc*/\n",
              "data-styled.g198[id=\"sc-fTQvRK\"]{content:\"eMFVHd,\"}/*!sc*/\n",
              ".cOfbyG{min-width:0;-webkit-flex:1;-ms-flex:1;flex:1;}/*!sc*/\n",
              ".sc-bUhFKy + .sc-bUhFKy{margin-left:3rem;}/*!sc*/\n",
              "@media (max-width:768px){.cOfbyG{-webkit-flex:initial;-ms-flex:initial;flex:initial;width:100%;}.sc-bUhFKy + .sc-bUhFKy{margin-left:0;margin-bottom:1.5rem;}}/*!sc*/\n",
              "data-styled.g199[id=\"sc-bUhFKy\"]{content:\"cOfbyG,\"}/*!sc*/\n",
              ".kGybnn{margin-top:5.5rem;}/*!sc*/\n",
              ".kGybnn h1{padding-right:2rem;font-size:3.75rem;margin-top:0;margin-bottom:2rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;}/*!sc*/\n",
              ".kGybnn .subinfo{font-size:1rem;}/*!sc*/\n",
              ".kGybnn .tags{font-size:2rem;margin-top:0.875rem;}/*!sc*/\n",
              ".kGybnn .tags .tag-skeleton + .tag-skeleton{margin-left:0.5rem;}/*!sc*/\n",
              ".kGybnn .series{margin-top:2rem;}/*!sc*/\n",
              ".kGybnn .thumbnail{margin-top:2rem;padding-top:52.35%;position:relative;}/*!sc*/\n",
              ".kGybnn .thumbnail .thumbnail-skeleton{position:absolute;top:0;left:0;width:100%;height:100%;}/*!sc*/\n",
              ".kGybnn .contents{margin-top:5rem;}/*!sc*/\n",
              ".kGybnn .contents .line{margin-bottom:0.75rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;font-size:1.125rem;}/*!sc*/\n",
              ".kGybnn .contents .lines + .lines{margin-top:3rem;}/*!sc*/\n",
              "@media (max-width:1024px){.kGybnn{margin-top:2rem;}.kGybnn h1{font-size:2.25rem;}.kGybnn .subinfo{font-size:0.875rem;}.kGybnn .tags{font-size:1.5rem;}}/*!sc*/\n",
              "data-styled.g200[id=\"sc-hRMWxn\"]{content:\"kGybnn,\"}/*!sc*/\n",
              "@media (max-width:768px){.enaCzh{padding-left:1rem;padding-right:1rem;}}/*!sc*/\n",
              "data-styled.g201[id=\"sc-fTxOGA\"]{content:\"enaCzh,\"}/*!sc*/\n",
              ".WNKnM{background:var(--bg-element1);border:1px solid var(--border2);padding-left:0.75rem;padding-right:0.75rem;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:1.5rem;border-radius:0.75rem;outline:none;}/*!sc*/\n",
              ".WNKnM svg{width:0.75rem;height:0.75rem;margin-right:0.75rem;color:var(--text3);}/*!sc*/\n",
              ".WNKnM span{font-size:0.75rem;font-weight:bold;color:var(--text3);}/*!sc*/\n",
              "data-styled.g202[id=\"sc-BHvUt\"]{content:\"WNKnM,\"}/*!sc*/\n",
              ".iA-dFHq{margin-top:1rem;margin-bottom:1rem;}/*!sc*/\n",
              "data-styled.g207[id=\"sc-hKTqa\"]{content:\"iA-dFHq,\"}/*!sc*/\n",
              ".hpspee{margin-top:16rem;margin-bottom:6rem;}/*!sc*/\n",
              "@media (max-width:1024px){.hpspee{margin-top:8rem;margin-bottom:3rem;}}/*!sc*/\n",
              "@media (max-width:768px){.hpspee{margin-top:2rem;}}/*!sc*/\n",
              "data-styled.g208[id=\"sc-gfqkcP\"]{content:\"hpspee,\"}/*!sc*/\n",
              "@-webkit-keyframes dRQjsE{0%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}50%{-webkit-transform:translateX(-8px);-ms-transform:translateX(-8px);transform:translateX(-8px);}100%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}}/*!sc*/\n",
              "@keyframes dRQjsE{0%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}50%{-webkit-transform:translateX(-8px);-ms-transform:translateX(-8px);transform:translateX(-8px);}100%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}}/*!sc*/\n",
              "data-styled.g209[id=\"sc-keyframes-dRQjsE\"]{content:\"dRQjsE,\"}/*!sc*/\n",
              "@-webkit-keyframes iyGUEJ{0%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}50%{-webkit-transform:translateX(8px);-ms-transform:translateX(8px);transform:translateX(8px);}100%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}}/*!sc*/\n",
              "@keyframes iyGUEJ{0%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}50%{-webkit-transform:translateX(8px);-ms-transform:translateX(8px);transform:translateX(8px);}100%{-webkit-transform:translateX(0px);-ms-transform:translateX(0px);transform:translateX(0px);}}/*!sc*/\n",
              "data-styled.g210[id=\"sc-keyframes-iyGUEJ\"]{content:\"iyGUEJ,\"}/*!sc*/\n",
              "body{background:var(--bg-page2);}/*!sc*/\n",
              "data-styled.g211[id=\"sc-global-iqNrnJ4\"]{content:\"sc-global-iqNrnJ4,\"}/*!sc*/\n",
              "body{margin:0;padding:0;font-family:-apple-system,BlinkMacSystemFont,\"Helvetica Neue\",\"Apple SD Gothic Neo\",\"Malgun Gothic\",\"맑은 고딕\",나눔고딕,\"Nanum Gothic\",\"Noto Sans KR\",\"Noto Sans CJK KR\",arial,돋움,Dotum,Tahoma,Geneva,sans-serif;-webkit-font-smoothing:antialiased;-moz-osx-font-smoothing:grayscale;color:var(--text1);box-sizing:border-box;}/*!sc*/\n",
              "*{box-sizing:inherit;}/*!sc*/\n",
              "code{font-family:'Fira Mono',source-code-pro,Menlo,Monaco,Consolas,'Courier New', monospace;}/*!sc*/\n",
              "input,button,textarea{font-family:inherit;}/*!sc*/\n",
              "html,body,#root{height:100%;}/*!sc*/\n",
              "body{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\n",
              "@media (prefers-color-scheme:dark){body{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}}/*!sc*/\n",
              "body[data-theme='light']{--bg-page1:#F8F9FA;--bg-page2:#FFFFFF;--bg-element1:#FFFFFF;--bg-element2:#F8F9FA;--bg-element3:#E9ECEF;--bg-element4:#DEE2E6;--bg-element5:#212529;--bg-element6:#343A40;--bg-element7:#FFFFFF;--bg-element8:#FBFDFC;--bg-invert:#1E1E1E;--bg-inline-code:#E9ECEF;--bg-tag:#F8F9FA;--text1:#212529;--text2:#495057;--text3:#868E96;--text4:#CED4DA;--border1:#343A40;--border2:#ADB5BD;--border3:#DEE2E6;--border4:#F1F3F5;--primary1:#12B886;--primary2:#20C997;--destructive1:#FF6B6B;--destructive2:#FF8787;--button-text:#FFFFFF;--slight-layer:rgba(0,0,0,0.05);--opaque-layer:rgba(249,249,249,0.85);--editor-footer:#FFFFFF;--prism-bg:#fbfcfd;--prism-default-text:#24292e;--prism-selection-bg:rgba(0,0,0,0.15);--prism-code-block-bg:#fbfcfd;--prism-code-1:#969896;--prism-code-2:#24292e;--prism-code-3:#a626a4;--prism-code-4:#63a35c;--prism-code-5:#0184bc;--prism-code-6:#50a14f;--prism-code-7:#a626a4;--prism-code-8:#005cc5;--prism-code-9:#a626a4;--prism-line-number:#585c63;}/*!sc*/\n",
              "body[data-theme='dark']{--bg-page1:#121212;--bg-page2:#121212;--bg-element1:#1E1E1E;--bg-element2:#1E1E1E;--bg-element3:#252525;--bg-element4:#2E2E2E;--bg-element5:#F1F3F5;--bg-element6:#F8F9FA;--bg-element7:#252525;--bg-element8:#0c0c0c;--bg-invert:#FFFFFF;--bg-inline-code:#363636;--bg-tag:#252525;--text1:#ECECEC;--text2:#D9D9D9;--text3:#ACACAC;--text4:#595959;--border1:#E0E0E0;--border2:#A0A0A0;--border3:#4D4D4D;--border4:#2A2A2A;--primary1:#96F2D7;--primary2:#63E6BE;--destructive1:#FFC9C9;--destructive2:#FFA8A8;--button-text:#121212;--slight-layer:rgba(255,255,255,0.1);--opaque-layer:rgba(0,0,0,0.85);--editor-footer:#2E2E2E;--prism-bg:#1E1E1E;--prism-default-text:#e0e6f1;--prism-selection-bg:#383e49;--prism-code-block-bg:#1e1e1e;--prism-code-1:#7c858d;--prism-code-2:#abb2bf;--prism-code-3:#e06c75;--prism-code-4:#d19a66;--prism-code-5:#98c379;--prism-code-6:#56b6c2;--prism-code-7:#c678dd;--prism-code-8:#61afef;--prism-code-9:#c678dd;--prism-line-number:#5c6370;}/*!sc*/\n",
              "data-styled.g212[id=\"sc-global-gYCCRU4\"]{content:\"sc-global-gYCCRU4,\"}/*!sc*/\n",
              "</style><link as=\"style\" data-chunk=\"main\" href=\"https://static.velog.io/static/css/main.e7869632.chunk.css\" rel=\"preload\"/><link as=\"style\" data-chunk=\"main\" href=\"https://static.velog.io/static/css/20.5dbdccff.chunk.css\" rel=\"preload\"/><link as=\"script\" data-chunk=\"main\" href=\"https://static.velog.io/static/js/runtime-main.5e039cd5.js\" rel=\"preload\"/><link as=\"script\" data-chunk=\"main\" href=\"https://static.velog.io/static/js/20.357f3aca.chunk.js\" rel=\"preload\"/><link as=\"script\" data-chunk=\"main\" href=\"https://static.velog.io/static/js/main.7e8cf780.chunk.js\" rel=\"preload\"/><link as=\"script\" data-chunk=\"pages-velog-VelogPage\" href=\"https://static.velog.io/static/js/pages-velog-VelogPage.ebd63700.chunk.js\" rel=\"preload\"/><link as=\"script\" data-chunk=\"PostPage\" href=\"https://static.velog.io/static/js/0.1f8bb2ed.chunk.js\" rel=\"preload\"/><link as=\"script\" data-chunk=\"PostPage\" href=\"https://static.velog.io/static/js/23.3869d1a9.chunk.js\" rel=\"preload\"/><link as=\"script\" data-chunk=\"PostPage\" href=\"https://static.velog.io/static/js/1.5cd4e340.chunk.js\" rel=\"preload\"/><link as=\"script\" data-chunk=\"PostPage\" href=\"https://static.velog.io/static/js/PostPage.3dee536f.chunk.js\" rel=\"preload\"/><link data-chunk=\"main\" href=\"https://static.velog.io/static/css/20.5dbdccff.chunk.css\" rel=\"stylesheet\"/><link data-chunk=\"main\" href=\"https://static.velog.io/static/css/main.e7869632.chunk.css\" rel=\"stylesheet\"/><link href=\"https://static.velog.io/favicon.ico\" rel=\"shortcut icon\"/><link href=\"https://static.velog.io/favicons/apple-icon-152x152.png\" rel=\"apple-touch-icon\" sizes=\"152x152\"/><link href=\"https://static.velog.io/favicons/favicon-32x32.png\" rel=\"icon\" sizes=\"32x32\"/><link href=\"https://static.velog.io/favicons/favicon-96x96.png\" rel=\"icon\" sizes=\"96x96\"/><link href=\"https://static.velog.io/favicons/favicon-16x16.png\" rel=\"icon\" sizes=\"16x16\"/><meta content=\"width=device-width, initial-scale=1\" name=\"viewport\"/><script async=\"\" crossorigin=\"anonymous\" src=\"https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-9161852896103498\"></script><script async=\"\" src=\"https://www.googletagmanager.com/gtag/js?id=G-8D0MD2S4PK\"></script><script>window.dataLayer = window.dataLayer || [];\n",
              "            function gtag(){dataLayer.push(arguments);}\n",
              "            gtag('js', new Date());\n",
              "          \n",
              "            gtag('config', 'G-8D0MD2S4PK');</script></head><body><div id=\"root\"><div class=\"__jazzbar false false\" style=\"width:0%\"></div><div class=\"sc-jObWnj sc-dPiLbb cMpExe\"><div class=\"sc-iwjdpV hcjGyB\"><div class=\"sc-fotOHu evafIC sc-llYSUQ kYqaTx\"><div class=\"sc-hGPBjI cdniDY\"><a class=\"sc-dlVxhl eleXpO\" href=\"/\"><svg fill=\"currentColor\" height=\"192\" viewbox=\"0 0 192 192\" width=\"192\"><path clip-rule=\"evenodd\" d=\"M24 0H168C181.255 0 192 10.7451 192 24V168C192 181.255 181.255 192 168 192H24C10.7451 192 0 181.255 0 168V24C0 10.7451 10.7451 0 24 0ZM49 57.9199V65.48H67L80.6799 142.52L98.5 141.26C116.02 119.06 127.84 102.44 133.96 91.3999C140.2 80.24 143.32 70.9399 143.32 63.5C143.32 59.0601 142 55.7 139.36 53.4199C136.84 51.1399 133.66 50 129.82 50C122.62 50 116.62 53.0601 111.82 59.1799C116.5 62.3 119.68 64.8799 121.36 66.9199C123.16 68.8401 124.06 71.4199 124.06 74.6599C124.06 80.0601 122.44 86.1799 119.2 93.02C116.08 99.8601 112.66 105.92 108.94 111.2C106.54 114.56 103.48 118.7 99.76 123.62L88.0601 57.2C87.1001 52.3999 84.1001 50 79.0601 50C76.78 50 72.3999 50.96 65.9199 52.8799C59.4399 54.6799 53.8 56.3601 49 57.9199Z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg></a><a class=\"user-logo\" href=\"/@minkyu4506\">Minguinho_zeze.log</a></div><div class=\"sc-iJKOTD cxmSXL\"><a class=\"sc-cxpSdN iIPjQP\" href=\"/search?username=minkyu4506\"><svg height=\"17\" viewbox=\"0 0 17 17\" width=\"17\"><path clip-rule=\"evenodd\" d=\"M13.66 7.36a6.3 6.3 0 1 1-12.598 0 6.3 6.3 0 0 1 12.598 0zm-1.73 5.772a7.36 7.36 0 1 1 1.201-1.201l3.636 3.635c.31.31.31.815 0 1.126l-.075.075a.796.796 0 0 1-1.126 0l-3.636-3.635z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg></a><button class=\"sc-egiyK gflbJg\" color=\"darkGray\">로그인</button></div></div></div><div class=\"sc-efQSVx iZAesw\" style=\"margin-top:0;opacity:0\"><div class=\"sc-iwjdpV hcjGyB\"><div class=\"sc-fotOHu evafIC sc-llYSUQ kYqaTx\"><div class=\"sc-hGPBjI cdniDY\"><a class=\"sc-dlVxhl eleXpO\" href=\"/\"><svg fill=\"currentColor\" height=\"192\" viewbox=\"0 0 192 192\" width=\"192\"><path clip-rule=\"evenodd\" d=\"M24 0H168C181.255 0 192 10.7451 192 24V168C192 181.255 181.255 192 168 192H24C10.7451 192 0 181.255 0 168V24C0 10.7451 10.7451 0 24 0ZM49 57.9199V65.48H67L80.6799 142.52L98.5 141.26C116.02 119.06 127.84 102.44 133.96 91.3999C140.2 80.24 143.32 70.9399 143.32 63.5C143.32 59.0601 142 55.7 139.36 53.4199C136.84 51.1399 133.66 50 129.82 50C122.62 50 116.62 53.0601 111.82 59.1799C116.5 62.3 119.68 64.8799 121.36 66.9199C123.16 68.8401 124.06 71.4199 124.06 74.6599C124.06 80.0601 122.44 86.1799 119.2 93.02C116.08 99.8601 112.66 105.92 108.94 111.2C106.54 114.56 103.48 118.7 99.76 123.62L88.0601 57.2C87.1001 52.3999 84.1001 50 79.0601 50C76.78 50 72.3999 50.96 65.9199 52.8799C59.4399 54.6799 53.8 56.3601 49 57.9199Z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg></a><a class=\"user-logo\" href=\"/@minkyu4506\">Minguinho_zeze.log</a></div><div class=\"sc-iJKOTD cxmSXL\"><a class=\"sc-cxpSdN iIPjQP\" href=\"/search?username=minkyu4506\"><svg height=\"17\" viewbox=\"0 0 17 17\" width=\"17\"><path clip-rule=\"evenodd\" d=\"M13.66 7.36a6.3 6.3 0 1 1-12.598 0 6.3 6.3 0 0 1 12.598 0zm-1.73 5.772a7.36 7.36 0 1 1 1.201-1.201l3.636 3.635c.31.31.31.815 0 1.126l-.075.075a.796.796 0 0 1-1.126 0l-3.636-3.635z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg></a><button class=\"sc-egiyK gflbJg\" color=\"darkGray\">로그인</button></div></div></div></div><div class=\"sc-dvQaRk ijHvhk sc-JkixQ cjEODL\"><div class=\"head-wrapper\"><h1>[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving </h1><div class=\"sc-gGPzkF gIGUn\"><div class=\"information\"><span class=\"username\"><a href=\"/@minkyu4506\">minkyu4506</a></span><span class=\"separator\">·</span><span>2021년 8월 5일</span></div><div class=\"sc-hkgtus lhyTWG\"><button class=\"sc-BHvUt WNKnM\" data-testid=\"like-btn\"><svg height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path d=\"M18 1l-6 4-6-4-6 5v7l12 10 12-10v-7z\" fill=\"currentColor\"></path></svg><span>6</span></button></div></div><div class=\"sc-cHzqoD homixB\"><a class=\"sc-fbyfCU jhmYjy\" href=\"/tags/autonomous-driving\">autonomous driving</a><a class=\"sc-fbyfCU jhmYjy\" href=\"/tags/multimodal-learning\">multimodal learning</a><a class=\"sc-fbyfCU jhmYjy\" href=\"/tags/paperreview\">paper_review</a></div><div class=\"sc-igXgud dhBvrx\"><div class=\"sc-JEhMO eiGuQF\"><div class=\"sc-cjrPHo sc-gHjyzD eRdeFp\"><div active=\"false\" class=\"sc-itWPBs SGCHT\" data-testid=\"like\" style=\"transform:scale(1)\"><svg height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path d=\"M18 1l-6 4-6-4-6 5v7l12 10 12-10v-7z\" fill=\"currentColor\"></path></svg></div><div class=\"sc-dcgwPl lpdPRq\">6</div><div class=\"sc-ehIJor kPcWLl\"><div class=\"positioner\"><div class=\"sc-hGnimi jUaBPZ\" style=\"opacity:0;transform:translate(0px, 0px)\"><div class=\"sc-itWPBs SGCHT\"><svg fill=\"currentColor\" height=\"1em\" stroke=\"currentColor\" stroke-width=\"0\" viewbox=\"0 0 512 512\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M504 256C504 119 393 8 256 8S8 119 8 256c0 123.78 90.69 226.38 209.25 245V327.69h-63V256h63v-54.64c0-62.15 37-96.48 93.67-96.48 27.14 0 55.52 4.84 55.52 4.84v61h-31.28c-30.8 0-40.41 19.12-40.41 38.73V256h68.78l-11 71.69h-57.78V501C413.31 482.38 504 379.78 504 256z\"></path></svg></div></div><div class=\"sc-hGnimi jUaBPZ\" style=\"opacity:0;transform:translate(0px)\"><div class=\"sc-itWPBs SGCHT\"><svg fill=\"currentColor\" height=\"1em\" stroke=\"currentColor\" stroke-width=\"0\" viewbox=\"0 0 512 512\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z\"></path></svg></div></div><div class=\"sc-hGnimi jUaBPZ\" style=\"opacity:0;transform:translate(0px, 0px)\"><div class=\"sc-itWPBs SGCHT\"><svg height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path d=\"M21.586 10.461l-10.05 10.075c-1.95 1.949-5.122 1.949-7.071 0s-1.95-5.122 0-7.072l10.628-10.585c1.17-1.17 3.073-1.17 4.243 0 1.169 1.17 1.17 3.072 0 4.242l-8.507 8.464c-.39.39-1.024.39-1.414 0s-.39-1.024 0-1.414l7.093-7.05-1.415-1.414-7.093 7.049c-1.172 1.172-1.171 3.073 0 4.244s3.071 1.171 4.242 0l8.507-8.464c.977-.977 1.464-2.256 1.464-3.536 0-2.769-2.246-4.999-5-4.999-1.28 0-2.559.488-3.536 1.465l-10.627 10.583c-1.366 1.368-2.05 3.159-2.05 4.951 0 3.863 3.13 7 7 7 1.792 0 3.583-.684 4.95-2.05l10.05-10.075-1.414-1.414z\" fill=\"currentColor\"></path></svg></div></div></div></div><div><div class=\"sc-itWPBs SGCHT\" style=\"position:relative\"><svg class=\"share\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\"><path d=\"M5 7c2.761 0 5 2.239 5 5s-2.239 5-5 5-5-2.239-5-5 2.239-5 5-5zm11.122 12.065c-.073.301-.122.611-.122.935 0 2.209 1.791 4 4 4s4-1.791 4-4-1.791-4-4-4c-1.165 0-2.204.506-2.935 1.301l-5.488-2.927c-.23.636-.549 1.229-.943 1.764l5.488 2.927zm7.878-15.065c0-2.209-1.791-4-4-4s-4 1.791-4 4c0 .324.049.634.122.935l-5.488 2.927c.395.535.713 1.127.943 1.764l5.488-2.927c.731.795 1.77 1.301 2.935 1.301 2.209 0 4-1.791 4-4z\" fill=\"currentColor\"></path></svg></div></div></div></div></div><div class=\"sc-fyrocj fdAPYo\"><h2><a href=\"/@minkyu4506/series/논문-리뷰-구현\">논문 리뷰 + 구현</a></h2><svg class=\"series-corner-image\" fill=\"currentColor\" height=\"48\" viewbox=\"0 0 32 48\" width=\"32\"><path d=\"M32 0H0v48h.163l16-16L32 47.836V0z\" fill=\"currentColor\"></path></svg><div class=\"sc-bUbRBg bLPYpH\"><div class=\"sc-jKTccl iaYsmD\"><svg fill=\"currentColor\" height=\"1em\" stroke=\"currentColor\" stroke-width=\"0\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M7 10l5 5 5-5z\"></path></svg>목록 보기</div><div class=\"sc-iWVNaa kHBljz\"><div class=\"series-number\">2<!-- -->/<!-- -->21</div><div class=\"sc-tAExr ezwaSR\"><button class=\"sc-dSfdvi eRIqao\"><svg fill=\"currentColor\" height=\"1em\" stroke=\"currentColor\" stroke-width=\"0\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M15.41 7.41L14 6l-6 6 6 6 1.41-1.41L10.83 12z\"></path></svg></button><button class=\"sc-dSfdvi eRIqao\"><svg fill=\"currentColor\" height=\"1em\" stroke=\"currentColor\" stroke-width=\"0\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M10 6L8.59 7.41 13.17 12l-4.58 4.59L10 18l6-6z\"></path></svg></button></div></div></div></div></div><img alt=\"post-thumbnail\" class=\"sc-jivBlf gNSMhR\" src=\"https://velog.velcdn.com/images/minkyu4506/post/18537d03-8701-4bc7-90aa-f1cd4b26a51a/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.14.18.png\"/></div><div class=\"sc-dvQaRk ijHvhk sc-hKTqa iA-dFHq\"><ins class=\"adsbygoogle\" data-ad-client=\"ca-pub-9161852896103498\" data-ad-format=\"fluid\" data-ad-layout=\"in-article\" data-ad-slot=\"6869845586\" style=\"display:block;text-align:center\"></ins></div><div class=\"sc-jvvksu bBHgCY\"><div class=\"sc-bQtKYq ehISJN\"><div class=\"sc-fXEqDS jlUmJL atom-one\"><p> 안녕하세요. 밍기뉴와제제입니다. </p>\n",
              "<p>정말 오랜만에 돌아왔습니다. 논문은 여러개 봤는데 리뷰할 정도로 깊게 탐구한 논문이 별로 없어 한동안 글을 안쓰다 이번에 논문 세미나를 하다보니 꼼꼼히 살펴본 논문이 생겼습니다. </p>\n",
              "<p> 이번에 리뷰를 하려는 논문은 'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving '라는 논문입니다. 자율주행에 관한 논문이죠. </p>\n",
              "<p> 이름을 보면 대충 짐작 가시겠지만 이 논문은 multimodal, 두가지 데이터를 처리하는 모델을 설계했습니다. 그리고 Transformer도 이용했다는 사실을 짐작할 수 있습니다. </p>\n",
              "<p> 그러면 지금부터 논문 흐름에 맞춰 리뷰를 해보도록 하겠습니다. </p>\n",
              "<h2 id=\"introduction\">Introduction</h2>\n",
              "<hr/>\n",
              "<p> 이 부분에서는 이전까지 자율주행 모델이 사용한 방식들을 소개 후 저자가 소개하는 모델 'transfuser'에 대해 설명합니다. </p>\n",
              "<h3 id=\"한가지-입력값만-받는-모델\">한가지 입력값만 받는 모델</h3>\n",
              "<p> 이전에 Image-only model과 LiDAR-only model이 등장했고 이는 자율주행의 성능을 올리는데 많이 기여했습니다. 허나 이렇게 한가지 데이터만 입력값으로 사용한 모델은 <strong>near-ideal한 움직임을 보이는 객체</strong>들만 있는 환경에서 <strong>제한된 움직임만 필요한 경로</strong>에 주행해야만 높은 성능을 보여준다는 것이었죠. 굉장히 사용하기 까다로웠습니다. </p>\n",
              "<p> 논문에서는 이를 두고 다음과 같이 말했습니다. </p>\n",
              "<blockquote>\n",
              "<p>adversarial scenarios에서 만족스럽지 못한 성능을 보여준다</p>\n",
              "</blockquote>\n",
              "<p>여기서 adversarial scenarios는 운전에 변수가 많이 생기는 환경을 말합니다. 예를 들면 비보호 회전을 해야하는 교차로, 랜덤하게 등장하는 자동차와 보행자 등이 운전에 변수를 주는 요소라 볼 수 있죠.<br/>\n",
              "그러면 이런 부분이 왜 낮은 성능이 나오게끔 하는걸까요? 다음의 그림을 보며 설명해 드리도록 하겠습니다. </p>\n",
              "<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fcda53439-1ba7-461e-a3d2-7b6805019556%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%208.10.17.png\"/></p>\n",
              "<p>위 사진은 논문에서 말한 adversarial scenarios 중 하나입니다.<br/>\n",
              "여기서 초록색 박스 안에 있는 자동차(Ego-Vehicle)와 왼쪽 도로에서 건너오는 빨간색 박스 속 자동차들(Traffic), 그리고 노란색 박스 안에 있는 신호등(Traffic Lights)이 있습니다. 여기서 Ego-Vehicle이 자율주행을 하는 자동차죠.</p>\n",
              "<p>이 상황에서 Ego-Vehicle이 카메라와 LiDAR에서 얻은 데이터를 살펴봅시다. LiDAR의 정의는 다음과 같습니다.</p>\n",
              "<blockquote>\n",
              "<p>LiDAR : Light Detection And Ranging, 레이저를 발사 후 돌아오는 시간을 계산해 주변 물체를 검출하는 센서</p>\n",
              "</blockquote>\n",
              "<p>LiDAR는 3D 데이터인 Point Cloud를 생산하며 여기엔 카메라가 관측할 수 없는 넓은 범위에 존재하는 객체에 대한 정보가 포함되어 있습니다. 그림을 보면 카메라 뷰에서 보이지 않는 자동차(Traffic)을 검출했다는 사실을 확인할 수 있습니다. </p>\n",
              "<p>허나 LiDAR는 카메라가 검출한 신호등을 찾지 못했습니다. 즉, 각 센서별로 얻을 수 있는 정보가 다릅니다. </p>\n",
              "<p>이러한 상황에서 Image-only 혹은 LiDAR-only model을 사용해 자율주행을 한다고 가정해봅시다.<br/>\n",
              "그러면 아래와 같은 문제가 생길 확률이 높습니다.</p>\n",
              "<ul>\n",
              "<li>Image-only model : 왼쪽에서 건너오는 자동차들을 고려하지 않고 운전 -&gt; 추돌 사고</li>\n",
              "<li>LiDAR-only model : 전방에 있는 신호등의 신호를 고려하지 않고 운전 -&gt; 신호 위반</li>\n",
              "</ul>\n",
              "<p>이건 꽤 큰 단점이죠. 그래서 사람들은 이를 해결하기 위한 방법을 찾고자 했습니다. </p>\n",
              "<h3 id=\"두가지-입력값을-함께-사용해보자\">두가지 입력값을 함께 사용해보자</h3>\n",
              "<p>사람들은 자율주행 자동차에 있는 센서에 주목했습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fed409fbd-f733-4294-a832-2410a12035b2%2F0*PjdSdGyiEB6Yg1UX.png\"/><br/>\n",
              "(출처 : <a href=\"https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f\">https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f</a>)</p>\n",
              "<p>위 사진은 자율주행 자동차에 들어있는 센서를 나타낸 그림입니다. 보시면 알겠지만 자율주행 자동차 안에는 수많은 센서들이 들어있습니다. </p>\n",
              "<p>이렇게 많은 센서를 보고 사람들이 생각한게 있습니다. </p>\n",
              "<blockquote>\n",
              "<p>\"자동차에 있는 두개의 센서를 함께 사용해보는건 어떨까?\"</p>\n",
              "</blockquote>\n",
              "<p>그래서 두가지 데이터를 함께 써보자는 아이디어를 떠올렸죠. 그리고 다음과 같은 질문을 남겼습니다. </p>\n",
              "<blockquote>\n",
              "<ul>\n",
              "<li>두가지 데이터를 어떤 방식으로 합쳐서 사용하지?</li>\n",
              "<li>두가지 데이터로 어떤걸 선택하지? </li>\n",
              "</ul>\n",
              "</blockquote>\n",
              "<p>이 질문에 답하기 위해 수많은 논문들이 나왔습니다. 그 중 한가지 논문에 나온 모델 구조에 대해 간단히 소개해드리겠습니다. </p>\n",
              "<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F74c12e61-7d7c-46aa-844e-21a9991b62fd%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%2010.19.35.png\"/><br/>\n",
              "(출처 : Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proc. IEEE Conf. on Computer Vision and Pat- tern Recognition (CVPR), 2017)</p>\n",
              "<p>위 그림에 나온 구조가 두가지 데이터를 처리하는 대부분의 모델이 사용하는 구조입니다. 각 데이터별로 CNN에 넣어 특성맵을 추출한 뒤 원소 단위로 평균값을 낸다든지 더한다든지 하는 방식으로 Fusion해 하나의 출력값으로 만드는 방식이죠. </p>\n",
              "<h3 id=\"여전히-아쉽다\">여전히 아쉽다!</h3>\n",
              "<p>두가지 데이터를 이용하는 방식은 한가지 데이터를 사용하는 방식보다 성능이 좋았습니다. 허나 여전히 단점이 있었습니다. </p>\n",
              "<p>바로 도심 속 운전같이 복잡한 상황에서 운전하기 힘들다는 점이었습니다. </p>\n",
              "<p>교차로에서 운전할 때를 고려해봅시다. 위에 제가 올린 사진과 같은 상황이죠. 여기서 자율주행을 하는 자동차(Ego-Vehicle)는 왼쪽에서 오는 자동차(Traffic)과 신호등의 신호(Traffic Lights) 사이의 연관성을 고려하며 운전을 해야합니다. 허나 각 데이터별로 특성맵을 추출하면 특성을 추출하는 과정에서 모든 정보를 고려할 수 없게 됩니다. </p>\n",
              "<p>즉, 모든 정보를 고려하지 않고 얻어낸 정보를 가지고 운전하기 때문에 사고가 날 확률이 높은 것이죠.</p>\n",
              "<p>이는 데이터의 문제가 아니라 데이터를 처리하는 모델 구조의 문제였습니다. </p>\n",
              "<h3 id=\"transformer\">Transformer</h3>\n",
              "<p>그래서 저자는 Attention mechanism만 사용해 데이터를 처리하는 Transformer를 특성 추출 과정에서 사용하기로 했습니다. </p>\n",
              "<p>Transformer의 self-attention는 입력 값의 각 원소가 전체적인 입력값의 어느 부분을 더 주목해야 하는지 반영하게 해주니 이를 이용해 이미지와 LiDAR 데이터를 전체적으로 고려하며 특성맵을 추출하는 방식을 생각한 것입니다.</p>\n",
              "<p>\"두가지 데이터를 어떤 방식으로 합쳐서 사용하지?\" 에 대한 답변은 Transforemr였습니다.</p>\n",
              "<h3 id=\"single-view-image-and-lidar-inputs\">Single-view image and LiDAR inputs</h3>\n",
              "<p>그리고 \"두가지 데이터로 어떤걸 선택하지?\"에 대한 답변을 해야합니다. </p>\n",
              "<p>저자는 이에 \"Single-view image and LiDAR를 입력 데이터로 사용한다\"고 말했습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F74af93a1-93f3-4d49-a6e9-dc0fa9a07905%2F%EC%9E%90%EB%A3%8C.png\"/><br/>\n",
              "이 둘을 사용하겠다는 것이죠.</p>\n",
              "<p>왜 Single-view image and LiDAR를 선택한 걸까요? 저자는 이 둘이 서로가 서로에게 부족한 점을 채워주는 상호보완성이 있기 때문에 선택했다고 말했습니다. </p>\n",
              "<p>즉, 이 둘을 입력데이터로 사용해 얻는 정보의 양이 제일 많다고 판단한 것이죠. </p>\n",
              "<h3 id=\"transfuser\">Transfuser</h3>\n",
              "<p>이제 저자가 생각해낸 모델을 정리해봅시다. </p>\n",
              "<blockquote>\n",
              "<p>입력 데이터로 Single-view image and LiDAR를 받아 특성을 추출하는 과정에서 Transformer를 사용해 전체적인 정보를 고려하는 모델</p>\n",
              "</blockquote>\n",
              "<p>한문장으로 간단히 정리됩니다. 저자는 이렇게 설계된 모델을 <strong>Transfuser</strong>라고 정의했습니다.</p>\n",
              "<p>여기까지 모델의 Introduction 부분이었습니다. 깔끔히 쓰고 싶었는데 쉽지않네요. 허허...</p>\n",
              "<p>그럼 이제 Transfuser가 포함된 자율주행 모델이 만들어지는 과정을 소개한 Method 항목을 소개해 드리도록 하겠습니다. </p>\n",
              "<h2 id=\"method\">Method</h2>\n",
              "<hr/>\n",
              "<p>원래 Releated work를 슥 살펴보고 Method로 넘어가야 하는데 그러면 분량이 너무 많아져서 바로 Method로 건너왔습니다. 저도 자율주행 모델에 대해 잘 감이 안잡힌 상태에서 이 논문을 읽어서 Related work 부분이 논문 이해에 꽤나 도움이 되었습니다. 관심 있으신 분들은 따로 찾아서 읽어보시는걸 추천드립니다. </p>\n",
              "<p>아무튼, 이제 Method에 대해 설명해 드리도록 하겠습니다.</p>\n",
              "<p>Method에는 Transformer를 이용해 자율주행 모델을 만드는 일련의 과정이 적혀있습니다. </p>\n",
              "<p>모델을 만드는 과정은 다음과 같이 3단계로 나눌 수 있습니다. </p>\n",
              "<ol>\n",
              "<li>Task 설정, 데이터셋 구성(Problem Setting)</li>\n",
              "<li>데이터셋 전처리(Input and Output Parameterization)</li>\n",
              "<li>모델 설계(Multi-Modal Fusion Transformer + Waypoint Prediction Network)</li>\n",
              "</ol>\n",
              "<p>그러면 'Task 설정'부터 설명해 드리도록 하겠습니다.</p>\n",
              "<h3 id=\"1-problem-setting\">1. Problem Setting</h3>\n",
              "<p>모델이 해결할 Task를 설정하고 이를 위한 학습법, 그리고 필요한 데이터셋을 설명하는 부분입니다. </p>\n",
              "<p>저자는 <strong>point-to-point navigation</strong>를 모델이 수행할 Task로 설정했습니다. </p>\n",
              "<p>저자는 point to point navigation이 목표지점까지 waypoint를 따라 사고 없이 완주하는 것이라 말했습니다. 여기서 사고는 다른 객체(자동차, 사람 등)과 충돌하거나 교통법규를 어기는 것을 말하죠. </p>\n",
              "<p>그리고 이를 학습하는 방법으로 imitation learning을 선택했습니다. imitation learning이란 강화학습의 일종인데요, 의미 그대로 해당 task에서 전문가(Expert)가 하는걸 따라하는 학습법입니다. </p>\n",
              "<p>강화 학습은 학습 주체인 agent와 agent가 행동하는데 규범이 되는 policy, 행동의 결과인 action, action으로 인한 상태 state, 그리고 state에 대한 보상 reward가 있습니다.여기서 보상 reward를 가장 많이 받는 방향으로 학습시키는 것이 목표죠. </p>\n",
              "<p>reward를 많이 받도록 만드는 방식은 여러가지가 있습니다. 그중 하나가 행동 규범힌 policy를 학습가능한 상태(parameterize)로 만드는 것이죠. </p>\n",
              "<p>imitation learning도 그 방식을 사용하고 있으며 논문에서는 다음과 같이 설명합니다. </p>\n",
              "<blockquote>\n",
              "<p>Policy를 Expert의 policy를 따라하게끔 학습하는 것</p>\n",
              "</blockquote>\n",
              "<p>그런데 여기서 궁금증이 생겼습니다. 왜 imiation learning을 선택한거지? 그래서 찾아봤습니다.<br/>\n",
              "찾아보니까 이렇게 policy를 학습 대상으로 삼아 학습시키는 방식은 <strong>고차원 데이터를 처리하고 연속된 action을 해야하는 모델의 학습에 적합</strong>하다고 합니다. </p>\n",
              "<p>이미지라는 고차원 데이터를 처리해 연속된 action이 필요한 운전을 하는 자율주행 모델에 적합한방식이라 선택한게 아닌가 싶습니다. </p>\n",
              "<p>그러면 이제 저자가 imitation learning을 사용한 학습과정을 설명해 드리도록 하겠습니다.</p>\n",
              "<h4 id=\"데이터셋-수집\">데이터셋 수집</h4>\n",
              "<p>우선 데이터셋을 수집해야하죠? 학습을 위한 학습 데이터셋과 평가를 위한 테스트 데이터셋이 필요합니다. </p>\n",
              "<p>데이터셋은 자율주행 오픈소스 시뮬레이터 CARLA(<a href=\"https://carla.org\">https://carla.org</a>)에 있는 가상 환경에서 수집<br/>\n",
              "합니다. 별다른 이유는 적지 않았지만 아무래도 사고가 날 수 있는 상황에 대한 데이터도 모으기 때문에 그런게 아닌가 싶네요. </p>\n",
              "<p>여튼, CARLA에 있는 가상환경에서 Expert가 주행하며 데이터를 모읍니다. imitation learning에서 말씀드린 Expert 맞습니다. </p>\n",
              "<p>Expert는 가상환경을 주행하며 입력 데이터와 출력 데이터를 수집합니다. 그렇게 해서<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fbf940494-966f-4a2d-ab3e-15adb7e16afe%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.06.20.png\"/><br/>\n",
              "위와 같은 데이터셋 D를 만들어줍니다. </p>\n",
              "<p>여기서 X는 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 한 시점(single time step)에 이미지 한장, point cloud 하나가 있는 것이죠.</p>\n",
              "<p>그리고 W는 T개의 waypoint가 모인 w로 이루어져 있습니다. 즉, 이미지와 point cloud를 하나씩 넣으면 출력값으로 T개의 Waypoint가 나오는 모델을 만들겠다는 뜻이죠.</p>\n",
              "<h4 id=\"학습-방법\">학습 방법</h4>\n",
              "<p>이렇게 데이터셋을 모았으니 학습을 시켜봅시다. 학습 방식은 다음과 같이 정의할 수 있습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F42199532-a602-4a20-89e2-8a21126a3759%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.11.08.png\"/><br/>\n",
              "여기서 L은 Loss함수입니다. 그러니까 Expert가 주행한 경로와 우리가 만든 agent의 policy에 따른 action, 다시 말해 <strong>우리가 만든 모델이 예측한 주행 경로 사이의 loss가 최소가 되게끔 policy를 학습시키겠다</strong>는 뜻이죠. </p>\n",
              "<p>저자는 이러한 학습 방식을 지도학습의 방식이라고 말했습니다. Expert의 데이터를 label data, 내가 만든 모델의 데이터가 prediction data라고 보면 저자의 말이 이해가 되시지 않을까 싶습니다. </p>\n",
              "<p>그래서 강화학습은 어떻게 학습 시키는걸까 찾아봤습니다. 강화학습은 데이터셋을 사용하지 않고 학습하기 때문에 매 순간 자기 자신이 만든 state와 reward를 보고 다음 action에 반영하며 점점 높은 reward만 받는 모델로 학습되는 방식을 사용한다는 사실을 알아냈습니다. 지도학습으로만 모델을 학습시켜본 저에게 있어서 강화학습은 상당히 신기한 방식입니다. </p>\n",
              "<h4 id=\"자율-주행\">자율 주행</h4>\n",
              "<p>저자는 학습 이후 어떻게 자율주행에 사용할지도 설명해 주었습니다.<br/>\n",
              "저자는 모델이 예측한 경로를 inverse dynamics model에 넣어 얻은 action으로 주행을 한다고 말했고 이 때 inverse dynamics model을 PID controller로 구현했다고 설명했습니다. </p>\n",
              "<p>PID controller는 간단한게 말해 주어진 출력값을 위해 필요한 제어값(가속, 감속, 회전 등)을 구하는 요소라고 보시면 됩니다. 자세한 설명은 <a href=\"https://ko.wikipedia.org/wiki/PID_%EC%A0%9C%EC%96%B4%EA%B8%B0\">여기</a>서 확인하실 수 있습니다. </p>\n",
              "<p>저자는 이러한 과정을 다음과 같은 식으로 나타냈습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fa7c85e89-258f-4110-991f-1a7316121323%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.23.16.png\"/><br/>\n",
              "action = PID(예측 경로)인 것이죠. 여기서 action은 agent가 행한 action과 동일한 개념입니다. </p>\n",
              "<h4 id=\"global-planner\">Global planner</h4>\n",
              "<p>마지막에 등장하는 문단인데 처음에는 이게 왜 있는건가 싶었습니다. </p>\n",
              "<p>읽어보니 저자들은 CARLA의 표준 프로토콜을 따르고 목표 지점이 GPS 좌표로 제공되며 목표 지점과 자동차가 안내한 지점이 몇백미터 떨어질 수 있다고 나와있습니다. </p>\n",
              "<p>다른 부분은 그러려니 하고 읽었는데 마지막 부분 '목표 지점과 안내 지점이 몇백미터 떨어질 수 있다'는 말이 거슬렸습니다. 도대체 뭔 뜻이지? </p>\n",
              "<p>제가 논문 세미나를 할 때 이 논문을 가지고 했는데요, 이에 관해 세미나 계신 분들께 여쭤보고 답을 들었는데도 이해가 제대로 안되서 구글에 검색까지 해봤습니다.</p>\n",
              "<p>구글에 검색을 해보니 다음과 같은 글을 발견했습니다. </p>\n",
              "<blockquote>\n",
              "<p>The global planner plans a global path around obstacles</p>\n",
              "</blockquote>\n",
              "<p>대충 번역하면 장애물을 돌아가는 global path를 생성하는게 global planner라고 하네요. </p>\n",
              "<p>아마 <strong>목표 지점에 가기 힘들면 그 근처로 안내할 수 있음</strong>을 말하고 싶어서 이 부분을 추가한게 아닌가 싶습니다.</p>\n",
              "<p>여기까지 Problem Setting이었습니다.</p>\n",
              "<h3 id=\"2-input-and-output-parameterization\">2. Input and Output Parameterization</h3>\n",
              "<p>이제 데이터셋을 어떻게 만들었는지? 정확히는 모델의 학습에 사용하기 위해 어떤 작업을 했는지 설명해 드리도록 하겠습니다.</p>\n",
              "<h4 id=\"input-representation\">Input Representation</h4>\n",
              "<p>우선 입력 데이터부터 설명해 드리고자 합니다.</p>\n",
              "<p>입력 데이터는 앞서 말씀드렸듯 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 카메라 이미지는 2D 데이터고 Point cloud는 3D 데이터라 각자 처리방식이 다릅니다. </p>\n",
              "<ol>\n",
              "<li>\n",
              "<p>카메라 이미지<br/>\n",
              "카메라에서 촬영된 이미지는 400X300 사이즈인데요, 여기서 가운데 256X256 영역만 추출해서 사용합니다. 왜냐하면 렌즈 구조상 외곽 이미지는 왜곡 되어있기 때문입니다. 이렇게 <strong>256X256X3</strong> 사이즈의 데이터를 얻습니다. </p>\n",
              "</li>\n",
              "<li>\n",
              "<p>LiDAR Point Cloud<br/>\n",
              "저자는 LiDAR에서 얻은 Point Cloud 중 자동차의 전면 32m, 좌우 측면 각 16m씩 해서 총 32m X 32m 영역만 사용합니다. 그리고 이를 2D 데이터로 변환해주는데요, 한 셀당 0.125m X 0.125m로 해서 256 X 256 픽셀 데이터로 변환해줍니다.<br/>\n",
              "그리고 Point Cloud는 3D 데이터라 높이에 관한 데이터도 있는데요, 저자는 이를 2개의 채널에 담았습니다. 하나는 지면 위(+) 높이 데이터, 다른 하나는 지면 밑(-) 높이 데이터를 담았죠.<br/>\n",
              "이렇게 <strong>256X256X2</strong> 사이즈의 데이터를 얻습니다.</p>\n",
              "</li>\n",
              "</ol>\n",
              "<h4 id=\"output-representation\">Output Representation</h4>\n",
              "<p>출력값 양식을 정의하는 부분입니다. </p>\n",
              "<p>출력값, 즉 waypoint는 BEV space에서 (x,y)의 양식을 지닙니다. </p>\n",
              "<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F143364fc-ea4f-4738-8c28-ad2d826983ed%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.59.06.png\"/><br/>\n",
              "이런 방식으로 나온다는 뜻이죠. 중심에 자동차가 있고 앞에 빨간 점으로 자동차가 이동할 waypoint가 나와 있습니다. 이 때 waypoint의 집합 trajectory는 다음과 같이 정의됩니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fe1e69200-2870-4820-87fb-71022c6b7fa2%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%2010.05.40.png\"/></p>\n",
              "<p>앞서 데이터셋을 구성할 때 T개의 waypoint 예측값이 모인 데이터셋을 만든다고 말씀드렸는데요, 저자는 T를 4로 정의했습니다. 왜 T를 4로 정의했냐면 예측 궤적을 가기 위한 제어값을 얻는 PID controller가 요구하는 waypoint의 default number가 4라서 T를 4로 설정했다고 말했습니다.</p>\n",
              "<p>여기까지 Input and Output Parameterization였습니다. </p>\n",
              "<h3 id=\"3-모델-설계\">3. 모델 설계</h3>\n",
              "<p>다음으로 모델의 구조에 대해 설명해 드리고자 합니다. </p>\n",
              "<p>모델의 구조는 크게 두 가지로 나눌 수 있습니다. 하나는 <strong>Multi-Modal Fusion Transformer</strong>고 다른 하나는 <strong>Waypoint Prediction Network</strong>입니다. </p>\n",
              "<p>Multi-Modal Fusion Transformer는 저자가 새로운 제안한 Transfuser를 말하는 것이구요, Waypoint Prediction Network는 Transfuser에서 얻은 값을 가지고 경로를 예측하는 모델입니다. </p>\n",
              "<p>우선 Transfuser부터 먼저 설명해 드리도록 하겠습니다. </p>\n",
              "<h4 id=\"1-multi-modal-fusion-transformertransfuser\">1. Multi-Modal Fusion Transformer(Transfuser)</h4>\n",
              "<p>Transfuser는 다음과 같은 구조를 가지고 있습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F98673fc0-6990-40b0-869c-3052443d7086%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.46.13.png\"/><br/>\n",
              "제가 Trnafuser는 특성을 추출하는 과정에서 Transformer를 이용해 전체 데이터를 고려하는 모델이라고 말씀드렸는데요, 이 그림을 보시면 \"아...이런 뜻이구나\" 이해하시지 않을까 싶습니다. </p>\n",
              "<p>여기서 눈여겨볼 항목은 당연히 저자가 강조한 Transformer를 이용해 전체 데이터 정보를 각 특성맵에 반영해주는 부분입니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F09f43877-9853-4ba7-8912-21a2f59d9700%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.51.55.png\"/> <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F9faf9fb5-3e84-4ddd-9beb-79600e08b92f%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.55.19.png\"/><br/>\n",
              "이 부분을 말하는 것이죠. 아래 그림은 윗 그림에서 Transformer 부분을 강조한 그림입니다.</p>\n",
              "<p>여기서 진행되는 연산의 순서를 말씀드리면 다음과 같습니다. </p>\n",
              "<ol>\n",
              "<li>Conv + Pool 연산으로 특성맵 추출</li>\n",
              "<li>추출한 특성맵의 사이즈를 8 X 8로 압축 후 Transformer에 입력값으로 보냄</li>\n",
              "<li>각 데이터에서 보내준 8 X 8 크기의 특성맵 2개를 합체 = 16 X 8 사이즈의 특성맵 생성</li>\n",
              "<li>16X8 벡터를 Positional Embedding 후 Linear layer를 이용해 자동차의 현재 속도를 Embedding vector에 projection</li>\n",
              "<li>Transformer에 넣어 self-attention 연산 =&gt; Embedding vector내 원소별로 전체 데이터(이미지 + LiDAR)에 대한 Attention이 반영됨. 사이즈는 16 X 8로 같음</li>\n",
              "<li>Attention이 반영된 Embedding vector를 Image, LiDAR별로 나눔 -&gt; 8 X 8 사이즈의 벡터가 2개 생성</li>\n",
              "<li>8 X 8 사이즈의 벡터를 압축하기 전의 크기로 scale up </li>\n",
              "<li>원래 특성맵과(1에서 추출한 특성맵) element-wise summation(원소끼리 더함)</li>\n",
              "</ol>\n",
              "<br/>\n",
              "<p>코드로 나타내면 상당히 간단해집니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Ff0cdda7c-89a7-4c60-8d4d-4e8d4826652d%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.09.01.png\"/><br/>\n",
              "아무튼 간단해집니다. </p>\n",
              "<p>여튼, 이런 과정을 총 4번 반복합니다. 더 해도 안된다는 법은 없는데 저자는 4번 반복하라고 말했습니다. </p>\n",
              "<p>4번 반복한 뒤 마지막에 Average Pooling + Flatten연산을 해서 1 X 1 X 512 벡터를 2개 생성합니다. 이미지에서 얻고 LiDAR에서 얻으니까 총 2개를 얻는 것이죠. </p>\n",
              "<p>이 2개의 벡터를 element-wise summation해서 하나의 1 X 1 X 512 벡터로 만들어줍니다. </p>\n",
              "<p>이렇게 우리는 최종 출력값 1 X 1 X 512 벡터를 얻었습니다. 이제 Waypoint Prediction Network를 확인해보도록 합시다. </p>\n",
              "<h4 id=\"2-waypoint-prediction-network\">2. Waypoint Prediction Network</h4>\n",
              "<p>앞서 우리는 Transfuser에서 1 X 1 X 512 사이즈의 벡터를 얻었습니다. </p>\n",
              "<p>이 벡터는 Waypoint Prediction Network에 쓰입니다. </p>\n",
              "<p>Waypoint Predictoin Network는 다음과 같은 구조를 가지고 있습니다. </p>\n",
              "<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fe2a83385-fdf5-4e03-9f20-8ae87396a950%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.47.15.png\"/></p>\n",
              "<p>보시면 MLP와 GRU로 이루어졌다는 사실을 확인하실 수 있습니다. </p>\n",
              "<ol>\n",
              "<li>\n",
              "<p>MLP<br/>\n",
              "MLP는 3개의 Linear Layer로 이루어져 있습니다. MLP는 입력값으로 들어오는 1 X 1 X 512 사이즈의 벡터를 1 X 1 X 64 벡터로 압축해줍니다. 계산의 효율성을 위해 줄여주는 겁니다.<br/>\n",
              "코드는 다음과 같습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fcd1db45c-1c0c-4fe5-b9bc-64866cb05b21%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.20.57.png\"/></p>\n",
              "</li>\n",
              "<li>\n",
              "<p>GRU<br/>\n",
              "GRU는 RNN에서 많이 쓰였던 LSTM을 개선한 알고리즘 입니다. 시계열 데이터를 처리하는데 적합한 알고리즘이죠. 이걸 레이어 형식으로 추가했습니다.<br/>\n",
              "GRU는 현 시점의 입력 데이터와 hidden state를 받아 연산을 처리합니다. waypoint prediction network에서는 자동차의 좌표와 목표 지점의 좌표를 더한 값을 입력 값으로 하였습니다. 이 때 좌표의 단위는 gps입니다.<br/>\n",
              "여기서 흥미로운 점이 있습니다. 바로 첫 시점의 입력 데이터 중 자동차의 좌표가 (0,0)이라는 점입니다. 이는 자동차가 좌표계의 원점에 있다고 가정했기 때문입니다.<br/>\n",
              "그러니까 <strong>입력 데이터를 넣는 시점에서 자동차의 위치가 x = (0,0)에 있다고 보는 것이고 (0,0)를 기준으로 향후 4 time의 waypoint를 예측하는 것</strong>이라 보시면 되겠습니다.<br/>\n",
              "다시 본론으로 돌아옵시다. 입력 데이터를 알아봤으니 이제 hidden state로 넘어가야죠. hidden state는 앞서 얻은 1 X 1 X 64 벡터로 초기화해줍니다. 우리가 입력 데이터로 얻은 특성을 hidden state를 초기화하는데 사용하는 겁니다.<br/>\n",
              "이렇게 입력값을 넣어주면 출력값이 나올겁니다. 이 출력값을 Linear layer에 넣으면 현 시점의 자동차에서 움직여야할 좌표 dx가 생성됩니다.<br/>\n",
              "이 dx에 기존 자동차의 좌표 x에 더하면 이제 다음 시점에 이동할 waypoint가 되는 겁니다.<br/>\n",
              "이 waypoints는 다음 시점에서 현재 좌표가 되겠죠? next_x = x + dx인 겁니다.<br/>\n",
              "여튼 이 과정을 4번 반복해 waypoint 4개를 얻습니다.</p>\n",
              "</li>\n",
              "</ol>\n",
              "<h4 id=\"plus--pid-controller\">Plus : PID controller</h4>\n",
              "<p>모델의 구조에는 없지만 자율주행을 수행하기 위해 꼭 있어야할 PID controller입니다.<br/>\n",
              "앞서 예측한 경로를 PID controller에 넣어 주행에 필요한 제어값을 얻는다고 말씀드렸습니다.<br/>\n",
              "실은 그 이상으로 설명드릴게 없습니다. 그러니 여기서는 구현된 코드를 보여드리고 넘어가도록 하겠습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F3fa43398-54ed-4ef2-ac1d-9e34b8896814%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.57.46.png\"/><br/>\n",
              "코드의 return 부분을 보시면 운전에 필요한 데이터들이 나와있습니다. steer는 차를 얼마나 회전할지 나타낸거고 throttle는 엔진에 들어갈 공기량을 제어하니까 가속을 얼마나 할지 나타낸거고 brake는 감속을 얼마나 할지 나타내는 것이죠. </p>\n",
              "<p>그런데 낯선 데이터가 하나 있습니다. 바로 metadata입니다. 슥 살펴보니 steer, throttle, brake만으로 설명이 안되는 정보를 보충 설명해주는 데이터인듯 합니다. 아마 저자가 실험했을 때 제어값의 정보 부족으로 좀 애먹었던게 아닌가 싶네요. 제 추측입니다. </p>\n",
              "<p>여기까지 모델의 구조를 살펴봤습니다. </p>\n",
              "<h2 id=\"experiment\">Experiment</h2>\n",
              "<hr/>\n",
              "<p>이제 실험 부분을 설명해 드리고자 합니다. </p>\n",
              "<p>여기서는 실험 세팅(experimental setup), 성능 비교(Results), 입력 데이터간 상호보완성 비교(Attention Map Visualizations), 구성 요소를 하나씩 빼면서 성능 확인(Ablation Study) 순으로 내용이 전개됩니다. </p>\n",
              "<h3 id=\"1-실험-세팅experimental-setup\">1. 실험 세팅(experimental setup)</h3>\n",
              "<p>여기서는 성능 측정을 위해 모델이 해야할 task와 이를 위해 필요한 데이터셋, 평가 지표와 성능을 비교할 모델을 소개하고 있습니다. </p>\n",
              "<h4 id=\"task\">Task</h4>\n",
              "<p>모델이 수행할 task는 다양한 주행 환경에서 제한 시간 안에 운전 규정을 시키며 주행하는 것입니다. </p>\n",
              "<p>여기서 주행 경로는 gps좌표 형식의 waypoint의 집합으로 제공되며 주행 도중에 일정 확률로 자동차나 보행자가 등장할 수 있고 차선 변경, 회전 등 주행 중에 충분히 일어날 수 있는 상황도 경로에 포함되어 있습니다. </p>\n",
              "<p>앞서 논문에서 말한 '복잡한 운전 상황'속 주행 성능을 평가하는거라 생각하시면 됩니다. </p>\n",
              "<h4 id=\"dataset\">Dataset</h4>\n",
              "<p>데이터셋을 모으는 방법이 적혀있습니다. </p>\n",
              "<p>앞서 말씀드렸듯 Expert가 CARLA에 있는 가상환경에서 주행하며 데이터를 모은다고 말씀드렸습니다. 여기서 더 자세히 써보도록 하겠습니다. </p>\n",
              "<p>CARLA에는 주행을 할 수 있는 8개의 Town이 있습니다. 8개의 가상환경이 있는 것이죠. 각 town의 특성은 다음과 같습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Ff9052600-3c62-40b6-bea6-c9dfb0c40ade%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%207.26.46.png\"/><br/>\n",
              "각자 특성을 가지고 있죠. Expert는 여기서 Town 01, 02, 03, 04, 06, 07, 10에 사전 정의된 경로들을 달리며 학습용 데이터셋을 수집합니다. </p>\n",
              "<p>그리고 학습용 데이터셋으로 모델을 훈련시키고 난 뒤 Town05에서 주행 성능을 평가합니다. </p>\n",
              "<p>Town05는 1차선부터 n차선, 그리고 일반도로부터 고속도로까지 다양한 도로가 있기 때문에 주행 성능을 평가하는 맵으로 선정했다고 말했습니다. </p>\n",
              "<p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F7fe65901-ef85-46ef-b802-861ba297b5e9%2FTown05.jpg\"/><br/>\n",
              "Town05에 깔려있는 도로를 나타낸 사진입니다. 다양한 도로로 구성되어 있음을 확인할 수 있습니다. </p>\n",
              "<p>저자는 어떠한 주행 경로에서 성능을 평가하는지도 설명했습니다. 저자는 단거리 경로와 장거리 경로를 각 10개씩 뽑았고 이를 Town05 Short, Town05 Long이라 이름 지었습니다. 특징은 다음과 같습니다.</p>\n",
              "<ul>\n",
              "<li>Town05 Short : 주행 거리 100~500m, 교차로 3개</li>\n",
              "<li>Town05 Long : 주행거리 1~2km, 교차로 10개</li>\n",
              "</ul>\n",
              "<p>그리고 주행 중에 자동차나 사람이 등장할 수 있다는 공통점이 있습니다. </p>\n",
              "<p>마지막으로 날씨입니다. 맑은 날 주행하는거랑 비오는 날에 주행하는건 난이도가 어느정도 차이가 나는데요, 저자는 <strong>동적인 객체와 신호등에 대한 주행 성능 평가에 집중할 것이기 때문에</strong> 날씨는 '항상 맑음'으로 고정한다고 말했습니다. </p>\n",
              "<p>개인적으로 아쉬운 부분이었습니다. 날씨도 변수를 줘서 실험을 했으면 더 좋지 않았을까 생각합니다. </p>\n",
              "<h4 id=\"metrics\">Metrics</h4>\n",
              "<p>구글에 검색해보니 '측정 수단'이라는 뜻으로 해석됩니다. 즉, 평가지표입니다. </p>\n",
              "<p>저자는 평가 지표로 RC, DS, Infraction Count를 선택했습니다. 하나씩 설명해 드리도록 하겠습니다. </p>\n",
              "<ol>\n",
              "<li>RC(Route Completion) : 주행 경로를 몇%나 주행했는지 나타내는 수치입니다. </li>\n",
              "<li>DS(Driving Score) : RC에 infraction multiplier를 곱한 값입니다. 여기서 infraction multiplier는 객체와의 충돌, 경로 이탈, 차선 침법, 신호 위반을 설명하는 수치라고 합니다. </li>\n",
              "<li>Infraction Count : 따로 설명은 해놓지 않았지만 사고 종류별 발생 횟수를 측정한게 아닐까 싶습니다. </li>\n",
              "</ol>\n",
              "<h4 id=\"baselines\">Baselines</h4>\n",
              "<p>Transfuser가 포함된 자율주행 모델과 성능을 비교할 모델을 적어놓았습니다. 5개의 모델과 비교합니다. </p>\n",
              "<p>모델 종류는 다음과 같습니다. </p>\n",
              "<ul>\n",
              "<li>CILRS : 카메라 이미지만 입력값으로 받으며 navigational command의 통제 아래 자율주행을 수행합니다. </li>\n",
              "<li>LBC : 원래 Bird's view image와 front image를 받았는데 논문(LBC)의 저자가 왼쪽 45도, 오른쪽 45도 각도에서 찍은 전면 카메라 이미지와 target heatmap을 입력값으로 받는걸로 바꿨습니다. </li>\n",
              "<li>AIM : 전면 카메라 이미지만 입력데이터로 받습니다. 단일 입력값을 받는 모델 중 가장 성능이 좋습니다. </li>\n",
              "<li>Late Fusion : 이제부터 두가지 입력값을 함께 처리하는 모델입니다. Late Fusion은 image와 LiDAR에서 얻은 값을 각각 Convolution Layer로 특성맵을 뽑아낸 후 element-wise summation해줍니다. </li>\n",
              "<li>Geometric Fusion : image와 LiDAR에서 얻은 값을 각각 Convolution Layer로 특성맵을 뽑을 때마다 서로 projection해 서로의 정보를 반영합니다. 이렇게 뽑은 두 특성맵을 element-wise summation 해줍니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fde2f3a7e-32cc-4294-8330-9be27248df91%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%209.41.56.png\"/><br/>\n",
              "위 사진은 구현코드입니다. 보시면 각자 특성을 추출 후 서로 projection하는걸 확인하실 수 있습니다. </li>\n",
              "</ul>\n",
              "<h3 id=\"2-실험-결과results\">2. 실험 결과(Results)</h3>\n",
              "<p>실험 결과는 다음과 같습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F38b6e380-d752-4841-bac0-409e94f3ee8d%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%209.45.13.png\"/><br/>\n",
              "왼쪽 사진은 Short, Long 경로에서 모델별 RC, DS를 나타낸거고 오른쪽 사진은 사고율을 나타낸 겁니다. </p>\n",
              "<h4 id=\"driving-performance\">Driving Performance</h4>\n",
              "<p>우선 왼쪽 표에 대해서 설명을 해드리도록 하겠습니다. </p>\n",
              "<p>여기서 눈여겨볼 부분은 한가지 입력값을 받는 CILRS, LBC, AIM보다 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능이 더 좋다는 겁니다. 두가지 입력값을 쓰기만 해도 한가지 입력값을 쓰는 것보다 성능이 좋다는 사실을 알 수 있습니다. </p>\n",
              "<p>그리고 또다시 눈여겨볼 부분은 Transfuser가 Late Fusion, Geometric Fusion보다 RC는 낮은데 DS가 높다는 것입니다. 즉, Transfuser는 주행 거리는 짧지만 안전운전을 더 잘한다는 뜻이죠. </p>\n",
              "<p>저자는 이를 보고 'Late Fusion, Geometric Fusion는 안전하게 운전하는 것보다 목표 지점에 가는데 중점을 뒀기 때문에 이런 결과가 나왔다'고 말했습니다. </p>\n",
              "<p>그리고 Expert의 점수도 나와있는데요, Expert도 장거리 운전에서는 그리 좋지 못한 성적을 얻었습니다. 신기합니다. </p>\n",
              "<h4 id=\"infraction\">Infraction</h4>\n",
              "<p>모델별 평균 사고율이 나옵니다. 초록색 막대가 Transfuser인데요, 모든 사고 항목에서 가장 낮습니다. 그런데  빨간불 신호 위반에서 다른 모델보다 낮긴 하지만 그래도 다른 사고 항목에 비하면 굉장히 높은 수치를 보입니다. 왜 그런걸까요? </p>\n",
              "<h4 id=\"limitations\">Limitations</h4>\n",
              "<p>여기선 모델의 한계점에 대해 저자가 얘기하는 부분입니다. 저자는 모델의 한계점으로 <strong>빨간불 신호 위반의 확률이 높은 것</strong>을 꼽았습니다. </p>\n",
              "<p>높은 신호위반 확률을 보이는 이유는 성능 평가를 위해 주행하던 경로에서 신호등이 카메라 구석에 찍혔는데 이 때문에 신호등의 빨간 불빛을 감지하기가 힘들어 빨간불에서 정차하지 않고 주행하는 일이 많았다고 합니다. </p>\n",
              "<p>그리고 이러한 문제를 해결할 additional supervision을 기대해본다고 말했습니다. </p>\n",
              "<h3 id=\"3-attention-map-visualizations\">3. Attention Map Visualizations</h3>\n",
              "<p>여기서는 카메라 이미지와 LiDAR point cloud간 상호보완성을 보여줍니다. </p>\n",
              "<p>어떻게 보여주냐면 교차로에서 신호대기중인 차량에서 얻은 이미지, Point cloud를 Transfuser로 특성을 추출하는 과정에서 self-attention을 통해 나온 16X8 사이즈의 벡터를 통해 설명합니다.</p>\n",
              "<p>여기서 반은 이미지쪽 벡터고 나머지 반은 LiDAR쪽 벡터입니다. 여기서 각각 자동차와 신호등에 대한 정보가 담긴 부분만 추출해 서로 얼마나 attention을 했는지 확인해봅니다. attention이 반영된 정도는 각 요소별 곱해진 score를 보고 알 수 있죠. </p>\n",
              "<p>그렇게 attention된 정도를 확인한 결과, 다음의 사실을 알 수 있었습니다. </p>\n",
              "<ul>\n",
              "<li>이미지 토큰의 62.75%가 attention을 가장 많이 한 5개의 token이 LiDAR에서 나온 토큰</li>\n",
              "<li>LiDAR 토큰의 78.45%가 attention을 가장 많이 한 5개의 token이 이미지에서 나온 토큰</li>\n",
              "</ul>\n",
              "<p>여기서 토큰은 transformer에 입력값으로 들어가는 데이터 단위를 말합니다. 출력값 역시 토큰의 집합이죠. 토큰을 데이터로 바꾼 뒤 읽으셔도 의미의 차이는 없을듯 합니다. </p>\n",
              "<p>아무튼, 이렇게 서로 상호보완하는 부분이 많습니다. 특성을 추출할 때 상대 데이터를 많이 고려한다는 뜻이죠. </p>\n",
              "<h3 id=\"4-ablation-study\">4. Ablation Study</h3>\n",
              "<p>여기서는 Transfuser의 Transformer에 대해 값을 수정해가며 성능의 변화를 관측한걸 얘기합니다. 저자는 Town05 Short에서 성능 평가를 했는데요, 성능표는 다음과 같았습니다.<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F3060d95b-e30f-41f8-a83b-b79cf1877329%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%2011.02.23.png\"/><br/>\n",
              "하나씩 설명해드리도록 하겠습니다. </p>\n",
              "<ol>\n",
              "<li>Scale : Transformer 이후 Fusion 횟수를 나타냅니다. 원래 4번 Fusion했는데 이 횟수를 줄여보며 성능을 비교해봤습니다. Scale이 1이면 마지막에 추출한 feature map(8X8X512)에서만 fusion하고 2면 16X16X256 feature map과 8X8X512 feature map에서 fusion하는거죠. </li>\n",
              "<li>Shared Transformer : 원래 각 사이즈의 특성맵마다 다른 Transformer를 사용합니다. 그러면 모든 특성맵에서 다같은 Transformer를 사용하면 어떻게 될까요? 성능이 떨어졌습니다. 저자는 각 convolution layer에서 얻은 특성맵이 갖고 있는 성질이 다 다르기 때문에 각기 다른 Transformer에서 처리해야 한다고 말했습니다.(different convolutional layers in ResNet learn different types of features due to which each transformer has to focus on fusing different types of features)</li>\n",
              "<li>Attention layers : 원래 각 Transfomer에는 8개의 Attention layer가 있습니다. 이를 1개, 4개로 만든 뒤 성능을 측정해봤습니다. </li>\n",
              "<li>No Pos. Embd : Transformer에 넣기전에 Positional Embedding을 안했을 경우입니다. </li>\n",
              "</ol>\n",
              "<p>이렇게 각 요소를 제거한 뒤 성능을 비교했습니다. Scale을 제외한 나머지 부분에서 하나의 공통점이 있는데요, 바로 RC는 증가하지만 DS가 떨어졌다는 점입니다. </p>\n",
              "<p>저자는 이를 보고 'Attention횟수가 많아질 수록 더 조심히 운전하게 된다'고 말했습니다. </p>\n",
              "<h2 id=\"conclusion\">Conclusion</h2>\n",
              "<hr/>\n",
              "<p>논문의 결말입니다. 저자는 앞서 말한 것을 conclusion에서 총체적으로 정리했습니다. 그리고 마지막에 자신들이 만든 모델에 다른 센서의 입력값을 추가해서 쓰거나 다른 AI task에 사용할 수 있다고 말하며 논문을 끝냈습니다.<br/>\n",
              "<br/></p>\n",
              "<h2 id=\"후기\">후기</h2>\n",
              "<hr/>\n",
              "<p>이렇게 길고 긴 논문 리뷰가 끝났습니다. 최선을 다해 리뷰해봤는데 미숙한 부분이 많았습니다. 이런식으로 데이터를 받아서 처리하는 모델도 처음 접했고 자율주행 task를 수행하는 모델도 처음이라 읽는데 많은 시간이 걸렸습니다. 그래도 리뷰하고 나니 뿌듯하네요. </p>\n",
              "<p>3주 뒤에 다른 논문을 세미나에서 발표하는데 그 논문도 velog에 올릴 계획입니다. 개강이 얼마 남지 않은 시기라 쓰기 힘들겠지만 하...할 수 있겠죠? </p>\n",
              "<p>마지막으로 제가 이 논문을 읽고 느낀점을 쓰고자 합니다. 제가 느낀 점은 다음과 같습니다.</p>\n",
              "<ul>\n",
              "<li>\n",
              "<p>두 종류의 입력값을 특성 추출 과정에서 반영함으로써 안전한 운전을 구현했다는 사실이 흥미로웠다.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p>허나 Transformer가 전체 입력값을 모두 고려하며 계산하기 때문에 연산량이 좀 많을텐데 실시간으로 판단이 필요한 운전에서 이런 점이 부담이 되지 않을까 싶다.</p>\n",
              "</li>\n",
              "<li>\n",
              "<p>추후 주행 속도도 개선하며 안전운전을 추구하는 모델이 나왔으면 좋겠다.</p>\n",
              "</li>\n",
              "</ul>\n",
              "<p>그리고 제가 이걸 세미나에서 발표했을 때 교수님께서 \"꼭 두가지 데이터를 사용했어야 했을까, LiDAR에서 얻은 정보를 사용할 때 2D 데이터로 변환하는 과정에서 많은 데이터 손실이 있을텐데 그걸 감수하면서까지 사용할 이유가 있을지 모르겠다, 차라리 시야각이 넓은 이미지를 사용하면 데이터 손실도 없이 사용할 수 있지 않을까\" 라고 저에게 말씀하셨습니다. </p>\n",
              "<p>실은 저는 입력값에 대한 어떠한 의문도 가지지 않았는데 교수님의 말씀을 듣고 의문이 들었습니다. 실제로 표를 봤을 때<br/>\n",
              "<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fd919d9ce-64eb-4d23-9e83-c67e9f7b4ca7%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.06.23.png\"/><br/>\n",
              "여기 보시면 한가지 입력값만 받는 AIM과 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능차이가 크게 없다는 사실을 확인할 수 있습니다. 물론 장거리 주행에서는 DS에서 차이가 나긴 하지만 다들 점수가 낮기 때문에 큰 상관은 없다고 생각합니다. </p>\n",
              "<p>아무튼, 많은 공부가 되었고 재밌게 읽은 논문이었습니다. 다음 논문 리뷰에서 뵙겠습니다!</p></div></div></div><div class=\"sc-dvQaRk ijHvhk sc-gfqkcP hpspee\"><div class=\"sc-TBWPX ePkhDB\"><div class=\"sc-jIkXHa iQZhhJ\"><a href=\"/@minkyu4506\"><img alt=\"profile\" src=\"https://velog.velcdn.com/images/minkyu4506/profile/3d19426f-f141-4188-b23a-254ce14fce5a/Untitled.png\"/></a><div class=\"sc-ZOtfp eYREua\"><div class=\"name\"><a href=\"/@minkyu4506\">Minguinho_zeze</a></div><div class=\"description\">안녕하세요. 딥러닝 알고리즘에 관심이 많은 학부생입니다. </div></div></div><div class=\"sc-jOxtWs fWmBKb\"></div><div class=\"sc-hmjpVf fBgOP\"><a data-testid=\"github\" href=\"https://github.com/MinkyuKim26\" rel=\"noopener noreferrer\" target=\"_blank\"><svg fill=\"currentColor\" height=\"20\" viewbox=\"0 0 20 20\" width=\"20\"><mask height=\"20\" id=\"github\" maskunits=\"userSpaceOnUse\" width=\"20\" x=\"0\" y=\"0\"><path clip-rule=\"evenodd\" d=\"M6.69 15.944c0 .08-.093.145-.21.145-.133.012-.226-.053-.226-.145 0-.081.093-.146.21-.146.12-.012.226.053.226.146zm-1.255-.182c-.028.08.053.173.174.198.105.04.226 0 .25-.081.024-.08-.053-.173-.174-.21-.104-.028-.221.012-.25.093zm1.783-.068c-.117.028-.198.104-.186.197.012.08.117.133.238.105.117-.028.198-.105.186-.186-.012-.076-.121-.129-.238-.116zM9.87.242C4.278.242 0 4.488 0 10.08c0 4.471 2.815 8.298 6.835 9.645.516.093.697-.226.697-.488 0-.25-.012-1.63-.012-2.476 0 0-2.822.605-3.415-1.202 0 0-.46-1.173-1.121-1.475 0 0-.924-.633.064-.621 0 0 1.004.08 1.557 1.04.883 1.557 2.363 1.109 2.94.843.092-.645.354-1.093.645-1.36-2.255-.25-4.529-.576-4.529-4.455 0-1.109.307-1.665.952-2.375-.105-.262-.448-1.342.105-2.738C5.56 4.157 7.5 5.51 7.5 5.51a9.474 9.474 0 0 1 2.532-.344c.86 0 1.726.117 2.533.343 0 0 1.939-1.355 2.782-1.089.552 1.4.21 2.476.105 2.738.645.714 1.04 1.27 1.04 2.375 0 3.891-2.375 4.202-4.63 4.456.372.319.686.923.686 1.87 0 1.36-.012 3.041-.012 3.372 0 .262.186.58.698.488C17.266 18.379 20 14.552 20 10.08 20 4.488 15.464.24 9.871.24zM3.919 14.149c-.052.04-.04.133.029.21.064.064.157.093.21.04.052-.04.04-.133-.029-.21-.064-.064-.157-.092-.21-.04zm-.435-.326c-.028.052.012.117.093.157.064.04.145.028.173-.028.028-.053-.012-.117-.093-.158-.08-.024-.145-.012-.173.029zm1.306 1.435c-.064.053-.04.174.053.25.092.093.21.105.262.04.052-.052.028-.173-.053-.25-.088-.092-.21-.104-.262-.04zm-.46-.593c-.064.04-.064.146 0 .238.065.093.174.133.226.093.065-.053.065-.157 0-.25-.056-.093-.16-.133-.225-.08z\" fill=\"#ffffff\" fill-rule=\"evenodd\"></path></mask><g mask=\"url(#github)\"><path d=\"M0 0h20v20H0z\" fill=\"currentColor\"></path></g></svg></a><a data-testid=\"twitter\" href=\"https://twitter.com/minguinho_zeze\" rel=\"noopener noreferrer\" target=\"_blank\"><svg fill=\"none\" height=\"32\" viewbox=\"0 0 32 32\" width=\"32\"><g clip-path=\"url(#twitter)\"><path d=\"M32 6.076a13.108 13.108 0 0 1-3.77 1.033 6.576 6.576 0 0 0 2.886-3.632 13.151 13.151 0 0 1-4.17 1.594 6.554 6.554 0 0 0-4.791-2.074c-4.239 0-7.354 3.955-6.396 8.06C10.304 10.784 5.467 8.171 2.228 4.2a6.574 6.574 0 0 0 2.03 8.765 6.538 6.538 0 0 1-2.971-.821c-.072 3.041 2.108 5.886 5.265 6.52-.924.25-1.936.309-2.965.112a6.57 6.57 0 0 0 6.133 4.558A13.2 13.2 0 0 1 0 26.053a18.585 18.585 0 0 0 10.064 2.95c12.19 0 19.076-10.295 18.66-19.528A13.366 13.366 0 0 0 32 6.076z\" fill=\"currentColor\"></path></g><defs><clippath id=\"twitter\"><path d=\"M0 0h32v32H0z\" fill=\"#fff\"></path></clippath></defs></svg></a><a href=\"mailto:minkyu4506@gmail.com\"><svg data-testid=\"email\" fill=\"none\" height=\"32\" viewbox=\"0 0 32 32\" width=\"32\"><path d=\"M16 16.871L1.019 5H30.98L16 16.871zm0 3.146L1 8.131V27h30V8.131L16 20.017z\" fill=\"currentColor\"></path></svg></a></div></div></div><div class=\"sc-dvQaRk ijHvhk sc-fTQvRK eMFVHd\"><div class=\"sc-bUhFKy cOfbyG\"><a class=\"sc-lhMiDA gkzonb\" href=\"/@minkyu4506/Faster-R-CNN-리뷰-with-Code\"><div class=\"sc-hJhJFJ crTinq\"><svg fill=\"currentColor\" height=\"1em\" stroke=\"currentColor\" stroke-width=\"0\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M20 11H7.83l5.59-5.59L12 4l-8 8 8 8 1.41-1.41L7.83 13H20v-2z\"></path></svg></div><div class=\"sc-cvlWTT lasECz\"><div class=\"description\">이전<!-- --> 포스트</div><h3>[논문리뷰]Faster R-CNN 리뷰 + 코드구현(TensorFlow2)</h3></div></a></div><div class=\"sc-bUhFKy cOfbyG\"><a class=\"sc-lhMiDA jOoREI\" href=\"/@minkyu4506/YOLO-v1-리뷰-코드-구현tensorflow2\"><div class=\"sc-hJhJFJ NTSqV\"><svg fill=\"currentColor\" height=\"1em\" stroke=\"currentColor\" stroke-width=\"0\" viewbox=\"0 0 24 24\" width=\"1em\" xmlns=\"http://www.w3.org/2000/svg\"><path d=\"M12 4l-1.41 1.41L16.17 11H4v2h12.17l-5.58 5.59L12 20l8-8z\"></path></svg></div><div class=\"sc-cvlWTT cQnPYI\"><div class=\"description\">다음<!-- --> 포스트</div><h3>[논문리뷰] YOLO v1 리뷰 + 코드 구현(TensorFlow2)</h3></div></a></div></div><div class=\"sc-dvQaRk ijHvhk sc-hKTqa iA-dFHq\"><ins class=\"adsbygoogle\" data-ad-client=\"ca-pub-9161852896103498\" data-ad-format=\"fluid\" data-ad-layout=\"in-article\" data-ad-slot=\"6869845586\" style=\"display:block;text-align:center\"></ins></div><div class=\"sc-dvQaRk ijHvhk sc-edERGn ewkRvR\"><h4>1<!-- -->개의 댓글</h4><div class=\"sc-jlsrNB\"><div class=\"sc-iWBNLc ioCAmf\"><textarea class=\"sc-hYQoXb jjhhWc\" placeholder=\"댓글을 작성하세요\" style=\"height:0\"></textarea><div class=\"buttons-wrapper\"><button class=\"sc-jrQzAO hSMJOX\" color=\"teal\">댓글 <!-- -->작성</button></div></div><div class=\"sc-gnnDb jGGkyw\"><div class=\"sc-fydGpi\"><div class=\"sc-cVAmsi eAtqhB comment\"><div class=\"sc-kHxTfl iNiviY\"><div class=\"profile\"><a href=\"/@nopannogain\"><img alt=\"comment-user-thumbnail\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAYAAADDPmHLAAAACXBIWXMAAAsTAAALEwEAmpwYAAAAAXNSR0IArs4c6QAAAARnQU1BAACxjwv8YQUAAASbSURBVHgB7Z0tTytBFIYP914BDiQ4cIADB0EhwYFE8ifq7g/hJ2CRSCQ4kOCobF3ruHk3maS5aSnbdnfPOe/7JE0oCTvTnmc+dvbMsNbr9b5M0PLLBDUSgBwJQI4EIEcCkCMByJEA5EgAciQAORKAHAlAjgQgRwKQIwHIkQDkSAByJAA5EoAcCUCOBCBHApAjAciRAORIAHIkADkSgBwJQI4EIEcCkCMByJEA5EgAciQAOX+MhPX1dTs+Prbt7W3b3d21jY2N6ndgPB7bYDCw4XBor6+v9vHxUb1nIL0Ae3t7dn5+XgV9FhABYuC1v79f/Q4SPD8/28vLi2UmrQA/Cfx34O/wwjXu7u7S9gi/z87O/loyELTr62vb2tqyZcFQcXp6Wv2MXiEb6SaBCDwEWDVFqmykEgABOjo6sqbAtbNJkEaAi4uLRoNfQBmXl5eWhRQCIChlnG6Dk5OTVstrkvACYKLXxJg/D5RZ1hEiE14ABGIVs/26IPgZeoHQAiDwbYz7s4AA0XuB0AIsusizKsrycmRCC+Dhyz84OLDIhBUAra/rHgCgDpGHgbAC7OzsmBc81aUuYQXY3Nw0L3iqS13CCtDFrd8sPNWlLsoIIkcCkBNWAE8JGpGTRcIKgPw9L3iqS13CCvD5+Wle8FSXuoQVAJm8HlK0UAfUJSqhJ4Fvb2/WNcgcjkxoAfDld936oieKhhYAwX96erKuwJ6B6Oni4dcBIEAXvQAC//j4aNEJLwCC30UgUGaGzSIpVgLRC7Q5FKCsLFvG0iwFPzw8tBIUlIGyspDqWcD9/X2jEuDaKCMT6R4GIUBNzAlwzWzBByl3ByNYaK23t7dLP6vHfT6u9/7+bhlZ6/V6X5YYpI0jebRu/mD2wBfSHxCBngAv9ASQ4PDwsErhwvvJE0JGo1EV9H6/72KFsS1SCDAZyFngnh2vVUwSUV4WQUILULZnlR06aMGYqDW1QDN56khZho6+Ghh2DoBgXF1dTZ3koZWvcqWubECdtg0NZUQ+QiakAGjxOA9gHhABj4wXeWyMHgX5/j85Zwi9AXoeD4+n6xJOAASk7nbwkjyCGT0meXg/mcWDYOMsIJwShtaO3mWRHT/odaINCaHmAIsEHyCQOP6tHAHXFKVukSQIsxK4aPDbBnWMdG5ACAHwhUYIfgHzEwwjEXAvQFdHwCzLzc1NiC1jrgXA2I31/Ijbr1HnCEfKuRagq/N/VgXuJLzPB9wKgMBnOITJu8RuBUDXnwHvQ4FLAbDkGrnr/x8MBV7vClwKEHHWPw+vn8mdANlaf8FrL+BOgIytv+Dxs7kSAC0kY+sveOwFXAnQ5bGvbdH0A6m6uBLAw8GPTePtaFk3AmTv/gtYF/A0DLgRgKH1Fzx9VjcCIBuHBU89nRsBkKrFgqfNJm5SwpBGVc7fz/CvWKZRUsk9bS1PvzVMfI+OiiVHApAjAciRAORIAHIkADkSgBwJQI4EIEcCkCMByJEA5EgAciQAORKAHAlAjgQgRwKQIwHIkQDkSAByJAA5EoAcCUCOBCBHApAjAciRAORIAHIkADkSgBwJQI4EIOcfGjV2tEfztqEAAAAASUVORK5CYII=\"/></a><div class=\"comment-info\"><div class=\"username\"><a href=\"/@nopannogain\">nopannogain</a></div><div class=\"date\">2023년 3월 16일</div></div></div></div><div class=\"sc-bQtKYq ehISJN\"><div class=\"sc-ksHpcM iYgFNI\"><div class=\"sc-bQtKYq ehISJN\"><div class=\"sc-fXEqDS jlUmJL atom-one\"><p>꼼꼼한 논문 리뷰 잘 보았습니다. 저도 논문 리서치 중인데, 논문 리뷰는 이렇게 하는 것이군요.ㅎㅎ 본받아서 저도 열심히 조사해야겠어요. 감사합니다:)</p></div></div></div></div><div class=\"sc-gXRojI mIalr\"><div class=\"sc-bGaVxB kbaMiN\"><svg fill=\"none\" height=\"12\" viewbox=\"0 0 12 12\" width=\"12\"><path d=\"M5.5 2.5h1v3h3v1h-3v3h-1v-3h-3v-1h3v-3z\" fill=\"currentColor\"></path><path clip-rule=\"evenodd\" d=\"M1 0a1 1 0 0 0-1 1v10a1 1 0 0 0 1 1h10a1 1 0 0 0 1-1V1a1 1 0 0 0-1-1H1zm10 1H1v10h10V1z\" fill=\"currentColor\" fill-rule=\"evenodd\"></path></svg><span>답글 달기</span></div></div></div></div></div></div></div></div><div class=\"Toastify\"></div></div><script>window.__APOLLO_STATE__={\"Post:040abdbb-a10b-4690-bcf8-060c67dd94d5\":{\"id\":\"040abdbb-a10b-4690-bcf8-060c67dd94d5\",\"title\":\"[논문리뷰] Multi-Modal Fusion Transformer for End-to-End Autonomous Driving \",\"released_at\":\"2021-08-05T15:14:35.674Z\",\"updated_at\":\"2023-09-08T15:24:22.379Z\",\"tags\":{\"type\":\"json\",\"json\":[\"autonomous driving\",\"multimodal learning\",\"paper_review\"]},\"body\":\" 안녕하세요. 밍기뉴와제제입니다. \\n \\n정말 오랜만에 돌아왔습니다. 논문은 여러개 봤는데 리뷰할 정도로 깊게 탐구한 논문이 별로 없어 한동안 글을 안쓰다 이번에 논문 세미나를 하다보니 꼼꼼히 살펴본 논문이 생겼습니다. \\n\\n 이번에 리뷰를 하려는 논문은 'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving '라는 논문입니다. 자율주행에 관한 논문이죠. \\n \\n 이름을 보면 대충 짐작 가시겠지만 이 논문은 multimodal, 두가지 데이터를 처리하는 모델을 설계했습니다. 그리고 Transformer도 이용했다는 사실을 짐작할 수 있습니다. \\n \\n 그러면 지금부터 논문 흐름에 맞춰 리뷰를 해보도록 하겠습니다. \\n \\n ## Introduction\\n ---\\n 이 부분에서는 이전까지 자율주행 모델이 사용한 방식들을 소개 후 저자가 소개하는 모델 'transfuser'에 대해 설명합니다. \\n \\n ### 한가지 입력값만 받는 모델\\n \\n 이전에 Image-only model과 LiDAR-only model이 등장했고 이는 자율주행의 성능을 올리는데 많이 기여했습니다. 허나 이렇게 한가지 데이터만 입력값으로 사용한 모델은 **near-ideal한 움직임을 보이는 객체**들만 있는 환경에서 **제한된 움직임만 필요한 경로**에 주행해야만 높은 성능을 보여준다는 것이었죠. 굉장히 사용하기 까다로웠습니다. \\n \\n 논문에서는 이를 두고 다음과 같이 말했습니다. \\n >adversarial scenarios에서 만족스럽지 못한 성능을 보여준다\\n \\n여기서 adversarial scenarios는 운전에 변수가 많이 생기는 환경을 말합니다. 예를 들면 비보호 회전을 해야하는 교차로, 랜덤하게 등장하는 자동차와 보행자 등이 운전에 변수를 주는 요소라 볼 수 있죠. \\n그러면 이런 부분이 왜 낮은 성능이 나오게끔 하는걸까요? 다음의 그림을 보며 설명해 드리도록 하겠습니다. \\n\\n![](https://images.velog.io/images/minkyu4506/post/cda53439-1ba7-461e-a3d2-7b6805019556/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%208.10.17.png)\\n\\n위 사진은 논문에서 말한 adversarial scenarios 중 하나입니다. \\n여기서 초록색 박스 안에 있는 자동차(Ego-Vehicle)와 왼쪽 도로에서 건너오는 빨간색 박스 속 자동차들(Traffic), 그리고 노란색 박스 안에 있는 신호등(Traffic Lights)이 있습니다. 여기서 Ego-Vehicle이 자율주행을 하는 자동차죠.\\n\\n이 상황에서 Ego-Vehicle이 카메라와 LiDAR에서 얻은 데이터를 살펴봅시다. LiDAR의 정의는 다음과 같습니다.\\n>LiDAR : Light Detection And Ranging, 레이저를 발사 후 돌아오는 시간을 계산해 주변 물체를 검출하는 센서\\n\\nLiDAR는 3D 데이터인 Point Cloud를 생산하며 여기엔 카메라가 관측할 수 없는 넓은 범위에 존재하는 객체에 대한 정보가 포함되어 있습니다. 그림을 보면 카메라 뷰에서 보이지 않는 자동차(Traffic)을 검출했다는 사실을 확인할 수 있습니다. \\n\\n허나 LiDAR는 카메라가 검출한 신호등을 찾지 못했습니다. 즉, 각 센서별로 얻을 수 있는 정보가 다릅니다. \\n\\n이러한 상황에서 Image-only 혹은 LiDAR-only model을 사용해 자율주행을 한다고 가정해봅시다. \\n그러면 아래와 같은 문제가 생길 확률이 높습니다.\\n\\n* Image-only model : 왼쪽에서 건너오는 자동차들을 고려하지 않고 운전 -> 추돌 사고\\n* LiDAR-only model : 전방에 있는 신호등의 신호를 고려하지 않고 운전 -> 신호 위반\\n\\n이건 꽤 큰 단점이죠. 그래서 사람들은 이를 해결하기 위한 방법을 찾고자 했습니다. \\n\\n### 두가지 입력값을 함께 사용해보자\\n\\n사람들은 자율주행 자동차에 있는 센서에 주목했습니다. \\n![](https://images.velog.io/images/minkyu4506/post/ed409fbd-f733-4294-a832-2410a12035b2/0*PjdSdGyiEB6Yg1UX.png)\\n(출처 : https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f)\\n\\n위 사진은 자율주행 자동차에 들어있는 센서를 나타낸 그림입니다. 보시면 알겠지만 자율주행 자동차 안에는 수많은 센서들이 들어있습니다. \\n\\n이렇게 많은 센서를 보고 사람들이 생각한게 있습니다. \\n>\\\"자동차에 있는 두개의 센서를 함께 사용해보는건 어떨까?\\\"\\n\\n그래서 두가지 데이터를 함께 써보자는 아이디어를 떠올렸죠. 그리고 다음과 같은 질문을 남겼습니다. \\n>* 두가지 데이터를 어떤 방식으로 합쳐서 사용하지?\\n* 두가지 데이터로 어떤걸 선택하지? \\n\\n이 질문에 답하기 위해 수많은 논문들이 나왔습니다. 그 중 한가지 논문에 나온 모델 구조에 대해 간단히 소개해드리겠습니다. \\n\\n![](https://images.velog.io/images/minkyu4506/post/74c12e61-7d7c-46aa-844e-21a9991b62fd/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%2010.19.35.png)\\n(출처 : Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proc. IEEE Conf. on Computer Vision and Pat- tern Recognition (CVPR), 2017)\\n\\n위 그림에 나온 구조가 두가지 데이터를 처리하는 대부분의 모델이 사용하는 구조입니다. 각 데이터별로 CNN에 넣어 특성맵을 추출한 뒤 원소 단위로 평균값을 낸다든지 더한다든지 하는 방식으로 Fusion해 하나의 출력값으로 만드는 방식이죠. \\n\\n### 여전히 아쉽다!\\n\\n두가지 데이터를 이용하는 방식은 한가지 데이터를 사용하는 방식보다 성능이 좋았습니다. 허나 여전히 단점이 있었습니다. \\n\\n바로 도심 속 운전같이 복잡한 상황에서 운전하기 힘들다는 점이었습니다. \\n\\n교차로에서 운전할 때를 고려해봅시다. 위에 제가 올린 사진과 같은 상황이죠. 여기서 자율주행을 하는 자동차(Ego-Vehicle)는 왼쪽에서 오는 자동차(Traffic)과 신호등의 신호(Traffic Lights) 사이의 연관성을 고려하며 운전을 해야합니다. 허나 각 데이터별로 특성맵을 추출하면 특성을 추출하는 과정에서 모든 정보를 고려할 수 없게 됩니다. \\n\\n즉, 모든 정보를 고려하지 않고 얻어낸 정보를 가지고 운전하기 때문에 사고가 날 확률이 높은 것이죠.\\n\\n이는 데이터의 문제가 아니라 데이터를 처리하는 모델 구조의 문제였습니다. \\n\\n### Transformer\\n\\n그래서 저자는 Attention mechanism만 사용해 데이터를 처리하는 Transformer를 특성 추출 과정에서 사용하기로 했습니다. \\n\\nTransformer의 self-attention는 입력 값의 각 원소가 전체적인 입력값의 어느 부분을 더 주목해야 하는지 반영하게 해주니 이를 이용해 이미지와 LiDAR 데이터를 전체적으로 고려하며 특성맵을 추출하는 방식을 생각한 것입니다.\\n\\n\\\"두가지 데이터를 어떤 방식으로 합쳐서 사용하지?\\\" 에 대한 답변은 Transforemr였습니다.\\n\\n### Single-view image and LiDAR inputs\\n\\n그리고 \\\"두가지 데이터로 어떤걸 선택하지?\\\"에 대한 답변을 해야합니다. \\n\\n저자는 이에 \\\"Single-view image and LiDAR를 입력 데이터로 사용한다\\\"고 말했습니다. \\n![](https://images.velog.io/images/minkyu4506/post/74af93a1-93f3-4d49-a6e9-dc0fa9a07905/%EC%9E%90%EB%A3%8C.png)\\n이 둘을 사용하겠다는 것이죠.\\n\\n왜 Single-view image and LiDAR를 선택한 걸까요? 저자는 이 둘이 서로가 서로에게 부족한 점을 채워주는 상호보완성이 있기 때문에 선택했다고 말했습니다. \\n\\n즉, 이 둘을 입력데이터로 사용해 얻는 정보의 양이 제일 많다고 판단한 것이죠. \\n\\n### Transfuser\\n\\n이제 저자가 생각해낸 모델을 정리해봅시다. \\n\\n>입력 데이터로 Single-view image and LiDAR를 받아 특성을 추출하는 과정에서 Transformer를 사용해 전체적인 정보를 고려하는 모델\\n\\n한문장으로 간단히 정리됩니다. 저자는 이렇게 설계된 모델을 **Transfuser**라고 정의했습니다.\\n\\n여기까지 모델의 Introduction 부분이었습니다. 깔끔히 쓰고 싶었는데 쉽지않네요. 허허...\\n\\n\\n그럼 이제 Transfuser가 포함된 자율주행 모델이 만들어지는 과정을 소개한 Method 항목을 소개해 드리도록 하겠습니다. \\n\\n## Method\\n---\\n원래 Releated work를 슥 살펴보고 Method로 넘어가야 하는데 그러면 분량이 너무 많아져서 바로 Method로 건너왔습니다. 저도 자율주행 모델에 대해 잘 감이 안잡힌 상태에서 이 논문을 읽어서 Related work 부분이 논문 이해에 꽤나 도움이 되었습니다. 관심 있으신 분들은 따로 찾아서 읽어보시는걸 추천드립니다. \\n\\n아무튼, 이제 Method에 대해 설명해 드리도록 하겠습니다.\\n\\nMethod에는 Transformer를 이용해 자율주행 모델을 만드는 일련의 과정이 적혀있습니다. \\n\\n모델을 만드는 과정은 다음과 같이 3단계로 나눌 수 있습니다. \\n\\n1. Task 설정, 데이터셋 구성(Problem Setting)\\n2. 데이터셋 전처리(Input and Output Parameterization)\\n3. 모델 설계(Multi-Modal Fusion Transformer + Waypoint Prediction Network)\\n\\n그러면 'Task 설정'부터 설명해 드리도록 하겠습니다.\\n\\n### 1. Problem Setting\\n\\n모델이 해결할 Task를 설정하고 이를 위한 학습법, 그리고 필요한 데이터셋을 설명하는 부분입니다. \\n\\n저자는 **point-to-point navigation**를 모델이 수행할 Task로 설정했습니다. \\n\\n저자는 point to point navigation이 목표지점까지 waypoint를 따라 사고 없이 완주하는 것이라 말했습니다. 여기서 사고는 다른 객체(자동차, 사람 등)과 충돌하거나 교통법규를 어기는 것을 말하죠. \\n\\n그리고 이를 학습하는 방법으로 imitation learning을 선택했습니다. imitation learning이란 강화학습의 일종인데요, 의미 그대로 해당 task에서 전문가(Expert)가 하는걸 따라하는 학습법입니다. \\n\\n강화 학습은 학습 주체인 agent와 agent가 행동하는데 규범이 되는 policy, 행동의 결과인 action, action으로 인한 상태 state, 그리고 state에 대한 보상 reward가 있습니다.여기서 보상 reward를 가장 많이 받는 방향으로 학습시키는 것이 목표죠. \\n\\nreward를 많이 받도록 만드는 방식은 여러가지가 있습니다. 그중 하나가 행동 규범힌 policy를 학습가능한 상태(parameterize)로 만드는 것이죠. \\n\\nimitation learning도 그 방식을 사용하고 있으며 논문에서는 다음과 같이 설명합니다. \\n>Policy를 Expert의 policy를 따라하게끔 학습하는 것\\n\\n그런데 여기서 궁금증이 생겼습니다. 왜 imiation learning을 선택한거지? 그래서 찾아봤습니다. \\n찾아보니까 이렇게 policy를 학습 대상으로 삼아 학습시키는 방식은 **고차원 데이터를 처리하고 연속된 action을 해야하는 모델의 학습에 적합**하다고 합니다. \\n\\n이미지라는 고차원 데이터를 처리해 연속된 action이 필요한 운전을 하는 자율주행 모델에 적합한방식이라 선택한게 아닌가 싶습니다. \\n\\n그러면 이제 저자가 imitation learning을 사용한 학습과정을 설명해 드리도록 하겠습니다.\\n\\n#### 데이터셋 수집 \\n우선 데이터셋을 수집해야하죠? 학습을 위한 학습 데이터셋과 평가를 위한 테스트 데이터셋이 필요합니다. \\n\\n데이터셋은 자율주행 오픈소스 시뮬레이터 CARLA(https://carla.org)에 있는 가상 환경에서 수집\\n합니다. 별다른 이유는 적지 않았지만 아무래도 사고가 날 수 있는 상황에 대한 데이터도 모으기 때문에 그런게 아닌가 싶네요. \\n\\n여튼, CARLA에 있는 가상환경에서 Expert가 주행하며 데이터를 모읍니다. imitation learning에서 말씀드린 Expert 맞습니다. \\n\\nExpert는 가상환경을 주행하며 입력 데이터와 출력 데이터를 수집합니다. 그렇게 해서 \\n![](https://images.velog.io/images/minkyu4506/post/bf940494-966f-4a2d-ab3e-15adb7e16afe/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.06.20.png)\\n위와 같은 데이터셋 D를 만들어줍니다. \\n\\n여기서 X는 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 한 시점(single time step)에 이미지 한장, point cloud 하나가 있는 것이죠.\\n\\n그리고 W는 T개의 waypoint가 모인 w로 이루어져 있습니다. 즉, 이미지와 point cloud를 하나씩 넣으면 출력값으로 T개의 Waypoint가 나오는 모델을 만들겠다는 뜻이죠.\\n\\n#### 학습 방법\\n이렇게 데이터셋을 모았으니 학습을 시켜봅시다. 학습 방식은 다음과 같이 정의할 수 있습니다. \\n![](https://images.velog.io/images/minkyu4506/post/42199532-a602-4a20-89e2-8a21126a3759/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.11.08.png)\\n여기서 L은 Loss함수입니다. 그러니까 Expert가 주행한 경로와 우리가 만든 agent의 policy에 따른 action, 다시 말해 **우리가 만든 모델이 예측한 주행 경로 사이의 loss가 최소가 되게끔 policy를 학습시키겠다**는 뜻이죠. \\n\\n저자는 이러한 학습 방식을 지도학습의 방식이라고 말했습니다. Expert의 데이터를 label data, 내가 만든 모델의 데이터가 prediction data라고 보면 저자의 말이 이해가 되시지 않을까 싶습니다. \\n\\n그래서 강화학습은 어떻게 학습 시키는걸까 찾아봤습니다. 강화학습은 데이터셋을 사용하지 않고 학습하기 때문에 매 순간 자기 자신이 만든 state와 reward를 보고 다음 action에 반영하며 점점 높은 reward만 받는 모델로 학습되는 방식을 사용한다는 사실을 알아냈습니다. 지도학습으로만 모델을 학습시켜본 저에게 있어서 강화학습은 상당히 신기한 방식입니다. \\n\\n#### 자율 주행 \\n저자는 학습 이후 어떻게 자율주행에 사용할지도 설명해 주었습니다. \\n저자는 모델이 예측한 경로를 inverse dynamics model에 넣어 얻은 action으로 주행을 한다고 말했고 이 때 inverse dynamics model을 PID controller로 구현했다고 설명했습니다. \\n\\nPID controller는 간단한게 말해 주어진 출력값을 위해 필요한 제어값(가속, 감속, 회전 등)을 구하는 요소라고 보시면 됩니다. 자세한 설명은 [여기](https://ko.wikipedia.org/wiki/PID_제어기)서 확인하실 수 있습니다. \\n\\n저자는 이러한 과정을 다음과 같은 식으로 나타냈습니다. \\n![](https://images.velog.io/images/minkyu4506/post/a7c85e89-258f-4110-991f-1a7316121323/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.23.16.png)\\naction = PID(예측 경로)인 것이죠. 여기서 action은 agent가 행한 action과 동일한 개념입니다. \\n\\n#### Global planner\\n마지막에 등장하는 문단인데 처음에는 이게 왜 있는건가 싶었습니다. \\n\\n읽어보니 저자들은 CARLA의 표준 프로토콜을 따르고 목표 지점이 GPS 좌표로 제공되며 목표 지점과 자동차가 안내한 지점이 몇백미터 떨어질 수 있다고 나와있습니다. \\n\\n다른 부분은 그러려니 하고 읽었는데 마지막 부분 '목표 지점과 안내 지점이 몇백미터 떨어질 수 있다'는 말이 거슬렸습니다. 도대체 뭔 뜻이지? \\n\\n제가 논문 세미나를 할 때 이 논문을 가지고 했는데요, 이에 관해 세미나 계신 분들께 여쭤보고 답을 들었는데도 이해가 제대로 안되서 구글에 검색까지 해봤습니다.\\n\\n구글에 검색을 해보니 다음과 같은 글을 발견했습니다. \\n>\\nThe global planner plans a global path around obstacles\\n\\n대충 번역하면 장애물을 돌아가는 global path를 생성하는게 global planner라고 하네요. \\n\\n아마 **목표 지점에 가기 힘들면 그 근처로 안내할 수 있음**을 말하고 싶어서 이 부분을 추가한게 아닌가 싶습니다.\\n\\n여기까지 Problem Setting이었습니다.\\n\\n### 2. Input and Output Parameterization\\n\\n이제 데이터셋을 어떻게 만들었는지? 정확히는 모델의 학습에 사용하기 위해 어떤 작업을 했는지 설명해 드리도록 하겠습니다.\\n\\n#### Input Representation\\n\\n우선 입력 데이터부터 설명해 드리고자 합니다.\\n\\n입력 데이터는 앞서 말씀드렸듯 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 카메라 이미지는 2D 데이터고 Point cloud는 3D 데이터라 각자 처리방식이 다릅니다. \\n\\n1. 카메라 이미지\\n카메라에서 촬영된 이미지는 400X300 사이즈인데요, 여기서 가운데 256X256 영역만 추출해서 사용합니다. 왜냐하면 렌즈 구조상 외곽 이미지는 왜곡 되어있기 때문입니다. 이렇게 **256X256X3** 사이즈의 데이터를 얻습니다. \\n\\n2. LiDAR Point Cloud\\n저자는 LiDAR에서 얻은 Point Cloud 중 자동차의 전면 32m, 좌우 측면 각 16m씩 해서 총 32m X 32m 영역만 사용합니다. 그리고 이를 2D 데이터로 변환해주는데요, 한 셀당 0.125m X 0.125m로 해서 256 X 256 픽셀 데이터로 변환해줍니다. \\n그리고 Point Cloud는 3D 데이터라 높이에 관한 데이터도 있는데요, 저자는 이를 2개의 채널에 담았습니다. 하나는 지면 위(+) 높이 데이터, 다른 하나는 지면 밑(-) 높이 데이터를 담았죠.\\n이렇게 **256X256X2** 사이즈의 데이터를 얻습니다.\\n\\n#### Output Representation\\n출력값 양식을 정의하는 부분입니다. \\n\\n출력값, 즉 waypoint는 BEV space에서 (x,y)의 양식을 지닙니다. \\n\\n![](https://images.velog.io/images/minkyu4506/post/143364fc-ea4f-4738-8c28-ad2d826983ed/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.59.06.png)\\n이런 방식으로 나온다는 뜻이죠. 중심에 자동차가 있고 앞에 빨간 점으로 자동차가 이동할 waypoint가 나와 있습니다. 이 때 waypoint의 집합 trajectory는 다음과 같이 정의됩니다. \\n![](https://images.velog.io/images/minkyu4506/post/e1e69200-2870-4820-87fb-71022c6b7fa2/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%2010.05.40.png)\\n\\n앞서 데이터셋을 구성할 때 T개의 waypoint 예측값이 모인 데이터셋을 만든다고 말씀드렸는데요, 저자는 T를 4로 정의했습니다. 왜 T를 4로 정의했냐면 예측 궤적을 가기 위한 제어값을 얻는 PID controller가 요구하는 waypoint의 default number가 4라서 T를 4로 설정했다고 말했습니다.\\n\\n여기까지 Input and Output Parameterization였습니다. \\n\\n### 3. 모델 설계\\n다음으로 모델의 구조에 대해 설명해 드리고자 합니다. \\n\\n모델의 구조는 크게 두 가지로 나눌 수 있습니다. 하나는 **Multi-Modal Fusion Transformer**고 다른 하나는 **Waypoint Prediction Network**입니다. \\n\\nMulti-Modal Fusion Transformer는 저자가 새로운 제안한 Transfuser를 말하는 것이구요, Waypoint Prediction Network는 Transfuser에서 얻은 값을 가지고 경로를 예측하는 모델입니다. \\n\\n우선 Transfuser부터 먼저 설명해 드리도록 하겠습니다. \\n\\n#### 1. Multi-Modal Fusion Transformer(Transfuser)\\nTransfuser는 다음과 같은 구조를 가지고 있습니다. \\n![](https://images.velog.io/images/minkyu4506/post/98673fc0-6990-40b0-869c-3052443d7086/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.46.13.png)\\n제가 Trnafuser는 특성을 추출하는 과정에서 Transformer를 이용해 전체 데이터를 고려하는 모델이라고 말씀드렸는데요, 이 그림을 보시면 \\\"아...이런 뜻이구나\\\" 이해하시지 않을까 싶습니다. \\n\\n여기서 눈여겨볼 항목은 당연히 저자가 강조한 Transformer를 이용해 전체 데이터 정보를 각 특성맵에 반영해주는 부분입니다. \\n![](https://images.velog.io/images/minkyu4506/post/09f43877-9853-4ba7-8912-21a2f59d9700/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.51.55.png) ![](https://images.velog.io/images/minkyu4506/post/9faf9fb5-3e84-4ddd-9beb-79600e08b92f/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.55.19.png)\\n이 부분을 말하는 것이죠. 아래 그림은 윗 그림에서 Transformer 부분을 강조한 그림입니다.\\n\\n여기서 진행되는 연산의 순서를 말씀드리면 다음과 같습니다. \\n\\n1. Conv + Pool 연산으로 특성맵 추출\\n2. 추출한 특성맵의 사이즈를 8 X 8로 압축 후 Transformer에 입력값으로 보냄\\n3. 각 데이터에서 보내준 8 X 8 크기의 특성맵 2개를 합체 = 16 X 8 사이즈의 특성맵 생성\\n4. 16X8 벡터를 Positional Embedding 후 Linear layer를 이용해 자동차의 현재 속도를 Embedding vector에 projection\\n5. Transformer에 넣어 self-attention 연산 => Embedding vector내 원소별로 전체 데이터(이미지 + LiDAR)에 대한 Attention이 반영됨. 사이즈는 16 X 8로 같음\\n6. Attention이 반영된 Embedding vector를 Image, LiDAR별로 나눔 -> 8 X 8 사이즈의 벡터가 2개 생성\\n7. 8 X 8 사이즈의 벡터를 압축하기 전의 크기로 scale up \\n8. 원래 특성맵과(1에서 추출한 특성맵) element-wise summation(원소끼리 더함)\\n\\n\\u003cbr>\\n\\n코드로 나타내면 상당히 간단해집니다. \\n![](https://images.velog.io/images/minkyu4506/post/f0cdda7c-89a7-4c60-8d4d-4e8d4826652d/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.09.01.png)\\n아무튼 간단해집니다. \\n\\n여튼, 이런 과정을 총 4번 반복합니다. 더 해도 안된다는 법은 없는데 저자는 4번 반복하라고 말했습니다. \\n\\n4번 반복한 뒤 마지막에 Average Pooling + Flatten연산을 해서 1 X 1 X 512 벡터를 2개 생성합니다. 이미지에서 얻고 LiDAR에서 얻으니까 총 2개를 얻는 것이죠. \\n\\n이 2개의 벡터를 element-wise summation해서 하나의 1 X 1 X 512 벡터로 만들어줍니다. \\n\\n이렇게 우리는 최종 출력값 1 X 1 X 512 벡터를 얻었습니다. 이제 Waypoint Prediction Network를 확인해보도록 합시다. \\n\\n#### 2. Waypoint Prediction Network\\n\\n앞서 우리는 Transfuser에서 1 X 1 X 512 사이즈의 벡터를 얻었습니다. \\n\\n이 벡터는 Waypoint Prediction Network에 쓰입니다. \\n\\nWaypoint Predictoin Network는 다음과 같은 구조를 가지고 있습니다. \\n\\n![](https://images.velog.io/images/minkyu4506/post/e2a83385-fdf5-4e03-9f20-8ae87396a950/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.47.15.png)\\n\\n보시면 MLP와 GRU로 이루어졌다는 사실을 확인하실 수 있습니다. \\n\\n1. MLP\\nMLP는 3개의 Linear Layer로 이루어져 있습니다. MLP는 입력값으로 들어오는 1 X 1 X 512 사이즈의 벡터를 1 X 1 X 64 벡터로 압축해줍니다. 계산의 효율성을 위해 줄여주는 겁니다. \\n코드는 다음과 같습니다. \\n![](https://images.velog.io/images/minkyu4506/post/cd1db45c-1c0c-4fe5-b9bc-64866cb05b21/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.20.57.png)\\n\\n2. GRU\\nGRU는 RNN에서 많이 쓰였던 LSTM을 개선한 알고리즘 입니다. 시계열 데이터를 처리하는데 적합한 알고리즘이죠. 이걸 레이어 형식으로 추가했습니다. \\nGRU는 현 시점의 입력 데이터와 hidden state를 받아 연산을 처리합니다. waypoint prediction network에서는 자동차의 좌표와 목표 지점의 좌표를 더한 값을 입력 값으로 하였습니다. 이 때 좌표의 단위는 gps입니다. \\n여기서 흥미로운 점이 있습니다. 바로 첫 시점의 입력 데이터 중 자동차의 좌표가 (0,0)이라는 점입니다. 이는 자동차가 좌표계의 원점에 있다고 가정했기 때문입니다. \\n그러니까 **입력 데이터를 넣는 시점에서 자동차의 위치가 x = (0,0)에 있다고 보는 것이고 (0,0)를 기준으로 향후 4 time의 waypoint를 예측하는 것**이라 보시면 되겠습니다. \\n다시 본론으로 돌아옵시다. 입력 데이터를 알아봤으니 이제 hidden state로 넘어가야죠. hidden state는 앞서 얻은 1 X 1 X 64 벡터로 초기화해줍니다. 우리가 입력 데이터로 얻은 특성을 hidden state를 초기화하는데 사용하는 겁니다. \\n이렇게 입력값을 넣어주면 출력값이 나올겁니다. 이 출력값을 Linear layer에 넣으면 현 시점의 자동차에서 움직여야할 좌표 dx가 생성됩니다. \\n이 dx에 기존 자동차의 좌표 x에 더하면 이제 다음 시점에 이동할 waypoint가 되는 겁니다. \\n이 waypoints는 다음 시점에서 현재 좌표가 되겠죠? next_x = x + dx인 겁니다. \\n여튼 이 과정을 4번 반복해 waypoint 4개를 얻습니다.\\n\\n#### Plus : PID controller\\n모델의 구조에는 없지만 자율주행을 수행하기 위해 꼭 있어야할 PID controller입니다. \\n앞서 예측한 경로를 PID controller에 넣어 주행에 필요한 제어값을 얻는다고 말씀드렸습니다. \\n실은 그 이상으로 설명드릴게 없습니다. 그러니 여기서는 구현된 코드를 보여드리고 넘어가도록 하겠습니다. \\n![](https://images.velog.io/images/minkyu4506/post/3fa43398-54ed-4ef2-ac1d-9e34b8896814/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.57.46.png)\\n코드의 return 부분을 보시면 운전에 필요한 데이터들이 나와있습니다. steer는 차를 얼마나 회전할지 나타낸거고 throttle는 엔진에 들어갈 공기량을 제어하니까 가속을 얼마나 할지 나타낸거고 brake는 감속을 얼마나 할지 나타내는 것이죠. \\n\\n그런데 낯선 데이터가 하나 있습니다. 바로 metadata입니다. 슥 살펴보니 steer, throttle, brake만으로 설명이 안되는 정보를 보충 설명해주는 데이터인듯 합니다. 아마 저자가 실험했을 때 제어값의 정보 부족으로 좀 애먹었던게 아닌가 싶네요. 제 추측입니다. \\n\\n여기까지 모델의 구조를 살펴봤습니다. \\n\\n## Experiment\\n---\\n이제 실험 부분을 설명해 드리고자 합니다. \\n\\n여기서는 실험 세팅(experimental setup), 성능 비교(Results), 입력 데이터간 상호보완성 비교(Attention Map Visualizations), 구성 요소를 하나씩 빼면서 성능 확인(Ablation Study) 순으로 내용이 전개됩니다. \\n\\n### 1. 실험 세팅(experimental setup)\\n\\n여기서는 성능 측정을 위해 모델이 해야할 task와 이를 위해 필요한 데이터셋, 평가 지표와 성능을 비교할 모델을 소개하고 있습니다. \\n\\n#### Task\\n모델이 수행할 task는 다양한 주행 환경에서 제한 시간 안에 운전 규정을 시키며 주행하는 것입니다. \\n\\n여기서 주행 경로는 gps좌표 형식의 waypoint의 집합으로 제공되며 주행 도중에 일정 확률로 자동차나 보행자가 등장할 수 있고 차선 변경, 회전 등 주행 중에 충분히 일어날 수 있는 상황도 경로에 포함되어 있습니다. \\n\\n앞서 논문에서 말한 '복잡한 운전 상황'속 주행 성능을 평가하는거라 생각하시면 됩니다. \\n\\n#### Dataset\\n데이터셋을 모으는 방법이 적혀있습니다. \\n\\n앞서 말씀드렸듯 Expert가 CARLA에 있는 가상환경에서 주행하며 데이터를 모은다고 말씀드렸습니다. 여기서 더 자세히 써보도록 하겠습니다. \\n\\nCARLA에는 주행을 할 수 있는 8개의 Town이 있습니다. 8개의 가상환경이 있는 것이죠. 각 town의 특성은 다음과 같습니다. \\n![](https://images.velog.io/images/minkyu4506/post/f9052600-3c62-40b6-bea6-c9dfb0c40ade/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%207.26.46.png)\\n각자 특성을 가지고 있죠. Expert는 여기서 Town 01, 02, 03, 04, 06, 07, 10에 사전 정의된 경로들을 달리며 학습용 데이터셋을 수집합니다. \\n\\n그리고 학습용 데이터셋으로 모델을 훈련시키고 난 뒤 Town05에서 주행 성능을 평가합니다. \\n\\nTown05는 1차선부터 n차선, 그리고 일반도로부터 고속도로까지 다양한 도로가 있기 때문에 주행 성능을 평가하는 맵으로 선정했다고 말했습니다. \\n\\n![](https://images.velog.io/images/minkyu4506/post/7fe65901-ef85-46ef-b802-861ba297b5e9/Town05.jpg)\\nTown05에 깔려있는 도로를 나타낸 사진입니다. 다양한 도로로 구성되어 있음을 확인할 수 있습니다. \\n\\n저자는 어떠한 주행 경로에서 성능을 평가하는지도 설명했습니다. 저자는 단거리 경로와 장거리 경로를 각 10개씩 뽑았고 이를 Town05 Short, Town05 Long이라 이름 지었습니다. 특징은 다음과 같습니다.\\n\\n* Town05 Short : 주행 거리 100~500m, 교차로 3개\\n* Town05 Long : 주행거리 1~2km, 교차로 10개\\n\\n그리고 주행 중에 자동차나 사람이 등장할 수 있다는 공통점이 있습니다. \\n\\n마지막으로 날씨입니다. 맑은 날 주행하는거랑 비오는 날에 주행하는건 난이도가 어느정도 차이가 나는데요, 저자는 **동적인 객체와 신호등에 대한 주행 성능 평가에 집중할 것이기 때문에** 날씨는 '항상 맑음'으로 고정한다고 말했습니다. \\n\\n개인적으로 아쉬운 부분이었습니다. 날씨도 변수를 줘서 실험을 했으면 더 좋지 않았을까 생각합니다. \\n\\n#### Metrics\\n\\n구글에 검색해보니 '측정 수단'이라는 뜻으로 해석됩니다. 즉, 평가지표입니다. \\n\\n저자는 평가 지표로 RC, DS, Infraction Count를 선택했습니다. 하나씩 설명해 드리도록 하겠습니다. \\n\\n1. RC(Route Completion) : 주행 경로를 몇%나 주행했는지 나타내는 수치입니다. \\n2. DS(Driving Score) : RC에 infraction multiplier를 곱한 값입니다. 여기서 infraction multiplier는 객체와의 충돌, 경로 이탈, 차선 침법, 신호 위반을 설명하는 수치라고 합니다. \\n3. Infraction Count : 따로 설명은 해놓지 않았지만 사고 종류별 발생 횟수를 측정한게 아닐까 싶습니다. \\n\\n#### Baselines\\n\\nTransfuser가 포함된 자율주행 모델과 성능을 비교할 모델을 적어놓았습니다. 5개의 모델과 비교합니다. \\n\\n모델 종류는 다음과 같습니다. \\n* CILRS : 카메라 이미지만 입력값으로 받으며 navigational command의 통제 아래 자율주행을 수행합니다. \\n* LBC : 원래 Bird's view image와 front image를 받았는데 논문(LBC)의 저자가 왼쪽 45도, 오른쪽 45도 각도에서 찍은 전면 카메라 이미지와 target heatmap을 입력값으로 받는걸로 바꿨습니다. \\n* AIM : 전면 카메라 이미지만 입력데이터로 받습니다. 단일 입력값을 받는 모델 중 가장 성능이 좋습니다. \\n* Late Fusion : 이제부터 두가지 입력값을 함께 처리하는 모델입니다. Late Fusion은 image와 LiDAR에서 얻은 값을 각각 Convolution Layer로 특성맵을 뽑아낸 후 element-wise summation해줍니다. \\n* Geometric Fusion : image와 LiDAR에서 얻은 값을 각각 Convolution Layer로 특성맵을 뽑을 때마다 서로 projection해 서로의 정보를 반영합니다. 이렇게 뽑은 두 특성맵을 element-wise summation 해줍니다.\\n![](https://images.velog.io/images/minkyu4506/post/de2f3a7e-32cc-4294-8330-9be27248df91/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%209.41.56.png)\\n위 사진은 구현코드입니다. 보시면 각자 특성을 추출 후 서로 projection하는걸 확인하실 수 있습니다. \\n\\n### 2. 실험 결과(Results)\\n실험 결과는 다음과 같습니다. \\n![](https://images.velog.io/images/minkyu4506/post/38b6e380-d752-4841-bac0-409e94f3ee8d/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%209.45.13.png)\\n왼쪽 사진은 Short, Long 경로에서 모델별 RC, DS를 나타낸거고 오른쪽 사진은 사고율을 나타낸 겁니다. \\n\\n#### Driving Performance\\n우선 왼쪽 표에 대해서 설명을 해드리도록 하겠습니다. \\n\\n여기서 눈여겨볼 부분은 한가지 입력값을 받는 CILRS, LBC, AIM보다 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능이 더 좋다는 겁니다. 두가지 입력값을 쓰기만 해도 한가지 입력값을 쓰는 것보다 성능이 좋다는 사실을 알 수 있습니다. \\n\\n그리고 또다시 눈여겨볼 부분은 Transfuser가 Late Fusion, Geometric Fusion보다 RC는 낮은데 DS가 높다는 것입니다. 즉, Transfuser는 주행 거리는 짧지만 안전운전을 더 잘한다는 뜻이죠. \\n\\n저자는 이를 보고 'Late Fusion, Geometric Fusion는 안전하게 운전하는 것보다 목표 지점에 가는데 중점을 뒀기 때문에 이런 결과가 나왔다'고 말했습니다. \\n\\n그리고 Expert의 점수도 나와있는데요, Expert도 장거리 운전에서는 그리 좋지 못한 성적을 얻었습니다. 신기합니다. \\n\\n#### Infraction\\n모델별 평균 사고율이 나옵니다. 초록색 막대가 Transfuser인데요, 모든 사고 항목에서 가장 낮습니다. 그런데  빨간불 신호 위반에서 다른 모델보다 낮긴 하지만 그래도 다른 사고 항목에 비하면 굉장히 높은 수치를 보입니다. 왜 그런걸까요? \\n\\n#### Limitations\\n여기선 모델의 한계점에 대해 저자가 얘기하는 부분입니다. 저자는 모델의 한계점으로 **빨간불 신호 위반의 확률이 높은 것**을 꼽았습니다. \\n\\n높은 신호위반 확률을 보이는 이유는 성능 평가를 위해 주행하던 경로에서 신호등이 카메라 구석에 찍혔는데 이 때문에 신호등의 빨간 불빛을 감지하기가 힘들어 빨간불에서 정차하지 않고 주행하는 일이 많았다고 합니다. \\n\\n그리고 이러한 문제를 해결할 additional supervision을 기대해본다고 말했습니다. \\n\\n### 3. Attention Map Visualizations\\n여기서는 카메라 이미지와 LiDAR point cloud간 상호보완성을 보여줍니다. \\n\\n어떻게 보여주냐면 교차로에서 신호대기중인 차량에서 얻은 이미지, Point cloud를 Transfuser로 특성을 추출하는 과정에서 self-attention을 통해 나온 16X8 사이즈의 벡터를 통해 설명합니다.\\n\\n여기서 반은 이미지쪽 벡터고 나머지 반은 LiDAR쪽 벡터입니다. 여기서 각각 자동차와 신호등에 대한 정보가 담긴 부분만 추출해 서로 얼마나 attention을 했는지 확인해봅니다. attention이 반영된 정도는 각 요소별 곱해진 score를 보고 알 수 있죠. \\n\\n그렇게 attention된 정도를 확인한 결과, 다음의 사실을 알 수 있었습니다. \\n* 이미지 토큰의 62.75%가 attention을 가장 많이 한 5개의 token이 LiDAR에서 나온 토큰\\n* LiDAR 토큰의 78.45%가 attention을 가장 많이 한 5개의 token이 이미지에서 나온 토큰\\n\\n여기서 토큰은 transformer에 입력값으로 들어가는 데이터 단위를 말합니다. 출력값 역시 토큰의 집합이죠. 토큰을 데이터로 바꾼 뒤 읽으셔도 의미의 차이는 없을듯 합니다. \\n\\n아무튼, 이렇게 서로 상호보완하는 부분이 많습니다. 특성을 추출할 때 상대 데이터를 많이 고려한다는 뜻이죠. \\n\\n### 4. Ablation Study\\n여기서는 Transfuser의 Transformer에 대해 값을 수정해가며 성능의 변화를 관측한걸 얘기합니다. 저자는 Town05 Short에서 성능 평가를 했는데요, 성능표는 다음과 같았습니다. \\n![](https://images.velog.io/images/minkyu4506/post/3060d95b-e30f-41f8-a83b-b79cf1877329/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%2011.02.23.png)\\n하나씩 설명해드리도록 하겠습니다. \\n\\n1. Scale : Transformer 이후 Fusion 횟수를 나타냅니다. 원래 4번 Fusion했는데 이 횟수를 줄여보며 성능을 비교해봤습니다. Scale이 1이면 마지막에 추출한 feature map(8X8X512)에서만 fusion하고 2면 16X16X256 feature map과 8X8X512 feature map에서 fusion하는거죠. \\n2. Shared Transformer : 원래 각 사이즈의 특성맵마다 다른 Transformer를 사용합니다. 그러면 모든 특성맵에서 다같은 Transformer를 사용하면 어떻게 될까요? 성능이 떨어졌습니다. 저자는 각 convolution layer에서 얻은 특성맵이 갖고 있는 성질이 다 다르기 때문에 각기 다른 Transformer에서 처리해야 한다고 말했습니다.(different convolutional layers in ResNet learn different types of features due to which each transformer has to focus on fusing different types of features)\\n3. Attention layers : 원래 각 Transfomer에는 8개의 Attention layer가 있습니다. 이를 1개, 4개로 만든 뒤 성능을 측정해봤습니다. \\n4. No Pos. Embd : Transformer에 넣기전에 Positional Embedding을 안했을 경우입니다. \\n\\n이렇게 각 요소를 제거한 뒤 성능을 비교했습니다. Scale을 제외한 나머지 부분에서 하나의 공통점이 있는데요, 바로 RC는 증가하지만 DS가 떨어졌다는 점입니다. \\n\\n저자는 이를 보고 'Attention횟수가 많아질 수록 더 조심히 운전하게 된다'고 말했습니다. \\n\\n## Conclusion\\n---\\n논문의 결말입니다. 저자는 앞서 말한 것을 conclusion에서 총체적으로 정리했습니다. 그리고 마지막에 자신들이 만든 모델에 다른 센서의 입력값을 추가해서 쓰거나 다른 AI task에 사용할 수 있다고 말하며 논문을 끝냈습니다. \\n\\u003cbr>\\n## 후기\\n---\\n이렇게 길고 긴 논문 리뷰가 끝났습니다. 최선을 다해 리뷰해봤는데 미숙한 부분이 많았습니다. 이런식으로 데이터를 받아서 처리하는 모델도 처음 접했고 자율주행 task를 수행하는 모델도 처음이라 읽는데 많은 시간이 걸렸습니다. 그래도 리뷰하고 나니 뿌듯하네요. \\n\\n3주 뒤에 다른 논문을 세미나에서 발표하는데 그 논문도 velog에 올릴 계획입니다. 개강이 얼마 남지 않은 시기라 쓰기 힘들겠지만 하...할 수 있겠죠? \\n\\n마지막으로 제가 이 논문을 읽고 느낀점을 쓰고자 합니다. 제가 느낀 점은 다음과 같습니다.\\n\\n* 두 종류의 입력값을 특성 추출 과정에서 반영함으로써 안전한 운전을 구현했다는 사실이 흥미로웠다.\\n\\n* 허나 Transformer가 전체 입력값을 모두 고려하며 계산하기 때문에 연산량이 좀 많을텐데 실시간으로 판단이 필요한 운전에서 이런 점이 부담이 되지 않을까 싶다.\\n\\n* 추후 주행 속도도 개선하며 안전운전을 추구하는 모델이 나왔으면 좋겠다.\\n\\n그리고 제가 이걸 세미나에서 발표했을 때 교수님께서 \\\"꼭 두가지 데이터를 사용했어야 했을까, LiDAR에서 얻은 정보를 사용할 때 2D 데이터로 변환하는 과정에서 많은 데이터 손실이 있을텐데 그걸 감수하면서까지 사용할 이유가 있을지 모르겠다, 차라리 시야각이 넓은 이미지를 사용하면 데이터 손실도 없이 사용할 수 있지 않을까\\\" 라고 저에게 말씀하셨습니다. \\n\\n실은 저는 입력값에 대한 어떠한 의문도 가지지 않았는데 교수님의 말씀을 듣고 의문이 들었습니다. 실제로 표를 봤을 때\\n![](https://images.velog.io/images/minkyu4506/post/d919d9ce-64eb-4d23-9e83-c67e9f7b4ca7/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.06.23.png)\\n여기 보시면 한가지 입력값만 받는 AIM과 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능차이가 크게 없다는 사실을 확인할 수 있습니다. 물론 장거리 주행에서는 DS에서 차이가 나긴 하지만 다들 점수가 낮기 때문에 큰 상관은 없다고 생각합니다. \\n\\n아무튼, 많은 공부가 되었고 재밌게 읽은 논문이었습니다. 다음 논문 리뷰에서 뵙겠습니다!\\n\\n\",\"short_description\":\" 안녕하세요. 밍기뉴와제제입니다.\\n\\n정말 오랜만에 돌아왔습니다. 이번에 리뷰하는 논문은 'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving'입니다.\\n\",\"is_markdown\":true,\"is_private\":false,\"is_temp\":false,\"thumbnail\":\"https://images.velog.io/images/minkyu4506/post/18537d03-8701-4bc7-90aa-f1cd4b26a51a/스크린샷 2021-08-06 오전 12.14.18.png\",\"comments_count\":1,\"url_slug\":\"논문리뷰-Multi-Modal-Fusion-Transformer-for-End-to-End-Autonomous-Driving\",\"likes\":6,\"liked\":false,\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"comments\":[{\"type\":\"id\",\"generated\":false,\"id\":\"Comment:16148570-8807-4fbe-9310-cf7cf3328a7a\",\"typename\":\"Comment\"}],\"__typename\":\"Post\",\"series\":{\"type\":\"id\",\"generated\":false,\"id\":\"Series:178ca26f-74db-41d1-b5a0-178dd836bd01\",\"typename\":\"Series\"},\"linked_posts\":{\"type\":\"id\",\"generated\":true,\"id\":\"$Post:040abdbb-a10b-4690-bcf8-060c67dd94d5.linked_posts\",\"typename\":\"LinkedPosts\"}},\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\":{\"id\":\"552ae1d0-fbd5-416e-81fb-acf301305d29\",\"username\":\"minkyu4506\",\"profile\":{\"type\":\"id\",\"generated\":false,\"id\":\"UserProfile:78c52242-365e-41ea-b3c4-75d5efd3ccbe\",\"typename\":\"UserProfile\"},\"velog_config\":{\"type\":\"id\",\"generated\":true,\"id\":\"$User:552ae1d0-fbd5-416e-81fb-acf301305d29.velog_config\",\"typename\":\"VelogConfig\"},\"__typename\":\"User\"},\"UserProfile:78c52242-365e-41ea-b3c4-75d5efd3ccbe\":{\"id\":\"78c52242-365e-41ea-b3c4-75d5efd3ccbe\",\"display_name\":\"Minguinho_zeze\",\"thumbnail\":\"https://images.velog.io/images/minkyu4506/profile/3d19426f-f141-4188-b23a-254ce14fce5a/Untitled.png\",\"short_bio\":\"안녕하세요. 딥러닝 알고리즘에 관심이 많은 학부생입니다. \",\"profile_links\":{\"type\":\"json\",\"json\":{\"email\":\"minkyu4506@gmail.com\",\"github\":\"MinkyuKim26\",\"twitter\":\"minguinho_zeze\"}},\"__typename\":\"UserProfile\"},\"$User:552ae1d0-fbd5-416e-81fb-acf301305d29.velog_config\":{\"title\":\"Minguinho_zeze.log\",\"__typename\":\"VelogConfig\"},\"Comment:16148570-8807-4fbe-9310-cf7cf3328a7a\":{\"id\":\"16148570-8807-4fbe-9310-cf7cf3328a7a\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:d9b8f8d1-1394-4e24-b896-edc0ed2ef6db\",\"typename\":\"User\"},\"text\":\"꼼꼼한 논문 리뷰 잘 보았습니다. 저도 논문 리서치 중인데, 논문 리뷰는 이렇게 하는 것이군요.ㅎㅎ 본받아서 저도 열심히 조사해야겠어요. 감사합니다:)\",\"replies_count\":0,\"level\":0,\"created_at\":\"2023-03-16T06:28:05.132Z\",\"deleted\":false,\"__typename\":\"Comment\"},\"User:d9b8f8d1-1394-4e24-b896-edc0ed2ef6db\":{\"id\":\"d9b8f8d1-1394-4e24-b896-edc0ed2ef6db\",\"username\":\"nopannogain\",\"profile\":{\"type\":\"id\",\"generated\":false,\"id\":\"UserProfile:c36ec24f-75e8-4a17-a323-3a2f97dcb4c0\",\"typename\":\"UserProfile\"},\"__typename\":\"User\"},\"UserProfile:c36ec24f-75e8-4a17-a323-3a2f97dcb4c0\":{\"id\":\"c36ec24f-75e8-4a17-a323-3a2f97dcb4c0\",\"thumbnail\":null,\"__typename\":\"UserProfile\"},\"Series:178ca26f-74db-41d1-b5a0-178dd836bd01\":{\"id\":\"178ca26f-74db-41d1-b5a0-178dd836bd01\",\"name\":\"논문 리뷰 + 구현\",\"url_slug\":\"논문-리뷰-구현\",\"series_posts\":[{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:2481b6f8-1a05-4325-bb59-886c7ed8a28f\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:6d0361d6-f3b1-43f7-a7d0-56f666687121\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:637c8f6b-abe2-4267-8f33-4c36b73f4632\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:ee72d632-dca9-44dd-8e12-c51a02367a17\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:c9de7822-2404-41fa-a656-400820f49f20\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:3ecb7f15-c79b-4f1a-b3df-62e2eba99a08\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:bb764c3c-14e6-4d00-9702-c78d36d69e1e\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:bc541266-5027-43fe-9702-5920cdbe5848\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:281a0201-84cf-45ca-bc6f-9a471088f055\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:ea7a6ef4-0395-402b-a3e7-ce3defaee215\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:f58d70bd-fc61-4bcb-a040-9dd6a83e0cda\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:fbe4d33c-08f6-4ae2-b9f4-4320d312b11b\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:2bf8abde-583f-40f8-b4ec-17cf20452600\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:5b3a3783-9ede-415f-9718-99895f53a06c\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:10f557e8-ec24-405e-9f5c-70aec262babd\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:6bbb2f85-556d-4a75-b863-48e79c1eec57\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:9c2661f7-08ab-4754-85fb-b916c8a25587\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:8d4dd3de-a6b2-4c03-b8aa-1f3028ebf4bc\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:8c9aefb2-03c9-4867-bfe4-1326b5262d1e\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:8c119007-0ca8-46bb-8e08-1b9ed1bbc85a\",\"typename\":\"SeriesPost\"},{\"type\":\"id\",\"generated\":false,\"id\":\"SeriesPost:3a3eb1ce-2fbd-43a2-96df-f6faa2d95b39\",\"typename\":\"SeriesPost\"}],\"__typename\":\"Series\"},\"SeriesPost:2481b6f8-1a05-4325-bb59-886c7ed8a28f\":{\"id\":\"2481b6f8-1a05-4325-bb59-886c7ed8a28f\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:672f3ed1-14c7-437c-9b71-45d3c62bc8f1\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:672f3ed1-14c7-437c-9b71-45d3c62bc8f1\":{\"id\":\"672f3ed1-14c7-437c-9b71-45d3c62bc8f1\",\"title\":\"[논문리뷰]Faster R-CNN 리뷰 + 코드구현(TensorFlow2)\",\"url_slug\":\"Faster-R-CNN-리뷰-with-Code\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:6d0361d6-f3b1-43f7-a7d0-56f666687121\":{\"id\":\"6d0361d6-f3b1-43f7-a7d0-56f666687121\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:040abdbb-a10b-4690-bcf8-060c67dd94d5\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"SeriesPost:637c8f6b-abe2-4267-8f33-4c36b73f4632\":{\"id\":\"637c8f6b-abe2-4267-8f33-4c36b73f4632\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:edc905f6-4fcf-492e-ad82-ec39eaaeb1de\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:edc905f6-4fcf-492e-ad82-ec39eaaeb1de\":{\"id\":\"edc905f6-4fcf-492e-ad82-ec39eaaeb1de\",\"title\":\"[논문리뷰] YOLO v1 리뷰 + 코드 구현(TensorFlow2)\",\"url_slug\":\"YOLO-v1-리뷰-코드-구현tensorflow2\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:ee72d632-dca9-44dd-8e12-c51a02367a17\":{\"id\":\"ee72d632-dca9-44dd-8e12-c51a02367a17\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:de387f0c-24db-4dde-a358-1046ab498f74\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:de387f0c-24db-4dde-a358-1046ab498f74\":{\"id\":\"de387f0c-24db-4dde-a358-1046ab498f74\",\"title\":\"[논문리뷰] Dynamic Head: Unifying Object Detection Heads with Attentions\",\"url_slug\":\"논문리뷰-Dynamic-Head-Unifying-Object-Detection-Heads-with-Attentions\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:c9de7822-2404-41fa-a656-400820f49f20\":{\"id\":\"c9de7822-2404-41fa-a656-400820f49f20\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:2c88e843-ccec-47dc-8895-b9c5a822b977\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:2c88e843-ccec-47dc-8895-b9c5a822b977\":{\"id\":\"2c88e843-ccec-47dc-8895-b9c5a822b977\",\"title\":\"[논문리뷰] CovidCTNet리뷰\",\"url_slug\":\"논문리뷰-CovidCTNet리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:3ecb7f15-c79b-4f1a-b3df-62e2eba99a08\":{\"id\":\"3ecb7f15-c79b-4f1a-b3df-62e2eba99a08\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:3b07b75b-ff53-4b53-9eb6-a9582649db1d\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:3b07b75b-ff53-4b53-9eb6-a9582649db1d\":{\"id\":\"3b07b75b-ff53-4b53-9eb6-a9582649db1d\",\"title\":\"[논문 리뷰] SSD(Single Shot MultiBox Detector)\",\"url_slug\":\"논문-리뷰-SSDSingle-Shot-MultiBox-Detector\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:bb764c3c-14e6-4d00-9702-c78d36d69e1e\":{\"id\":\"bb764c3c-14e6-4d00-9702-c78d36d69e1e\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:928c7e72-7b7c-4e5b-a9b0-a331beda119a\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:928c7e72-7b7c-4e5b-a9b0-a331beda119a\":{\"id\":\"928c7e72-7b7c-4e5b-a9b0-a331beda119a\",\"title\":\"[논문 리뷰] U-Net 리뷰\",\"url_slug\":\"논문-리뷰-U-Net-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:bc541266-5027-43fe-9702-5920cdbe5848\":{\"id\":\"bc541266-5027-43fe-9702-5920cdbe5848\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:0d78a78d-c132-4e2d-a70f-e64ff900dcaa\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:0d78a78d-c132-4e2d-a70f-e64ff900dcaa\":{\"id\":\"0d78a78d-c132-4e2d-a70f-e64ff900dcaa\",\"title\":\"[논문리뷰]GAN(Generative Adversarial Nets) 리뷰\",\"url_slug\":\"논문리뷰GANGenerative-Adversarial-Nets-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:281a0201-84cf-45ca-bc6f-9a471088f055\":{\"id\":\"281a0201-84cf-45ca-bc6f-9a471088f055\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:e1f57e7f-ef7a-4131-9ea4-0a38a07dc6d7\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:e1f57e7f-ef7a-4131-9ea4-0a38a07dc6d7\":{\"id\":\"e1f57e7f-ef7a-4131-9ea4-0a38a07dc6d7\",\"title\":\"[데이터셋 리뷰]  ‘DiLiGenT’ Photometric Stereo Dataset\",\"url_slug\":\"데이터셋-리뷰-DiLiGenT-Photometric-Stereo-Dataset\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:ea7a6ef4-0395-402b-a3e7-ce3defaee215\":{\"id\":\"ea7a6ef4-0395-402b-a3e7-ce3defaee215\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:bfe9ccde-c6c4-4d32-b99b-d757fa8a018a\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:bfe9ccde-c6c4-4d32-b99b-d757fa8a018a\":{\"id\":\"bfe9ccde-c6c4-4d32-b99b-d757fa8a018a\",\"title\":\"PyTorch로 YOLOv1  구현하기\",\"url_slug\":\"PyTorch로-YOLOv1-구현하기\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:f58d70bd-fc61-4bcb-a040-9dd6a83e0cda\":{\"id\":\"f58d70bd-fc61-4bcb-a040-9dd6a83e0cda\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:032c5d02-0a19-4166-af6d-6c40d05865bf\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:032c5d02-0a19-4166-af6d-6c40d05865bf\":{\"id\":\"032c5d02-0a19-4166-af6d-6c40d05865bf\",\"title\":\"[논문리뷰] Densely Connected Convolutional Networks(DenseNet)\",\"url_slug\":\"논문리뷰-Densely-Connected-Convolutional-NetworksDenseNet\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:fbe4d33c-08f6-4ae2-b9f4-4320d312b11b\":{\"id\":\"fbe4d33c-08f6-4ae2-b9f4-4320d312b11b\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:ae403834-c84e-46e5-a5e3-e5b8c39d04e9\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:ae403834-c84e-46e5-a5e3-e5b8c39d04e9\":{\"id\":\"ae403834-c84e-46e5-a5e3-e5b8c39d04e9\",\"title\":\"[논문 리뷰] Efficient Module Based Single Image Super Resolution for Multiple Problems\",\"url_slug\":\"논문-리뷰-Efficient-Module-Based-Single-Image-Super-Resolution-for-Multiple-Problems\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:2bf8abde-583f-40f8-b4ec-17cf20452600\":{\"id\":\"2bf8abde-583f-40f8-b4ec-17cf20452600\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:3e7c0d59-aac3-439e-a85a-8fe3935c94a8\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:3e7c0d59-aac3-439e-a85a-8fe3935c94a8\":{\"id\":\"3e7c0d59-aac3-439e-a85a-8fe3935c94a8\",\"title\":\"[논문리뷰] Extending Stein’s unbiased risk estimator to train deep denoisers with correlated pairs of noisy images\",\"url_slug\":\"논문리뷰-Extending-Steins-unbiased-risk-estimator-to-train-deep-denoisers-with-correlated-pairs-of-noisy-images\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:5b3a3783-9ede-415f-9718-99895f53a06c\":{\"id\":\"5b3a3783-9ede-415f-9718-99895f53a06c\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:59a95946-8c7d-4a0e-a6ab-1d7fa9dfc62e\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:59a95946-8c7d-4a0e-a6ab-1d7fa9dfc62e\":{\"id\":\"59a95946-8c7d-4a0e-a6ab-1d7fa9dfc62e\",\"title\":\"[논문리뷰] Multi-Temporal Recurrent Neural Networks For Progressive Non-Uniform Single Image Deblurring With Incremental Temporal Training\",\"url_slug\":\"논문리뷰-Multi-Temporal-Recurrent-Neural-Networks-For-Progressive-Non-Uniform-Single-Image-Deblurring-With-Incremental-Temporal-Training\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:10f557e8-ec24-405e-9f5c-70aec262babd\":{\"id\":\"10f557e8-ec24-405e-9f5c-70aec262babd\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:39a9ae37-abfe-4f76-b664-836f247b3164\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:39a9ae37-abfe-4f76-b664-836f247b3164\":{\"id\":\"39a9ae37-abfe-4f76-b664-836f247b3164\",\"title\":\"[논문리뷰] FEDPARA- LOW-RANK HADAMARD PRODUCT FOR COMMUNICATION-EFFICIENT FEDERATED LEARNING\",\"url_slug\":\"논문리뷰-FEDPARA-LOW-RANK-HADAMARD-PRODUCT-FOR-COMMUNICATION-EFFICIENT-FEDERATED-LEARNING\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:6bbb2f85-556d-4a75-b863-48e79c1eec57\":{\"id\":\"6bbb2f85-556d-4a75-b863-48e79c1eec57\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:b142364f-8e50-4e8b-aee2-56069c9591ac\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:b142364f-8e50-4e8b-aee2-56069c9591ac\":{\"id\":\"b142364f-8e50-4e8b-aee2-56069c9591ac\",\"title\":\"[논문리뷰] YOLOv2, YOLOv3 리뷰\",\"url_slug\":\"논문리뷰-YOLOv2-YOLOv3-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:9c2661f7-08ab-4754-85fb-b916c8a25587\":{\"id\":\"9c2661f7-08ab-4754-85fb-b916c8a25587\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:4ef447b8-2c67-4983-a2f5-a2509008e374\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:4ef447b8-2c67-4983-a2f5-a2509008e374\":{\"id\":\"4ef447b8-2c67-4983-a2f5-a2509008e374\",\"title\":\"[논문리뷰]NeRF: Representing Scenes as\\nNeural Radiance Fields for View Synthesis 리뷰\",\"url_slug\":\"NeRF-Representing-Scenes-asNeural-Radiance-Fields-for-View-Synthesis-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:8d4dd3de-a6b2-4c03-b8aa-1f3028ebf4bc\":{\"id\":\"8d4dd3de-a6b2-4c03-b8aa-1f3028ebf4bc\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:bea4ca63-cd86-4b37-a58e-a97659423e5a\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:bea4ca63-cd86-4b37-a58e-a97659423e5a\":{\"id\":\"bea4ca63-cd86-4b37-a58e-a97659423e5a\",\"title\":\"[논문리뷰] 'MLP-Mixer: An all-MLP Architecture for Vision' 리뷰 + 구현(PyTorch)\\n\",\"url_slug\":\"논문리뷰-MLP-Mixer-An-all-MLP-Architecture-for-Vision-리뷰-구현\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:8c9aefb2-03c9-4867-bfe4-1326b5262d1e\":{\"id\":\"8c9aefb2-03c9-4867-bfe4-1326b5262d1e\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:ccaa8ef1-263f-4fbb-b682-45406080ad57\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:ccaa8ef1-263f-4fbb-b682-45406080ad57\":{\"id\":\"ccaa8ef1-263f-4fbb-b682-45406080ad57\",\"title\":\"[논문리뷰] 'DiffusionDet: Diffusion Model for Object Detection' 리뷰\",\"url_slug\":\"논문리뷰-DiffusionDet-Diffusion-Model-for-Object-Detection-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:8c119007-0ca8-46bb-8e08-1b9ed1bbc85a\":{\"id\":\"8c119007-0ca8-46bb-8e08-1b9ed1bbc85a\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:4edba77a-e19c-4569-a7dc-22443fcb2dcb\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:4edba77a-e19c-4569-a7dc-22443fcb2dcb\":{\"id\":\"4edba77a-e19c-4569-a7dc-22443fcb2dcb\",\"title\":\"[논문리뷰] 'Compressing Neural Networks: Towards Determining the Optimal Layer-wise Decomposition' 리뷰\",\"url_slug\":\"논문리뷰-Compressing-Neural-Networks-Towards-Determining-the-Optimal-Layer-wise-Decomposition-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"SeriesPost:3a3eb1ce-2fbd-43a2-96df-f6faa2d95b39\":{\"id\":\"3a3eb1ce-2fbd-43a2-96df-f6faa2d95b39\",\"post\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:9a35ca2c-725a-4641-838b-a2f480bd1262\",\"typename\":\"Post\"},\"__typename\":\"SeriesPost\"},\"Post:9a35ca2c-725a-4641-838b-a2f480bd1262\":{\"id\":\"9a35ca2c-725a-4641-838b-a2f480bd1262\",\"title\":\"[논문리뷰] 'EfficientFormer: Vision Transformers at MobileNet Speed' 리뷰\",\"url_slug\":\"논문리뷰-EfficientFormer-Vision-Transformers-at-MobileNet-Speed-리뷰\",\"user\":{\"type\":\"id\",\"generated\":false,\"id\":\"User:552ae1d0-fbd5-416e-81fb-acf301305d29\",\"typename\":\"User\"},\"__typename\":\"Post\"},\"$Post:040abdbb-a10b-4690-bcf8-060c67dd94d5.linked_posts\":{\"previous\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:672f3ed1-14c7-437c-9b71-45d3c62bc8f1\",\"typename\":\"Post\"},\"next\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:edc905f6-4fcf-492e-ad82-ec39eaaeb1de\",\"typename\":\"Post\"},\"__typename\":\"LinkedPosts\"},\"ROOT_QUERY\":{\"post({\\\"url_slug\\\":\\\"논문리뷰-Multi-Modal-Fusion-Transformer-for-End-to-End-Autonomous-Driving\\\",\\\"username\\\":\\\"minkyu4506\\\"})\":{\"type\":\"id\",\"generated\":false,\"id\":\"Post:040abdbb-a10b-4690-bcf8-060c67dd94d5\",\"typename\":\"Post\"},\"velog_config({\\\"username\\\":\\\"minkyu4506\\\"})\":{\"type\":\"id\",\"generated\":true,\"id\":\"$ROOT_QUERY.velog_config({\\\"username\\\":\\\"minkyu4506\\\"})\",\"typename\":\"VelogConfig\"},\"auth\":null},\"$ROOT_QUERY.velog_config({\\\"username\\\":\\\"minkyu4506\\\"})\":{\"title\":\"Minguinho_zeze.log\",\"logo_image\":null,\"__typename\":\"VelogConfig\"}};</script><script>window.__REDUX_STATE__={\"core\":{\"layer\":false,\"auth\":{\"visible\":false,\"mode\":\"LOGIN\"},\"user\":null,\"popup\":{\"visible\":false,\"title\":\"\",\"message\":\"\"}},\"write\":{\"mode\":\"MARKDOWN\",\"markdown\":\"\",\"title\":\"\",\"html\":\"\",\"tags\":[],\"publish\":false,\"textBody\":\"\",\"defaultDescription\":\"\",\"description\":\"\",\"isPrivate\":false,\"urlSlug\":\"\",\"thumbnail\":null,\"editSeries\":false,\"selectedSeries\":null,\"postId\":null,\"isTemp\":false,\"initialTitle\":\"\",\"initialBody\":\"\"},\"header\":{\"custom\":true,\"userLogo\":{\"title\":\"Minguinho_zeze.log\",\"logo_image\":null},\"username\":\"minkyu4506\"},\"post\":{\"id\":null},\"error\":{\"errorType\":null},\"scroll\":{\"main\":0,\"user/posts\":0},\"home\":{\"timeframe\":\"week\"},\"darkMode\":{\"theme\":\"default\",\"systemTheme\":\"not-ready\"}};</script><script id=\"__LOADABLE_REQUIRED_CHUNKS__\" type=\"application/json\">[18,0,23,1,3]</script><script id=\"__LOADABLE_REQUIRED_CHUNKS___ext\" type=\"application/json\">{\"namedChunks\":[\"pages-velog-VelogPage\",\"PostPage\"]}</script><script async=\"\" data-chunk=\"main\" src=\"https://static.velog.io/static/js/runtime-main.5e039cd5.js\"></script><script async=\"\" data-chunk=\"main\" src=\"https://static.velog.io/static/js/20.357f3aca.chunk.js\"></script><script async=\"\" data-chunk=\"main\" src=\"https://static.velog.io/static/js/main.7e8cf780.chunk.js\"></script><script async=\"\" data-chunk=\"pages-velog-VelogPage\" src=\"https://static.velog.io/static/js/pages-velog-VelogPage.ebd63700.chunk.js\"></script><script async=\"\" data-chunk=\"PostPage\" src=\"https://static.velog.io/static/js/0.1f8bb2ed.chunk.js\"></script><script async=\"\" data-chunk=\"PostPage\" src=\"https://static.velog.io/static/js/23.3869d1a9.chunk.js\"></script><script async=\"\" data-chunk=\"PostPage\" src=\"https://static.velog.io/static/js/1.5cd4e340.chunk.js\"></script><script async=\"\" data-chunk=\"PostPage\" src=\"https://static.velog.io/static/js/PostPage.3dee536f.chunk.js\"></script></body></html>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('h3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jPX8RAGIIoFp",
        "outputId": "c6501442-1eca-4dfc-bd79-8d30573c229b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<h3 id=\"한가지-입력값만-받는-모델\">한가지 입력값만 받는 모델</h3>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('h3')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9K3gVsuJsvD",
        "outputId": "7ddc8453-c101-401a-c827-b6bc6fac71cc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<h3 id=\"한가지-입력값만-받는-모델\">한가지 입력값만 받는 모델</h3>,\n",
              " <h3 id=\"두가지-입력값을-함께-사용해보자\">두가지 입력값을 함께 사용해보자</h3>,\n",
              " <h3 id=\"여전히-아쉽다\">여전히 아쉽다!</h3>,\n",
              " <h3 id=\"transformer\">Transformer</h3>,\n",
              " <h3 id=\"single-view-image-and-lidar-inputs\">Single-view image and LiDAR inputs</h3>,\n",
              " <h3 id=\"transfuser\">Transfuser</h3>,\n",
              " <h3 id=\"1-problem-setting\">1. Problem Setting</h3>,\n",
              " <h3 id=\"2-input-and-output-parameterization\">2. Input and Output Parameterization</h3>,\n",
              " <h3 id=\"3-모델-설계\">3. 모델 설계</h3>,\n",
              " <h3 id=\"1-실험-세팅experimental-setup\">1. 실험 세팅(experimental setup)</h3>,\n",
              " <h3 id=\"2-실험-결과results\">2. 실험 결과(Results)</h3>,\n",
              " <h3 id=\"3-attention-map-visualizations\">3. Attention Map Visualizations</h3>,\n",
              " <h3 id=\"4-ablation-study\">4. Ablation Study</h3>,\n",
              " <h3>[논문리뷰]Faster R-CNN 리뷰 + 코드구현(TensorFlow2)</h3>,\n",
              " <h3>[논문리뷰] YOLO v1 리뷰 + 코드 구현(TensorFlow2)</h3>]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find_all('p')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nfaYHB5uJwxU",
        "outputId": "ab89e0bf-da11-446f-edd9-76fe3a3ac7fd"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<p> 안녕하세요. 밍기뉴와제제입니다. </p>,\n",
              " <p>정말 오랜만에 돌아왔습니다. 논문은 여러개 봤는데 리뷰할 정도로 깊게 탐구한 논문이 별로 없어 한동안 글을 안쓰다 이번에 논문 세미나를 하다보니 꼼꼼히 살펴본 논문이 생겼습니다. </p>,\n",
              " <p> 이번에 리뷰를 하려는 논문은 'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving '라는 논문입니다. 자율주행에 관한 논문이죠. </p>,\n",
              " <p> 이름을 보면 대충 짐작 가시겠지만 이 논문은 multimodal, 두가지 데이터를 처리하는 모델을 설계했습니다. 그리고 Transformer도 이용했다는 사실을 짐작할 수 있습니다. </p>,\n",
              " <p> 그러면 지금부터 논문 흐름에 맞춰 리뷰를 해보도록 하겠습니다. </p>,\n",
              " <p> 이 부분에서는 이전까지 자율주행 모델이 사용한 방식들을 소개 후 저자가 소개하는 모델 'transfuser'에 대해 설명합니다. </p>,\n",
              " <p> 이전에 Image-only model과 LiDAR-only model이 등장했고 이는 자율주행의 성능을 올리는데 많이 기여했습니다. 허나 이렇게 한가지 데이터만 입력값으로 사용한 모델은 <strong>near-ideal한 움직임을 보이는 객체</strong>들만 있는 환경에서 <strong>제한된 움직임만 필요한 경로</strong>에 주행해야만 높은 성능을 보여준다는 것이었죠. 굉장히 사용하기 까다로웠습니다. </p>,\n",
              " <p> 논문에서는 이를 두고 다음과 같이 말했습니다. </p>,\n",
              " <p>adversarial scenarios에서 만족스럽지 못한 성능을 보여준다</p>,\n",
              " <p>여기서 adversarial scenarios는 운전에 변수가 많이 생기는 환경을 말합니다. 예를 들면 비보호 회전을 해야하는 교차로, 랜덤하게 등장하는 자동차와 보행자 등이 운전에 변수를 주는 요소라 볼 수 있죠.<br/>\n",
              " 그러면 이런 부분이 왜 낮은 성능이 나오게끔 하는걸까요? 다음의 그림을 보며 설명해 드리도록 하겠습니다. </p>,\n",
              " <p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fcda53439-1ba7-461e-a3d2-7b6805019556%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%208.10.17.png\"/></p>,\n",
              " <p>위 사진은 논문에서 말한 adversarial scenarios 중 하나입니다.<br/>\n",
              " 여기서 초록색 박스 안에 있는 자동차(Ego-Vehicle)와 왼쪽 도로에서 건너오는 빨간색 박스 속 자동차들(Traffic), 그리고 노란색 박스 안에 있는 신호등(Traffic Lights)이 있습니다. 여기서 Ego-Vehicle이 자율주행을 하는 자동차죠.</p>,\n",
              " <p>이 상황에서 Ego-Vehicle이 카메라와 LiDAR에서 얻은 데이터를 살펴봅시다. LiDAR의 정의는 다음과 같습니다.</p>,\n",
              " <p>LiDAR : Light Detection And Ranging, 레이저를 발사 후 돌아오는 시간을 계산해 주변 물체를 검출하는 센서</p>,\n",
              " <p>LiDAR는 3D 데이터인 Point Cloud를 생산하며 여기엔 카메라가 관측할 수 없는 넓은 범위에 존재하는 객체에 대한 정보가 포함되어 있습니다. 그림을 보면 카메라 뷰에서 보이지 않는 자동차(Traffic)을 검출했다는 사실을 확인할 수 있습니다. </p>,\n",
              " <p>허나 LiDAR는 카메라가 검출한 신호등을 찾지 못했습니다. 즉, 각 센서별로 얻을 수 있는 정보가 다릅니다. </p>,\n",
              " <p>이러한 상황에서 Image-only 혹은 LiDAR-only model을 사용해 자율주행을 한다고 가정해봅시다.<br/>\n",
              " 그러면 아래와 같은 문제가 생길 확률이 높습니다.</p>,\n",
              " <p>이건 꽤 큰 단점이죠. 그래서 사람들은 이를 해결하기 위한 방법을 찾고자 했습니다. </p>,\n",
              " <p>사람들은 자율주행 자동차에 있는 센서에 주목했습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fed409fbd-f733-4294-a832-2410a12035b2%2F0*PjdSdGyiEB6Yg1UX.png\"/><br/>\n",
              " (출처 : <a href=\"https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f\">https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f</a>)</p>,\n",
              " <p>위 사진은 자율주행 자동차에 들어있는 센서를 나타낸 그림입니다. 보시면 알겠지만 자율주행 자동차 안에는 수많은 센서들이 들어있습니다. </p>,\n",
              " <p>이렇게 많은 센서를 보고 사람들이 생각한게 있습니다. </p>,\n",
              " <p>\"자동차에 있는 두개의 센서를 함께 사용해보는건 어떨까?\"</p>,\n",
              " <p>그래서 두가지 데이터를 함께 써보자는 아이디어를 떠올렸죠. 그리고 다음과 같은 질문을 남겼습니다. </p>,\n",
              " <p>이 질문에 답하기 위해 수많은 논문들이 나왔습니다. 그 중 한가지 논문에 나온 모델 구조에 대해 간단히 소개해드리겠습니다. </p>,\n",
              " <p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F74c12e61-7d7c-46aa-844e-21a9991b62fd%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-04%20%EC%98%A4%ED%9B%84%2010.19.35.png\"/><br/>\n",
              " (출처 : Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proc. IEEE Conf. on Computer Vision and Pat- tern Recognition (CVPR), 2017)</p>,\n",
              " <p>위 그림에 나온 구조가 두가지 데이터를 처리하는 대부분의 모델이 사용하는 구조입니다. 각 데이터별로 CNN에 넣어 특성맵을 추출한 뒤 원소 단위로 평균값을 낸다든지 더한다든지 하는 방식으로 Fusion해 하나의 출력값으로 만드는 방식이죠. </p>,\n",
              " <p>두가지 데이터를 이용하는 방식은 한가지 데이터를 사용하는 방식보다 성능이 좋았습니다. 허나 여전히 단점이 있었습니다. </p>,\n",
              " <p>바로 도심 속 운전같이 복잡한 상황에서 운전하기 힘들다는 점이었습니다. </p>,\n",
              " <p>교차로에서 운전할 때를 고려해봅시다. 위에 제가 올린 사진과 같은 상황이죠. 여기서 자율주행을 하는 자동차(Ego-Vehicle)는 왼쪽에서 오는 자동차(Traffic)과 신호등의 신호(Traffic Lights) 사이의 연관성을 고려하며 운전을 해야합니다. 허나 각 데이터별로 특성맵을 추출하면 특성을 추출하는 과정에서 모든 정보를 고려할 수 없게 됩니다. </p>,\n",
              " <p>즉, 모든 정보를 고려하지 않고 얻어낸 정보를 가지고 운전하기 때문에 사고가 날 확률이 높은 것이죠.</p>,\n",
              " <p>이는 데이터의 문제가 아니라 데이터를 처리하는 모델 구조의 문제였습니다. </p>,\n",
              " <p>그래서 저자는 Attention mechanism만 사용해 데이터를 처리하는 Transformer를 특성 추출 과정에서 사용하기로 했습니다. </p>,\n",
              " <p>Transformer의 self-attention는 입력 값의 각 원소가 전체적인 입력값의 어느 부분을 더 주목해야 하는지 반영하게 해주니 이를 이용해 이미지와 LiDAR 데이터를 전체적으로 고려하며 특성맵을 추출하는 방식을 생각한 것입니다.</p>,\n",
              " <p>\"두가지 데이터를 어떤 방식으로 합쳐서 사용하지?\" 에 대한 답변은 Transforemr였습니다.</p>,\n",
              " <p>그리고 \"두가지 데이터로 어떤걸 선택하지?\"에 대한 답변을 해야합니다. </p>,\n",
              " <p>저자는 이에 \"Single-view image and LiDAR를 입력 데이터로 사용한다\"고 말했습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F74af93a1-93f3-4d49-a6e9-dc0fa9a07905%2F%EC%9E%90%EB%A3%8C.png\"/><br/>\n",
              " 이 둘을 사용하겠다는 것이죠.</p>,\n",
              " <p>왜 Single-view image and LiDAR를 선택한 걸까요? 저자는 이 둘이 서로가 서로에게 부족한 점을 채워주는 상호보완성이 있기 때문에 선택했다고 말했습니다. </p>,\n",
              " <p>즉, 이 둘을 입력데이터로 사용해 얻는 정보의 양이 제일 많다고 판단한 것이죠. </p>,\n",
              " <p>이제 저자가 생각해낸 모델을 정리해봅시다. </p>,\n",
              " <p>입력 데이터로 Single-view image and LiDAR를 받아 특성을 추출하는 과정에서 Transformer를 사용해 전체적인 정보를 고려하는 모델</p>,\n",
              " <p>한문장으로 간단히 정리됩니다. 저자는 이렇게 설계된 모델을 <strong>Transfuser</strong>라고 정의했습니다.</p>,\n",
              " <p>여기까지 모델의 Introduction 부분이었습니다. 깔끔히 쓰고 싶었는데 쉽지않네요. 허허...</p>,\n",
              " <p>그럼 이제 Transfuser가 포함된 자율주행 모델이 만들어지는 과정을 소개한 Method 항목을 소개해 드리도록 하겠습니다. </p>,\n",
              " <p>원래 Releated work를 슥 살펴보고 Method로 넘어가야 하는데 그러면 분량이 너무 많아져서 바로 Method로 건너왔습니다. 저도 자율주행 모델에 대해 잘 감이 안잡힌 상태에서 이 논문을 읽어서 Related work 부분이 논문 이해에 꽤나 도움이 되었습니다. 관심 있으신 분들은 따로 찾아서 읽어보시는걸 추천드립니다. </p>,\n",
              " <p>아무튼, 이제 Method에 대해 설명해 드리도록 하겠습니다.</p>,\n",
              " <p>Method에는 Transformer를 이용해 자율주행 모델을 만드는 일련의 과정이 적혀있습니다. </p>,\n",
              " <p>모델을 만드는 과정은 다음과 같이 3단계로 나눌 수 있습니다. </p>,\n",
              " <p>그러면 'Task 설정'부터 설명해 드리도록 하겠습니다.</p>,\n",
              " <p>모델이 해결할 Task를 설정하고 이를 위한 학습법, 그리고 필요한 데이터셋을 설명하는 부분입니다. </p>,\n",
              " <p>저자는 <strong>point-to-point navigation</strong>를 모델이 수행할 Task로 설정했습니다. </p>,\n",
              " <p>저자는 point to point navigation이 목표지점까지 waypoint를 따라 사고 없이 완주하는 것이라 말했습니다. 여기서 사고는 다른 객체(자동차, 사람 등)과 충돌하거나 교통법규를 어기는 것을 말하죠. </p>,\n",
              " <p>그리고 이를 학습하는 방법으로 imitation learning을 선택했습니다. imitation learning이란 강화학습의 일종인데요, 의미 그대로 해당 task에서 전문가(Expert)가 하는걸 따라하는 학습법입니다. </p>,\n",
              " <p>강화 학습은 학습 주체인 agent와 agent가 행동하는데 규범이 되는 policy, 행동의 결과인 action, action으로 인한 상태 state, 그리고 state에 대한 보상 reward가 있습니다.여기서 보상 reward를 가장 많이 받는 방향으로 학습시키는 것이 목표죠. </p>,\n",
              " <p>reward를 많이 받도록 만드는 방식은 여러가지가 있습니다. 그중 하나가 행동 규범힌 policy를 학습가능한 상태(parameterize)로 만드는 것이죠. </p>,\n",
              " <p>imitation learning도 그 방식을 사용하고 있으며 논문에서는 다음과 같이 설명합니다. </p>,\n",
              " <p>Policy를 Expert의 policy를 따라하게끔 학습하는 것</p>,\n",
              " <p>그런데 여기서 궁금증이 생겼습니다. 왜 imiation learning을 선택한거지? 그래서 찾아봤습니다.<br/>\n",
              " 찾아보니까 이렇게 policy를 학습 대상으로 삼아 학습시키는 방식은 <strong>고차원 데이터를 처리하고 연속된 action을 해야하는 모델의 학습에 적합</strong>하다고 합니다. </p>,\n",
              " <p>이미지라는 고차원 데이터를 처리해 연속된 action이 필요한 운전을 하는 자율주행 모델에 적합한방식이라 선택한게 아닌가 싶습니다. </p>,\n",
              " <p>그러면 이제 저자가 imitation learning을 사용한 학습과정을 설명해 드리도록 하겠습니다.</p>,\n",
              " <p>우선 데이터셋을 수집해야하죠? 학습을 위한 학습 데이터셋과 평가를 위한 테스트 데이터셋이 필요합니다. </p>,\n",
              " <p>데이터셋은 자율주행 오픈소스 시뮬레이터 CARLA(<a href=\"https://carla.org\">https://carla.org</a>)에 있는 가상 환경에서 수집<br/>\n",
              " 합니다. 별다른 이유는 적지 않았지만 아무래도 사고가 날 수 있는 상황에 대한 데이터도 모으기 때문에 그런게 아닌가 싶네요. </p>,\n",
              " <p>여튼, CARLA에 있는 가상환경에서 Expert가 주행하며 데이터를 모읍니다. imitation learning에서 말씀드린 Expert 맞습니다. </p>,\n",
              " <p>Expert는 가상환경을 주행하며 입력 데이터와 출력 데이터를 수집합니다. 그렇게 해서<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fbf940494-966f-4a2d-ab3e-15adb7e16afe%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.06.20.png\"/><br/>\n",
              " 위와 같은 데이터셋 D를 만들어줍니다. </p>,\n",
              " <p>여기서 X는 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 한 시점(single time step)에 이미지 한장, point cloud 하나가 있는 것이죠.</p>,\n",
              " <p>그리고 W는 T개의 waypoint가 모인 w로 이루어져 있습니다. 즉, 이미지와 point cloud를 하나씩 넣으면 출력값으로 T개의 Waypoint가 나오는 모델을 만들겠다는 뜻이죠.</p>,\n",
              " <p>이렇게 데이터셋을 모았으니 학습을 시켜봅시다. 학습 방식은 다음과 같이 정의할 수 있습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F42199532-a602-4a20-89e2-8a21126a3759%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.11.08.png\"/><br/>\n",
              " 여기서 L은 Loss함수입니다. 그러니까 Expert가 주행한 경로와 우리가 만든 agent의 policy에 따른 action, 다시 말해 <strong>우리가 만든 모델이 예측한 주행 경로 사이의 loss가 최소가 되게끔 policy를 학습시키겠다</strong>는 뜻이죠. </p>,\n",
              " <p>저자는 이러한 학습 방식을 지도학습의 방식이라고 말했습니다. Expert의 데이터를 label data, 내가 만든 모델의 데이터가 prediction data라고 보면 저자의 말이 이해가 되시지 않을까 싶습니다. </p>,\n",
              " <p>그래서 강화학습은 어떻게 학습 시키는걸까 찾아봤습니다. 강화학습은 데이터셋을 사용하지 않고 학습하기 때문에 매 순간 자기 자신이 만든 state와 reward를 보고 다음 action에 반영하며 점점 높은 reward만 받는 모델로 학습되는 방식을 사용한다는 사실을 알아냈습니다. 지도학습으로만 모델을 학습시켜본 저에게 있어서 강화학습은 상당히 신기한 방식입니다. </p>,\n",
              " <p>저자는 학습 이후 어떻게 자율주행에 사용할지도 설명해 주었습니다.<br/>\n",
              " 저자는 모델이 예측한 경로를 inverse dynamics model에 넣어 얻은 action으로 주행을 한다고 말했고 이 때 inverse dynamics model을 PID controller로 구현했다고 설명했습니다. </p>,\n",
              " <p>PID controller는 간단한게 말해 주어진 출력값을 위해 필요한 제어값(가속, 감속, 회전 등)을 구하는 요소라고 보시면 됩니다. 자세한 설명은 <a href=\"https://ko.wikipedia.org/wiki/PID_%EC%A0%9C%EC%96%B4%EA%B8%B0\">여기</a>서 확인하실 수 있습니다. </p>,\n",
              " <p>저자는 이러한 과정을 다음과 같은 식으로 나타냈습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fa7c85e89-258f-4110-991f-1a7316121323%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.23.16.png\"/><br/>\n",
              " action = PID(예측 경로)인 것이죠. 여기서 action은 agent가 행한 action과 동일한 개념입니다. </p>,\n",
              " <p>마지막에 등장하는 문단인데 처음에는 이게 왜 있는건가 싶었습니다. </p>,\n",
              " <p>읽어보니 저자들은 CARLA의 표준 프로토콜을 따르고 목표 지점이 GPS 좌표로 제공되며 목표 지점과 자동차가 안내한 지점이 몇백미터 떨어질 수 있다고 나와있습니다. </p>,\n",
              " <p>다른 부분은 그러려니 하고 읽었는데 마지막 부분 '목표 지점과 안내 지점이 몇백미터 떨어질 수 있다'는 말이 거슬렸습니다. 도대체 뭔 뜻이지? </p>,\n",
              " <p>제가 논문 세미나를 할 때 이 논문을 가지고 했는데요, 이에 관해 세미나 계신 분들께 여쭤보고 답을 들었는데도 이해가 제대로 안되서 구글에 검색까지 해봤습니다.</p>,\n",
              " <p>구글에 검색을 해보니 다음과 같은 글을 발견했습니다. </p>,\n",
              " <p>The global planner plans a global path around obstacles</p>,\n",
              " <p>대충 번역하면 장애물을 돌아가는 global path를 생성하는게 global planner라고 하네요. </p>,\n",
              " <p>아마 <strong>목표 지점에 가기 힘들면 그 근처로 안내할 수 있음</strong>을 말하고 싶어서 이 부분을 추가한게 아닌가 싶습니다.</p>,\n",
              " <p>여기까지 Problem Setting이었습니다.</p>,\n",
              " <p>이제 데이터셋을 어떻게 만들었는지? 정확히는 모델의 학습에 사용하기 위해 어떤 작업을 했는지 설명해 드리도록 하겠습니다.</p>,\n",
              " <p>우선 입력 데이터부터 설명해 드리고자 합니다.</p>,\n",
              " <p>입력 데이터는 앞서 말씀드렸듯 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 카메라 이미지는 2D 데이터고 Point cloud는 3D 데이터라 각자 처리방식이 다릅니다. </p>,\n",
              " <p>카메라 이미지<br/>\n",
              " 카메라에서 촬영된 이미지는 400X300 사이즈인데요, 여기서 가운데 256X256 영역만 추출해서 사용합니다. 왜냐하면 렌즈 구조상 외곽 이미지는 왜곡 되어있기 때문입니다. 이렇게 <strong>256X256X3</strong> 사이즈의 데이터를 얻습니다. </p>,\n",
              " <p>LiDAR Point Cloud<br/>\n",
              " 저자는 LiDAR에서 얻은 Point Cloud 중 자동차의 전면 32m, 좌우 측면 각 16m씩 해서 총 32m X 32m 영역만 사용합니다. 그리고 이를 2D 데이터로 변환해주는데요, 한 셀당 0.125m X 0.125m로 해서 256 X 256 픽셀 데이터로 변환해줍니다.<br/>\n",
              " 그리고 Point Cloud는 3D 데이터라 높이에 관한 데이터도 있는데요, 저자는 이를 2개의 채널에 담았습니다. 하나는 지면 위(+) 높이 데이터, 다른 하나는 지면 밑(-) 높이 데이터를 담았죠.<br/>\n",
              " 이렇게 <strong>256X256X2</strong> 사이즈의 데이터를 얻습니다.</p>,\n",
              " <p>출력값 양식을 정의하는 부분입니다. </p>,\n",
              " <p>출력값, 즉 waypoint는 BEV space에서 (x,y)의 양식을 지닙니다. </p>,\n",
              " <p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F143364fc-ea4f-4738-8c28-ad2d826983ed%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%209.59.06.png\"/><br/>\n",
              " 이런 방식으로 나온다는 뜻이죠. 중심에 자동차가 있고 앞에 빨간 점으로 자동차가 이동할 waypoint가 나와 있습니다. 이 때 waypoint의 집합 trajectory는 다음과 같이 정의됩니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fe1e69200-2870-4820-87fb-71022c6b7fa2%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%EC%A0%84%2010.05.40.png\"/></p>,\n",
              " <p>앞서 데이터셋을 구성할 때 T개의 waypoint 예측값이 모인 데이터셋을 만든다고 말씀드렸는데요, 저자는 T를 4로 정의했습니다. 왜 T를 4로 정의했냐면 예측 궤적을 가기 위한 제어값을 얻는 PID controller가 요구하는 waypoint의 default number가 4라서 T를 4로 설정했다고 말했습니다.</p>,\n",
              " <p>여기까지 Input and Output Parameterization였습니다. </p>,\n",
              " <p>다음으로 모델의 구조에 대해 설명해 드리고자 합니다. </p>,\n",
              " <p>모델의 구조는 크게 두 가지로 나눌 수 있습니다. 하나는 <strong>Multi-Modal Fusion Transformer</strong>고 다른 하나는 <strong>Waypoint Prediction Network</strong>입니다. </p>,\n",
              " <p>Multi-Modal Fusion Transformer는 저자가 새로운 제안한 Transfuser를 말하는 것이구요, Waypoint Prediction Network는 Transfuser에서 얻은 값을 가지고 경로를 예측하는 모델입니다. </p>,\n",
              " <p>우선 Transfuser부터 먼저 설명해 드리도록 하겠습니다. </p>,\n",
              " <p>Transfuser는 다음과 같은 구조를 가지고 있습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F98673fc0-6990-40b0-869c-3052443d7086%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.46.13.png\"/><br/>\n",
              " 제가 Trnafuser는 특성을 추출하는 과정에서 Transformer를 이용해 전체 데이터를 고려하는 모델이라고 말씀드렸는데요, 이 그림을 보시면 \"아...이런 뜻이구나\" 이해하시지 않을까 싶습니다. </p>,\n",
              " <p>여기서 눈여겨볼 항목은 당연히 저자가 강조한 Transformer를 이용해 전체 데이터 정보를 각 특성맵에 반영해주는 부분입니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F09f43877-9853-4ba7-8912-21a2f59d9700%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.51.55.png\"/> <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F9faf9fb5-3e84-4ddd-9beb-79600e08b92f%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.55.19.png\"/><br/>\n",
              " 이 부분을 말하는 것이죠. 아래 그림은 윗 그림에서 Transformer 부분을 강조한 그림입니다.</p>,\n",
              " <p>여기서 진행되는 연산의 순서를 말씀드리면 다음과 같습니다. </p>,\n",
              " <p>코드로 나타내면 상당히 간단해집니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Ff0cdda7c-89a7-4c60-8d4d-4e8d4826652d%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.09.01.png\"/><br/>\n",
              " 아무튼 간단해집니다. </p>,\n",
              " <p>여튼, 이런 과정을 총 4번 반복합니다. 더 해도 안된다는 법은 없는데 저자는 4번 반복하라고 말했습니다. </p>,\n",
              " <p>4번 반복한 뒤 마지막에 Average Pooling + Flatten연산을 해서 1 X 1 X 512 벡터를 2개 생성합니다. 이미지에서 얻고 LiDAR에서 얻으니까 총 2개를 얻는 것이죠. </p>,\n",
              " <p>이 2개의 벡터를 element-wise summation해서 하나의 1 X 1 X 512 벡터로 만들어줍니다. </p>,\n",
              " <p>이렇게 우리는 최종 출력값 1 X 1 X 512 벡터를 얻었습니다. 이제 Waypoint Prediction Network를 확인해보도록 합시다. </p>,\n",
              " <p>앞서 우리는 Transfuser에서 1 X 1 X 512 사이즈의 벡터를 얻었습니다. </p>,\n",
              " <p>이 벡터는 Waypoint Prediction Network에 쓰입니다. </p>,\n",
              " <p>Waypoint Predictoin Network는 다음과 같은 구조를 가지고 있습니다. </p>,\n",
              " <p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fe2a83385-fdf5-4e03-9f20-8ae87396a950%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%202.47.15.png\"/></p>,\n",
              " <p>보시면 MLP와 GRU로 이루어졌다는 사실을 확인하실 수 있습니다. </p>,\n",
              " <p>MLP<br/>\n",
              " MLP는 3개의 Linear Layer로 이루어져 있습니다. MLP는 입력값으로 들어오는 1 X 1 X 512 사이즈의 벡터를 1 X 1 X 64 벡터로 압축해줍니다. 계산의 효율성을 위해 줄여주는 겁니다.<br/>\n",
              " 코드는 다음과 같습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fcd1db45c-1c0c-4fe5-b9bc-64866cb05b21%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.20.57.png\"/></p>,\n",
              " <p>GRU<br/>\n",
              " GRU는 RNN에서 많이 쓰였던 LSTM을 개선한 알고리즘 입니다. 시계열 데이터를 처리하는데 적합한 알고리즘이죠. 이걸 레이어 형식으로 추가했습니다.<br/>\n",
              " GRU는 현 시점의 입력 데이터와 hidden state를 받아 연산을 처리합니다. waypoint prediction network에서는 자동차의 좌표와 목표 지점의 좌표를 더한 값을 입력 값으로 하였습니다. 이 때 좌표의 단위는 gps입니다.<br/>\n",
              " 여기서 흥미로운 점이 있습니다. 바로 첫 시점의 입력 데이터 중 자동차의 좌표가 (0,0)이라는 점입니다. 이는 자동차가 좌표계의 원점에 있다고 가정했기 때문입니다.<br/>\n",
              " 그러니까 <strong>입력 데이터를 넣는 시점에서 자동차의 위치가 x = (0,0)에 있다고 보는 것이고 (0,0)를 기준으로 향후 4 time의 waypoint를 예측하는 것</strong>이라 보시면 되겠습니다.<br/>\n",
              " 다시 본론으로 돌아옵시다. 입력 데이터를 알아봤으니 이제 hidden state로 넘어가야죠. hidden state는 앞서 얻은 1 X 1 X 64 벡터로 초기화해줍니다. 우리가 입력 데이터로 얻은 특성을 hidden state를 초기화하는데 사용하는 겁니다.<br/>\n",
              " 이렇게 입력값을 넣어주면 출력값이 나올겁니다. 이 출력값을 Linear layer에 넣으면 현 시점의 자동차에서 움직여야할 좌표 dx가 생성됩니다.<br/>\n",
              " 이 dx에 기존 자동차의 좌표 x에 더하면 이제 다음 시점에 이동할 waypoint가 되는 겁니다.<br/>\n",
              " 이 waypoints는 다음 시점에서 현재 좌표가 되겠죠? next_x = x + dx인 겁니다.<br/>\n",
              " 여튼 이 과정을 4번 반복해 waypoint 4개를 얻습니다.</p>,\n",
              " <p>모델의 구조에는 없지만 자율주행을 수행하기 위해 꼭 있어야할 PID controller입니다.<br/>\n",
              " 앞서 예측한 경로를 PID controller에 넣어 주행에 필요한 제어값을 얻는다고 말씀드렸습니다.<br/>\n",
              " 실은 그 이상으로 설명드릴게 없습니다. 그러니 여기서는 구현된 코드를 보여드리고 넘어가도록 하겠습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F3fa43398-54ed-4ef2-ac1d-9e34b8896814%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%203.57.46.png\"/><br/>\n",
              " 코드의 return 부분을 보시면 운전에 필요한 데이터들이 나와있습니다. steer는 차를 얼마나 회전할지 나타낸거고 throttle는 엔진에 들어갈 공기량을 제어하니까 가속을 얼마나 할지 나타낸거고 brake는 감속을 얼마나 할지 나타내는 것이죠. </p>,\n",
              " <p>그런데 낯선 데이터가 하나 있습니다. 바로 metadata입니다. 슥 살펴보니 steer, throttle, brake만으로 설명이 안되는 정보를 보충 설명해주는 데이터인듯 합니다. 아마 저자가 실험했을 때 제어값의 정보 부족으로 좀 애먹었던게 아닌가 싶네요. 제 추측입니다. </p>,\n",
              " <p>여기까지 모델의 구조를 살펴봤습니다. </p>,\n",
              " <p>이제 실험 부분을 설명해 드리고자 합니다. </p>,\n",
              " <p>여기서는 실험 세팅(experimental setup), 성능 비교(Results), 입력 데이터간 상호보완성 비교(Attention Map Visualizations), 구성 요소를 하나씩 빼면서 성능 확인(Ablation Study) 순으로 내용이 전개됩니다. </p>,\n",
              " <p>여기서는 성능 측정을 위해 모델이 해야할 task와 이를 위해 필요한 데이터셋, 평가 지표와 성능을 비교할 모델을 소개하고 있습니다. </p>,\n",
              " <p>모델이 수행할 task는 다양한 주행 환경에서 제한 시간 안에 운전 규정을 시키며 주행하는 것입니다. </p>,\n",
              " <p>여기서 주행 경로는 gps좌표 형식의 waypoint의 집합으로 제공되며 주행 도중에 일정 확률로 자동차나 보행자가 등장할 수 있고 차선 변경, 회전 등 주행 중에 충분히 일어날 수 있는 상황도 경로에 포함되어 있습니다. </p>,\n",
              " <p>앞서 논문에서 말한 '복잡한 운전 상황'속 주행 성능을 평가하는거라 생각하시면 됩니다. </p>,\n",
              " <p>데이터셋을 모으는 방법이 적혀있습니다. </p>,\n",
              " <p>앞서 말씀드렸듯 Expert가 CARLA에 있는 가상환경에서 주행하며 데이터를 모은다고 말씀드렸습니다. 여기서 더 자세히 써보도록 하겠습니다. </p>,\n",
              " <p>CARLA에는 주행을 할 수 있는 8개의 Town이 있습니다. 8개의 가상환경이 있는 것이죠. 각 town의 특성은 다음과 같습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Ff9052600-3c62-40b6-bea6-c9dfb0c40ade%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%207.26.46.png\"/><br/>\n",
              " 각자 특성을 가지고 있죠. Expert는 여기서 Town 01, 02, 03, 04, 06, 07, 10에 사전 정의된 경로들을 달리며 학습용 데이터셋을 수집합니다. </p>,\n",
              " <p>그리고 학습용 데이터셋으로 모델을 훈련시키고 난 뒤 Town05에서 주행 성능을 평가합니다. </p>,\n",
              " <p>Town05는 1차선부터 n차선, 그리고 일반도로부터 고속도로까지 다양한 도로가 있기 때문에 주행 성능을 평가하는 맵으로 선정했다고 말했습니다. </p>,\n",
              " <p><img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F7fe65901-ef85-46ef-b802-861ba297b5e9%2FTown05.jpg\"/><br/>\n",
              " Town05에 깔려있는 도로를 나타낸 사진입니다. 다양한 도로로 구성되어 있음을 확인할 수 있습니다. </p>,\n",
              " <p>저자는 어떠한 주행 경로에서 성능을 평가하는지도 설명했습니다. 저자는 단거리 경로와 장거리 경로를 각 10개씩 뽑았고 이를 Town05 Short, Town05 Long이라 이름 지었습니다. 특징은 다음과 같습니다.</p>,\n",
              " <p>그리고 주행 중에 자동차나 사람이 등장할 수 있다는 공통점이 있습니다. </p>,\n",
              " <p>마지막으로 날씨입니다. 맑은 날 주행하는거랑 비오는 날에 주행하는건 난이도가 어느정도 차이가 나는데요, 저자는 <strong>동적인 객체와 신호등에 대한 주행 성능 평가에 집중할 것이기 때문에</strong> 날씨는 '항상 맑음'으로 고정한다고 말했습니다. </p>,\n",
              " <p>개인적으로 아쉬운 부분이었습니다. 날씨도 변수를 줘서 실험을 했으면 더 좋지 않았을까 생각합니다. </p>,\n",
              " <p>구글에 검색해보니 '측정 수단'이라는 뜻으로 해석됩니다. 즉, 평가지표입니다. </p>,\n",
              " <p>저자는 평가 지표로 RC, DS, Infraction Count를 선택했습니다. 하나씩 설명해 드리도록 하겠습니다. </p>,\n",
              " <p>Transfuser가 포함된 자율주행 모델과 성능을 비교할 모델을 적어놓았습니다. 5개의 모델과 비교합니다. </p>,\n",
              " <p>모델 종류는 다음과 같습니다. </p>,\n",
              " <p>실험 결과는 다음과 같습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F38b6e380-d752-4841-bac0-409e94f3ee8d%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%209.45.13.png\"/><br/>\n",
              " 왼쪽 사진은 Short, Long 경로에서 모델별 RC, DS를 나타낸거고 오른쪽 사진은 사고율을 나타낸 겁니다. </p>,\n",
              " <p>우선 왼쪽 표에 대해서 설명을 해드리도록 하겠습니다. </p>,\n",
              " <p>여기서 눈여겨볼 부분은 한가지 입력값을 받는 CILRS, LBC, AIM보다 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능이 더 좋다는 겁니다. 두가지 입력값을 쓰기만 해도 한가지 입력값을 쓰는 것보다 성능이 좋다는 사실을 알 수 있습니다. </p>,\n",
              " <p>그리고 또다시 눈여겨볼 부분은 Transfuser가 Late Fusion, Geometric Fusion보다 RC는 낮은데 DS가 높다는 것입니다. 즉, Transfuser는 주행 거리는 짧지만 안전운전을 더 잘한다는 뜻이죠. </p>,\n",
              " <p>저자는 이를 보고 'Late Fusion, Geometric Fusion는 안전하게 운전하는 것보다 목표 지점에 가는데 중점을 뒀기 때문에 이런 결과가 나왔다'고 말했습니다. </p>,\n",
              " <p>그리고 Expert의 점수도 나와있는데요, Expert도 장거리 운전에서는 그리 좋지 못한 성적을 얻었습니다. 신기합니다. </p>,\n",
              " <p>모델별 평균 사고율이 나옵니다. 초록색 막대가 Transfuser인데요, 모든 사고 항목에서 가장 낮습니다. 그런데  빨간불 신호 위반에서 다른 모델보다 낮긴 하지만 그래도 다른 사고 항목에 비하면 굉장히 높은 수치를 보입니다. 왜 그런걸까요? </p>,\n",
              " <p>여기선 모델의 한계점에 대해 저자가 얘기하는 부분입니다. 저자는 모델의 한계점으로 <strong>빨간불 신호 위반의 확률이 높은 것</strong>을 꼽았습니다. </p>,\n",
              " <p>높은 신호위반 확률을 보이는 이유는 성능 평가를 위해 주행하던 경로에서 신호등이 카메라 구석에 찍혔는데 이 때문에 신호등의 빨간 불빛을 감지하기가 힘들어 빨간불에서 정차하지 않고 주행하는 일이 많았다고 합니다. </p>,\n",
              " <p>그리고 이러한 문제를 해결할 additional supervision을 기대해본다고 말했습니다. </p>,\n",
              " <p>여기서는 카메라 이미지와 LiDAR point cloud간 상호보완성을 보여줍니다. </p>,\n",
              " <p>어떻게 보여주냐면 교차로에서 신호대기중인 차량에서 얻은 이미지, Point cloud를 Transfuser로 특성을 추출하는 과정에서 self-attention을 통해 나온 16X8 사이즈의 벡터를 통해 설명합니다.</p>,\n",
              " <p>여기서 반은 이미지쪽 벡터고 나머지 반은 LiDAR쪽 벡터입니다. 여기서 각각 자동차와 신호등에 대한 정보가 담긴 부분만 추출해 서로 얼마나 attention을 했는지 확인해봅니다. attention이 반영된 정도는 각 요소별 곱해진 score를 보고 알 수 있죠. </p>,\n",
              " <p>그렇게 attention된 정도를 확인한 결과, 다음의 사실을 알 수 있었습니다. </p>,\n",
              " <p>여기서 토큰은 transformer에 입력값으로 들어가는 데이터 단위를 말합니다. 출력값 역시 토큰의 집합이죠. 토큰을 데이터로 바꾼 뒤 읽으셔도 의미의 차이는 없을듯 합니다. </p>,\n",
              " <p>아무튼, 이렇게 서로 상호보완하는 부분이 많습니다. 특성을 추출할 때 상대 데이터를 많이 고려한다는 뜻이죠. </p>,\n",
              " <p>여기서는 Transfuser의 Transformer에 대해 값을 수정해가며 성능의 변화를 관측한걸 얘기합니다. 저자는 Town05 Short에서 성능 평가를 했는데요, 성능표는 다음과 같았습니다.<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2F3060d95b-e30f-41f8-a83b-b79cf1877329%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-05%20%EC%98%A4%ED%9B%84%2011.02.23.png\"/><br/>\n",
              " 하나씩 설명해드리도록 하겠습니다. </p>,\n",
              " <p>이렇게 각 요소를 제거한 뒤 성능을 비교했습니다. Scale을 제외한 나머지 부분에서 하나의 공통점이 있는데요, 바로 RC는 증가하지만 DS가 떨어졌다는 점입니다. </p>,\n",
              " <p>저자는 이를 보고 'Attention횟수가 많아질 수록 더 조심히 운전하게 된다'고 말했습니다. </p>,\n",
              " <p>논문의 결말입니다. 저자는 앞서 말한 것을 conclusion에서 총체적으로 정리했습니다. 그리고 마지막에 자신들이 만든 모델에 다른 센서의 입력값을 추가해서 쓰거나 다른 AI task에 사용할 수 있다고 말하며 논문을 끝냈습니다.<br/>\n",
              " <br/></p>,\n",
              " <p>이렇게 길고 긴 논문 리뷰가 끝났습니다. 최선을 다해 리뷰해봤는데 미숙한 부분이 많았습니다. 이런식으로 데이터를 받아서 처리하는 모델도 처음 접했고 자율주행 task를 수행하는 모델도 처음이라 읽는데 많은 시간이 걸렸습니다. 그래도 리뷰하고 나니 뿌듯하네요. </p>,\n",
              " <p>3주 뒤에 다른 논문을 세미나에서 발표하는데 그 논문도 velog에 올릴 계획입니다. 개강이 얼마 남지 않은 시기라 쓰기 힘들겠지만 하...할 수 있겠죠? </p>,\n",
              " <p>마지막으로 제가 이 논문을 읽고 느낀점을 쓰고자 합니다. 제가 느낀 점은 다음과 같습니다.</p>,\n",
              " <p>두 종류의 입력값을 특성 추출 과정에서 반영함으로써 안전한 운전을 구현했다는 사실이 흥미로웠다.</p>,\n",
              " <p>허나 Transformer가 전체 입력값을 모두 고려하며 계산하기 때문에 연산량이 좀 많을텐데 실시간으로 판단이 필요한 운전에서 이런 점이 부담이 되지 않을까 싶다.</p>,\n",
              " <p>추후 주행 속도도 개선하며 안전운전을 추구하는 모델이 나왔으면 좋겠다.</p>,\n",
              " <p>그리고 제가 이걸 세미나에서 발표했을 때 교수님께서 \"꼭 두가지 데이터를 사용했어야 했을까, LiDAR에서 얻은 정보를 사용할 때 2D 데이터로 변환하는 과정에서 많은 데이터 손실이 있을텐데 그걸 감수하면서까지 사용할 이유가 있을지 모르겠다, 차라리 시야각이 넓은 이미지를 사용하면 데이터 손실도 없이 사용할 수 있지 않을까\" 라고 저에게 말씀하셨습니다. </p>,\n",
              " <p>실은 저는 입력값에 대한 어떠한 의문도 가지지 않았는데 교수님의 말씀을 듣고 의문이 들었습니다. 실제로 표를 봤을 때<br/>\n",
              " <img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fd919d9ce-64eb-4d23-9e83-c67e9f7b4ca7%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.06.23.png\"/><br/>\n",
              " 여기 보시면 한가지 입력값만 받는 AIM과 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능차이가 크게 없다는 사실을 확인할 수 있습니다. 물론 장거리 주행에서는 DS에서 차이가 나긴 하지만 다들 점수가 낮기 때문에 큰 상관은 없다고 생각합니다. </p>,\n",
              " <p>아무튼, 많은 공부가 되었고 재밌게 읽은 논문이었습니다. 다음 논문 리뷰에서 뵙겠습니다!</p>,\n",
              " <p>꼼꼼한 논문 리뷰 잘 보았습니다. 저도 논문 리서치 중인데, 논문 리뷰는 이렇게 하는 것이군요.ㅎㅎ 본받아서 저도 열심히 조사해야겠어요. 감사합니다:)</p>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('p').text   # 태그 안 텍스트만 반환"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "oBJhXwJUJ2za",
        "outputId": "f9fffa41-6762-487f-f2ef-0a06ef2cdce1"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' 안녕하세요. 밍기뉴와제제입니다. '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "soup.find('p').text.strip()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "TYpaJz5hKIgZ",
        "outputId": "8d31353d-4c25-47da-99c0-50a839580269"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'안녕하세요. 밍기뉴와제제입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_list = soup.find_all('p')\n",
        "\n",
        "for t in text_list:\n",
        "  print(t.text.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w8XC_mQYKR8P",
        "outputId": "98f84c67-3b6b-41a2-b446-23b1cf08f3fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요. 밍기뉴와제제입니다.\n",
            "정말 오랜만에 돌아왔습니다. 논문은 여러개 봤는데 리뷰할 정도로 깊게 탐구한 논문이 별로 없어 한동안 글을 안쓰다 이번에 논문 세미나를 하다보니 꼼꼼히 살펴본 논문이 생겼습니다.\n",
            "이번에 리뷰를 하려는 논문은 'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving '라는 논문입니다. 자율주행에 관한 논문이죠.\n",
            "이름을 보면 대충 짐작 가시겠지만 이 논문은 multimodal, 두가지 데이터를 처리하는 모델을 설계했습니다. 그리고 Transformer도 이용했다는 사실을 짐작할 수 있습니다.\n",
            "그러면 지금부터 논문 흐름에 맞춰 리뷰를 해보도록 하겠습니다.\n",
            "이 부분에서는 이전까지 자율주행 모델이 사용한 방식들을 소개 후 저자가 소개하는 모델 'transfuser'에 대해 설명합니다.\n",
            "이전에 Image-only model과 LiDAR-only model이 등장했고 이는 자율주행의 성능을 올리는데 많이 기여했습니다. 허나 이렇게 한가지 데이터만 입력값으로 사용한 모델은 near-ideal한 움직임을 보이는 객체들만 있는 환경에서 제한된 움직임만 필요한 경로에 주행해야만 높은 성능을 보여준다는 것이었죠. 굉장히 사용하기 까다로웠습니다.\n",
            "논문에서는 이를 두고 다음과 같이 말했습니다.\n",
            "adversarial scenarios에서 만족스럽지 못한 성능을 보여준다\n",
            "여기서 adversarial scenarios는 운전에 변수가 많이 생기는 환경을 말합니다. 예를 들면 비보호 회전을 해야하는 교차로, 랜덤하게 등장하는 자동차와 보행자 등이 운전에 변수를 주는 요소라 볼 수 있죠.\n",
            "그러면 이런 부분이 왜 낮은 성능이 나오게끔 하는걸까요? 다음의 그림을 보며 설명해 드리도록 하겠습니다.\n",
            "\n",
            "위 사진은 논문에서 말한 adversarial scenarios 중 하나입니다.\n",
            "여기서 초록색 박스 안에 있는 자동차(Ego-Vehicle)와 왼쪽 도로에서 건너오는 빨간색 박스 속 자동차들(Traffic), 그리고 노란색 박스 안에 있는 신호등(Traffic Lights)이 있습니다. 여기서 Ego-Vehicle이 자율주행을 하는 자동차죠.\n",
            "이 상황에서 Ego-Vehicle이 카메라와 LiDAR에서 얻은 데이터를 살펴봅시다. LiDAR의 정의는 다음과 같습니다.\n",
            "LiDAR : Light Detection And Ranging, 레이저를 발사 후 돌아오는 시간을 계산해 주변 물체를 검출하는 센서\n",
            "LiDAR는 3D 데이터인 Point Cloud를 생산하며 여기엔 카메라가 관측할 수 없는 넓은 범위에 존재하는 객체에 대한 정보가 포함되어 있습니다. 그림을 보면 카메라 뷰에서 보이지 않는 자동차(Traffic)을 검출했다는 사실을 확인할 수 있습니다.\n",
            "허나 LiDAR는 카메라가 검출한 신호등을 찾지 못했습니다. 즉, 각 센서별로 얻을 수 있는 정보가 다릅니다.\n",
            "이러한 상황에서 Image-only 혹은 LiDAR-only model을 사용해 자율주행을 한다고 가정해봅시다.\n",
            "그러면 아래와 같은 문제가 생길 확률이 높습니다.\n",
            "이건 꽤 큰 단점이죠. 그래서 사람들은 이를 해결하기 위한 방법을 찾고자 했습니다.\n",
            "사람들은 자율주행 자동차에 있는 센서에 주목했습니다.\n",
            "\n",
            "(출처 : https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f)\n",
            "위 사진은 자율주행 자동차에 들어있는 센서를 나타낸 그림입니다. 보시면 알겠지만 자율주행 자동차 안에는 수많은 센서들이 들어있습니다.\n",
            "이렇게 많은 센서를 보고 사람들이 생각한게 있습니다.\n",
            "\"자동차에 있는 두개의 센서를 함께 사용해보는건 어떨까?\"\n",
            "그래서 두가지 데이터를 함께 써보자는 아이디어를 떠올렸죠. 그리고 다음과 같은 질문을 남겼습니다.\n",
            "이 질문에 답하기 위해 수많은 논문들이 나왔습니다. 그 중 한가지 논문에 나온 모델 구조에 대해 간단히 소개해드리겠습니다.\n",
            "(출처 : Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proc. IEEE Conf. on Computer Vision and Pat- tern Recognition (CVPR), 2017)\n",
            "위 그림에 나온 구조가 두가지 데이터를 처리하는 대부분의 모델이 사용하는 구조입니다. 각 데이터별로 CNN에 넣어 특성맵을 추출한 뒤 원소 단위로 평균값을 낸다든지 더한다든지 하는 방식으로 Fusion해 하나의 출력값으로 만드는 방식이죠.\n",
            "두가지 데이터를 이용하는 방식은 한가지 데이터를 사용하는 방식보다 성능이 좋았습니다. 허나 여전히 단점이 있었습니다.\n",
            "바로 도심 속 운전같이 복잡한 상황에서 운전하기 힘들다는 점이었습니다.\n",
            "교차로에서 운전할 때를 고려해봅시다. 위에 제가 올린 사진과 같은 상황이죠. 여기서 자율주행을 하는 자동차(Ego-Vehicle)는 왼쪽에서 오는 자동차(Traffic)과 신호등의 신호(Traffic Lights) 사이의 연관성을 고려하며 운전을 해야합니다. 허나 각 데이터별로 특성맵을 추출하면 특성을 추출하는 과정에서 모든 정보를 고려할 수 없게 됩니다.\n",
            "즉, 모든 정보를 고려하지 않고 얻어낸 정보를 가지고 운전하기 때문에 사고가 날 확률이 높은 것이죠.\n",
            "이는 데이터의 문제가 아니라 데이터를 처리하는 모델 구조의 문제였습니다.\n",
            "그래서 저자는 Attention mechanism만 사용해 데이터를 처리하는 Transformer를 특성 추출 과정에서 사용하기로 했습니다.\n",
            "Transformer의 self-attention는 입력 값의 각 원소가 전체적인 입력값의 어느 부분을 더 주목해야 하는지 반영하게 해주니 이를 이용해 이미지와 LiDAR 데이터를 전체적으로 고려하며 특성맵을 추출하는 방식을 생각한 것입니다.\n",
            "\"두가지 데이터를 어떤 방식으로 합쳐서 사용하지?\" 에 대한 답변은 Transforemr였습니다.\n",
            "그리고 \"두가지 데이터로 어떤걸 선택하지?\"에 대한 답변을 해야합니다.\n",
            "저자는 이에 \"Single-view image and LiDAR를 입력 데이터로 사용한다\"고 말했습니다.\n",
            "\n",
            "이 둘을 사용하겠다는 것이죠.\n",
            "왜 Single-view image and LiDAR를 선택한 걸까요? 저자는 이 둘이 서로가 서로에게 부족한 점을 채워주는 상호보완성이 있기 때문에 선택했다고 말했습니다.\n",
            "즉, 이 둘을 입력데이터로 사용해 얻는 정보의 양이 제일 많다고 판단한 것이죠.\n",
            "이제 저자가 생각해낸 모델을 정리해봅시다.\n",
            "입력 데이터로 Single-view image and LiDAR를 받아 특성을 추출하는 과정에서 Transformer를 사용해 전체적인 정보를 고려하는 모델\n",
            "한문장으로 간단히 정리됩니다. 저자는 이렇게 설계된 모델을 Transfuser라고 정의했습니다.\n",
            "여기까지 모델의 Introduction 부분이었습니다. 깔끔히 쓰고 싶었는데 쉽지않네요. 허허...\n",
            "그럼 이제 Transfuser가 포함된 자율주행 모델이 만들어지는 과정을 소개한 Method 항목을 소개해 드리도록 하겠습니다.\n",
            "원래 Releated work를 슥 살펴보고 Method로 넘어가야 하는데 그러면 분량이 너무 많아져서 바로 Method로 건너왔습니다. 저도 자율주행 모델에 대해 잘 감이 안잡힌 상태에서 이 논문을 읽어서 Related work 부분이 논문 이해에 꽤나 도움이 되었습니다. 관심 있으신 분들은 따로 찾아서 읽어보시는걸 추천드립니다.\n",
            "아무튼, 이제 Method에 대해 설명해 드리도록 하겠습니다.\n",
            "Method에는 Transformer를 이용해 자율주행 모델을 만드는 일련의 과정이 적혀있습니다.\n",
            "모델을 만드는 과정은 다음과 같이 3단계로 나눌 수 있습니다.\n",
            "그러면 'Task 설정'부터 설명해 드리도록 하겠습니다.\n",
            "모델이 해결할 Task를 설정하고 이를 위한 학습법, 그리고 필요한 데이터셋을 설명하는 부분입니다.\n",
            "저자는 point-to-point navigation를 모델이 수행할 Task로 설정했습니다.\n",
            "저자는 point to point navigation이 목표지점까지 waypoint를 따라 사고 없이 완주하는 것이라 말했습니다. 여기서 사고는 다른 객체(자동차, 사람 등)과 충돌하거나 교통법규를 어기는 것을 말하죠.\n",
            "그리고 이를 학습하는 방법으로 imitation learning을 선택했습니다. imitation learning이란 강화학습의 일종인데요, 의미 그대로 해당 task에서 전문가(Expert)가 하는걸 따라하는 학습법입니다.\n",
            "강화 학습은 학습 주체인 agent와 agent가 행동하는데 규범이 되는 policy, 행동의 결과인 action, action으로 인한 상태 state, 그리고 state에 대한 보상 reward가 있습니다.여기서 보상 reward를 가장 많이 받는 방향으로 학습시키는 것이 목표죠.\n",
            "reward를 많이 받도록 만드는 방식은 여러가지가 있습니다. 그중 하나가 행동 규범힌 policy를 학습가능한 상태(parameterize)로 만드는 것이죠.\n",
            "imitation learning도 그 방식을 사용하고 있으며 논문에서는 다음과 같이 설명합니다.\n",
            "Policy를 Expert의 policy를 따라하게끔 학습하는 것\n",
            "그런데 여기서 궁금증이 생겼습니다. 왜 imiation learning을 선택한거지? 그래서 찾아봤습니다.\n",
            "찾아보니까 이렇게 policy를 학습 대상으로 삼아 학습시키는 방식은 고차원 데이터를 처리하고 연속된 action을 해야하는 모델의 학습에 적합하다고 합니다.\n",
            "이미지라는 고차원 데이터를 처리해 연속된 action이 필요한 운전을 하는 자율주행 모델에 적합한방식이라 선택한게 아닌가 싶습니다.\n",
            "그러면 이제 저자가 imitation learning을 사용한 학습과정을 설명해 드리도록 하겠습니다.\n",
            "우선 데이터셋을 수집해야하죠? 학습을 위한 학습 데이터셋과 평가를 위한 테스트 데이터셋이 필요합니다.\n",
            "데이터셋은 자율주행 오픈소스 시뮬레이터 CARLA(https://carla.org)에 있는 가상 환경에서 수집\n",
            "합니다. 별다른 이유는 적지 않았지만 아무래도 사고가 날 수 있는 상황에 대한 데이터도 모으기 때문에 그런게 아닌가 싶네요.\n",
            "여튼, CARLA에 있는 가상환경에서 Expert가 주행하며 데이터를 모읍니다. imitation learning에서 말씀드린 Expert 맞습니다.\n",
            "Expert는 가상환경을 주행하며 입력 데이터와 출력 데이터를 수집합니다. 그렇게 해서\n",
            "\n",
            "위와 같은 데이터셋 D를 만들어줍니다.\n",
            "여기서 X는 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 한 시점(single time step)에 이미지 한장, point cloud 하나가 있는 것이죠.\n",
            "그리고 W는 T개의 waypoint가 모인 w로 이루어져 있습니다. 즉, 이미지와 point cloud를 하나씩 넣으면 출력값으로 T개의 Waypoint가 나오는 모델을 만들겠다는 뜻이죠.\n",
            "이렇게 데이터셋을 모았으니 학습을 시켜봅시다. 학습 방식은 다음과 같이 정의할 수 있습니다.\n",
            "\n",
            "여기서 L은 Loss함수입니다. 그러니까 Expert가 주행한 경로와 우리가 만든 agent의 policy에 따른 action, 다시 말해 우리가 만든 모델이 예측한 주행 경로 사이의 loss가 최소가 되게끔 policy를 학습시키겠다는 뜻이죠.\n",
            "저자는 이러한 학습 방식을 지도학습의 방식이라고 말했습니다. Expert의 데이터를 label data, 내가 만든 모델의 데이터가 prediction data라고 보면 저자의 말이 이해가 되시지 않을까 싶습니다.\n",
            "그래서 강화학습은 어떻게 학습 시키는걸까 찾아봤습니다. 강화학습은 데이터셋을 사용하지 않고 학습하기 때문에 매 순간 자기 자신이 만든 state와 reward를 보고 다음 action에 반영하며 점점 높은 reward만 받는 모델로 학습되는 방식을 사용한다는 사실을 알아냈습니다. 지도학습으로만 모델을 학습시켜본 저에게 있어서 강화학습은 상당히 신기한 방식입니다.\n",
            "저자는 학습 이후 어떻게 자율주행에 사용할지도 설명해 주었습니다.\n",
            "저자는 모델이 예측한 경로를 inverse dynamics model에 넣어 얻은 action으로 주행을 한다고 말했고 이 때 inverse dynamics model을 PID controller로 구현했다고 설명했습니다.\n",
            "PID controller는 간단한게 말해 주어진 출력값을 위해 필요한 제어값(가속, 감속, 회전 등)을 구하는 요소라고 보시면 됩니다. 자세한 설명은 여기서 확인하실 수 있습니다.\n",
            "저자는 이러한 과정을 다음과 같은 식으로 나타냈습니다.\n",
            "\n",
            "action = PID(예측 경로)인 것이죠. 여기서 action은 agent가 행한 action과 동일한 개념입니다.\n",
            "마지막에 등장하는 문단인데 처음에는 이게 왜 있는건가 싶었습니다.\n",
            "읽어보니 저자들은 CARLA의 표준 프로토콜을 따르고 목표 지점이 GPS 좌표로 제공되며 목표 지점과 자동차가 안내한 지점이 몇백미터 떨어질 수 있다고 나와있습니다.\n",
            "다른 부분은 그러려니 하고 읽었는데 마지막 부분 '목표 지점과 안내 지점이 몇백미터 떨어질 수 있다'는 말이 거슬렸습니다. 도대체 뭔 뜻이지?\n",
            "제가 논문 세미나를 할 때 이 논문을 가지고 했는데요, 이에 관해 세미나 계신 분들께 여쭤보고 답을 들었는데도 이해가 제대로 안되서 구글에 검색까지 해봤습니다.\n",
            "구글에 검색을 해보니 다음과 같은 글을 발견했습니다.\n",
            "The global planner plans a global path around obstacles\n",
            "대충 번역하면 장애물을 돌아가는 global path를 생성하는게 global planner라고 하네요.\n",
            "아마 목표 지점에 가기 힘들면 그 근처로 안내할 수 있음을 말하고 싶어서 이 부분을 추가한게 아닌가 싶습니다.\n",
            "여기까지 Problem Setting이었습니다.\n",
            "이제 데이터셋을 어떻게 만들었는지? 정확히는 모델의 학습에 사용하기 위해 어떤 작업을 했는지 설명해 드리도록 하겠습니다.\n",
            "우선 입력 데이터부터 설명해 드리고자 합니다.\n",
            "입력 데이터는 앞서 말씀드렸듯 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 카메라 이미지는 2D 데이터고 Point cloud는 3D 데이터라 각자 처리방식이 다릅니다.\n",
            "카메라 이미지\n",
            "카메라에서 촬영된 이미지는 400X300 사이즈인데요, 여기서 가운데 256X256 영역만 추출해서 사용합니다. 왜냐하면 렌즈 구조상 외곽 이미지는 왜곡 되어있기 때문입니다. 이렇게 256X256X3 사이즈의 데이터를 얻습니다.\n",
            "LiDAR Point Cloud\n",
            "저자는 LiDAR에서 얻은 Point Cloud 중 자동차의 전면 32m, 좌우 측면 각 16m씩 해서 총 32m X 32m 영역만 사용합니다. 그리고 이를 2D 데이터로 변환해주는데요, 한 셀당 0.125m X 0.125m로 해서 256 X 256 픽셀 데이터로 변환해줍니다.\n",
            "그리고 Point Cloud는 3D 데이터라 높이에 관한 데이터도 있는데요, 저자는 이를 2개의 채널에 담았습니다. 하나는 지면 위(+) 높이 데이터, 다른 하나는 지면 밑(-) 높이 데이터를 담았죠.\n",
            "이렇게 256X256X2 사이즈의 데이터를 얻습니다.\n",
            "출력값 양식을 정의하는 부분입니다.\n",
            "출력값, 즉 waypoint는 BEV space에서 (x,y)의 양식을 지닙니다.\n",
            "이런 방식으로 나온다는 뜻이죠. 중심에 자동차가 있고 앞에 빨간 점으로 자동차가 이동할 waypoint가 나와 있습니다. 이 때 waypoint의 집합 trajectory는 다음과 같이 정의됩니다.\n",
            "앞서 데이터셋을 구성할 때 T개의 waypoint 예측값이 모인 데이터셋을 만든다고 말씀드렸는데요, 저자는 T를 4로 정의했습니다. 왜 T를 4로 정의했냐면 예측 궤적을 가기 위한 제어값을 얻는 PID controller가 요구하는 waypoint의 default number가 4라서 T를 4로 설정했다고 말했습니다.\n",
            "여기까지 Input and Output Parameterization였습니다.\n",
            "다음으로 모델의 구조에 대해 설명해 드리고자 합니다.\n",
            "모델의 구조는 크게 두 가지로 나눌 수 있습니다. 하나는 Multi-Modal Fusion Transformer고 다른 하나는 Waypoint Prediction Network입니다.\n",
            "Multi-Modal Fusion Transformer는 저자가 새로운 제안한 Transfuser를 말하는 것이구요, Waypoint Prediction Network는 Transfuser에서 얻은 값을 가지고 경로를 예측하는 모델입니다.\n",
            "우선 Transfuser부터 먼저 설명해 드리도록 하겠습니다.\n",
            "Transfuser는 다음과 같은 구조를 가지고 있습니다.\n",
            "\n",
            "제가 Trnafuser는 특성을 추출하는 과정에서 Transformer를 이용해 전체 데이터를 고려하는 모델이라고 말씀드렸는데요, 이 그림을 보시면 \"아...이런 뜻이구나\" 이해하시지 않을까 싶습니다.\n",
            "여기서 눈여겨볼 항목은 당연히 저자가 강조한 Transformer를 이용해 전체 데이터 정보를 각 특성맵에 반영해주는 부분입니다.\n",
            " \n",
            "이 부분을 말하는 것이죠. 아래 그림은 윗 그림에서 Transformer 부분을 강조한 그림입니다.\n",
            "여기서 진행되는 연산의 순서를 말씀드리면 다음과 같습니다.\n",
            "코드로 나타내면 상당히 간단해집니다.\n",
            "\n",
            "아무튼 간단해집니다.\n",
            "여튼, 이런 과정을 총 4번 반복합니다. 더 해도 안된다는 법은 없는데 저자는 4번 반복하라고 말했습니다.\n",
            "4번 반복한 뒤 마지막에 Average Pooling + Flatten연산을 해서 1 X 1 X 512 벡터를 2개 생성합니다. 이미지에서 얻고 LiDAR에서 얻으니까 총 2개를 얻는 것이죠.\n",
            "이 2개의 벡터를 element-wise summation해서 하나의 1 X 1 X 512 벡터로 만들어줍니다.\n",
            "이렇게 우리는 최종 출력값 1 X 1 X 512 벡터를 얻었습니다. 이제 Waypoint Prediction Network를 확인해보도록 합시다.\n",
            "앞서 우리는 Transfuser에서 1 X 1 X 512 사이즈의 벡터를 얻었습니다.\n",
            "이 벡터는 Waypoint Prediction Network에 쓰입니다.\n",
            "Waypoint Predictoin Network는 다음과 같은 구조를 가지고 있습니다.\n",
            "\n",
            "보시면 MLP와 GRU로 이루어졌다는 사실을 확인하실 수 있습니다.\n",
            "MLP\n",
            "MLP는 3개의 Linear Layer로 이루어져 있습니다. MLP는 입력값으로 들어오는 1 X 1 X 512 사이즈의 벡터를 1 X 1 X 64 벡터로 압축해줍니다. 계산의 효율성을 위해 줄여주는 겁니다.\n",
            "코드는 다음과 같습니다.\n",
            "GRU\n",
            "GRU는 RNN에서 많이 쓰였던 LSTM을 개선한 알고리즘 입니다. 시계열 데이터를 처리하는데 적합한 알고리즘이죠. 이걸 레이어 형식으로 추가했습니다.\n",
            "GRU는 현 시점의 입력 데이터와 hidden state를 받아 연산을 처리합니다. waypoint prediction network에서는 자동차의 좌표와 목표 지점의 좌표를 더한 값을 입력 값으로 하였습니다. 이 때 좌표의 단위는 gps입니다.\n",
            "여기서 흥미로운 점이 있습니다. 바로 첫 시점의 입력 데이터 중 자동차의 좌표가 (0,0)이라는 점입니다. 이는 자동차가 좌표계의 원점에 있다고 가정했기 때문입니다.\n",
            "그러니까 입력 데이터를 넣는 시점에서 자동차의 위치가 x = (0,0)에 있다고 보는 것이고 (0,0)를 기준으로 향후 4 time의 waypoint를 예측하는 것이라 보시면 되겠습니다.\n",
            "다시 본론으로 돌아옵시다. 입력 데이터를 알아봤으니 이제 hidden state로 넘어가야죠. hidden state는 앞서 얻은 1 X 1 X 64 벡터로 초기화해줍니다. 우리가 입력 데이터로 얻은 특성을 hidden state를 초기화하는데 사용하는 겁니다.\n",
            "이렇게 입력값을 넣어주면 출력값이 나올겁니다. 이 출력값을 Linear layer에 넣으면 현 시점의 자동차에서 움직여야할 좌표 dx가 생성됩니다.\n",
            "이 dx에 기존 자동차의 좌표 x에 더하면 이제 다음 시점에 이동할 waypoint가 되는 겁니다.\n",
            "이 waypoints는 다음 시점에서 현재 좌표가 되겠죠? next_x = x + dx인 겁니다.\n",
            "여튼 이 과정을 4번 반복해 waypoint 4개를 얻습니다.\n",
            "모델의 구조에는 없지만 자율주행을 수행하기 위해 꼭 있어야할 PID controller입니다.\n",
            "앞서 예측한 경로를 PID controller에 넣어 주행에 필요한 제어값을 얻는다고 말씀드렸습니다.\n",
            "실은 그 이상으로 설명드릴게 없습니다. 그러니 여기서는 구현된 코드를 보여드리고 넘어가도록 하겠습니다.\n",
            "\n",
            "코드의 return 부분을 보시면 운전에 필요한 데이터들이 나와있습니다. steer는 차를 얼마나 회전할지 나타낸거고 throttle는 엔진에 들어갈 공기량을 제어하니까 가속을 얼마나 할지 나타낸거고 brake는 감속을 얼마나 할지 나타내는 것이죠.\n",
            "그런데 낯선 데이터가 하나 있습니다. 바로 metadata입니다. 슥 살펴보니 steer, throttle, brake만으로 설명이 안되는 정보를 보충 설명해주는 데이터인듯 합니다. 아마 저자가 실험했을 때 제어값의 정보 부족으로 좀 애먹었던게 아닌가 싶네요. 제 추측입니다.\n",
            "여기까지 모델의 구조를 살펴봤습니다.\n",
            "이제 실험 부분을 설명해 드리고자 합니다.\n",
            "여기서는 실험 세팅(experimental setup), 성능 비교(Results), 입력 데이터간 상호보완성 비교(Attention Map Visualizations), 구성 요소를 하나씩 빼면서 성능 확인(Ablation Study) 순으로 내용이 전개됩니다.\n",
            "여기서는 성능 측정을 위해 모델이 해야할 task와 이를 위해 필요한 데이터셋, 평가 지표와 성능을 비교할 모델을 소개하고 있습니다.\n",
            "모델이 수행할 task는 다양한 주행 환경에서 제한 시간 안에 운전 규정을 시키며 주행하는 것입니다.\n",
            "여기서 주행 경로는 gps좌표 형식의 waypoint의 집합으로 제공되며 주행 도중에 일정 확률로 자동차나 보행자가 등장할 수 있고 차선 변경, 회전 등 주행 중에 충분히 일어날 수 있는 상황도 경로에 포함되어 있습니다.\n",
            "앞서 논문에서 말한 '복잡한 운전 상황'속 주행 성능을 평가하는거라 생각하시면 됩니다.\n",
            "데이터셋을 모으는 방법이 적혀있습니다.\n",
            "앞서 말씀드렸듯 Expert가 CARLA에 있는 가상환경에서 주행하며 데이터를 모은다고 말씀드렸습니다. 여기서 더 자세히 써보도록 하겠습니다.\n",
            "CARLA에는 주행을 할 수 있는 8개의 Town이 있습니다. 8개의 가상환경이 있는 것이죠. 각 town의 특성은 다음과 같습니다.\n",
            "\n",
            "각자 특성을 가지고 있죠. Expert는 여기서 Town 01, 02, 03, 04, 06, 07, 10에 사전 정의된 경로들을 달리며 학습용 데이터셋을 수집합니다.\n",
            "그리고 학습용 데이터셋으로 모델을 훈련시키고 난 뒤 Town05에서 주행 성능을 평가합니다.\n",
            "Town05는 1차선부터 n차선, 그리고 일반도로부터 고속도로까지 다양한 도로가 있기 때문에 주행 성능을 평가하는 맵으로 선정했다고 말했습니다.\n",
            "Town05에 깔려있는 도로를 나타낸 사진입니다. 다양한 도로로 구성되어 있음을 확인할 수 있습니다.\n",
            "저자는 어떠한 주행 경로에서 성능을 평가하는지도 설명했습니다. 저자는 단거리 경로와 장거리 경로를 각 10개씩 뽑았고 이를 Town05 Short, Town05 Long이라 이름 지었습니다. 특징은 다음과 같습니다.\n",
            "그리고 주행 중에 자동차나 사람이 등장할 수 있다는 공통점이 있습니다.\n",
            "마지막으로 날씨입니다. 맑은 날 주행하는거랑 비오는 날에 주행하는건 난이도가 어느정도 차이가 나는데요, 저자는 동적인 객체와 신호등에 대한 주행 성능 평가에 집중할 것이기 때문에 날씨는 '항상 맑음'으로 고정한다고 말했습니다.\n",
            "개인적으로 아쉬운 부분이었습니다. 날씨도 변수를 줘서 실험을 했으면 더 좋지 않았을까 생각합니다.\n",
            "구글에 검색해보니 '측정 수단'이라는 뜻으로 해석됩니다. 즉, 평가지표입니다.\n",
            "저자는 평가 지표로 RC, DS, Infraction Count를 선택했습니다. 하나씩 설명해 드리도록 하겠습니다.\n",
            "Transfuser가 포함된 자율주행 모델과 성능을 비교할 모델을 적어놓았습니다. 5개의 모델과 비교합니다.\n",
            "모델 종류는 다음과 같습니다.\n",
            "실험 결과는 다음과 같습니다.\n",
            "\n",
            "왼쪽 사진은 Short, Long 경로에서 모델별 RC, DS를 나타낸거고 오른쪽 사진은 사고율을 나타낸 겁니다.\n",
            "우선 왼쪽 표에 대해서 설명을 해드리도록 하겠습니다.\n",
            "여기서 눈여겨볼 부분은 한가지 입력값을 받는 CILRS, LBC, AIM보다 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능이 더 좋다는 겁니다. 두가지 입력값을 쓰기만 해도 한가지 입력값을 쓰는 것보다 성능이 좋다는 사실을 알 수 있습니다.\n",
            "그리고 또다시 눈여겨볼 부분은 Transfuser가 Late Fusion, Geometric Fusion보다 RC는 낮은데 DS가 높다는 것입니다. 즉, Transfuser는 주행 거리는 짧지만 안전운전을 더 잘한다는 뜻이죠.\n",
            "저자는 이를 보고 'Late Fusion, Geometric Fusion는 안전하게 운전하는 것보다 목표 지점에 가는데 중점을 뒀기 때문에 이런 결과가 나왔다'고 말했습니다.\n",
            "그리고 Expert의 점수도 나와있는데요, Expert도 장거리 운전에서는 그리 좋지 못한 성적을 얻었습니다. 신기합니다.\n",
            "모델별 평균 사고율이 나옵니다. 초록색 막대가 Transfuser인데요, 모든 사고 항목에서 가장 낮습니다. 그런데  빨간불 신호 위반에서 다른 모델보다 낮긴 하지만 그래도 다른 사고 항목에 비하면 굉장히 높은 수치를 보입니다. 왜 그런걸까요?\n",
            "여기선 모델의 한계점에 대해 저자가 얘기하는 부분입니다. 저자는 모델의 한계점으로 빨간불 신호 위반의 확률이 높은 것을 꼽았습니다.\n",
            "높은 신호위반 확률을 보이는 이유는 성능 평가를 위해 주행하던 경로에서 신호등이 카메라 구석에 찍혔는데 이 때문에 신호등의 빨간 불빛을 감지하기가 힘들어 빨간불에서 정차하지 않고 주행하는 일이 많았다고 합니다.\n",
            "그리고 이러한 문제를 해결할 additional supervision을 기대해본다고 말했습니다.\n",
            "여기서는 카메라 이미지와 LiDAR point cloud간 상호보완성을 보여줍니다.\n",
            "어떻게 보여주냐면 교차로에서 신호대기중인 차량에서 얻은 이미지, Point cloud를 Transfuser로 특성을 추출하는 과정에서 self-attention을 통해 나온 16X8 사이즈의 벡터를 통해 설명합니다.\n",
            "여기서 반은 이미지쪽 벡터고 나머지 반은 LiDAR쪽 벡터입니다. 여기서 각각 자동차와 신호등에 대한 정보가 담긴 부분만 추출해 서로 얼마나 attention을 했는지 확인해봅니다. attention이 반영된 정도는 각 요소별 곱해진 score를 보고 알 수 있죠.\n",
            "그렇게 attention된 정도를 확인한 결과, 다음의 사실을 알 수 있었습니다.\n",
            "여기서 토큰은 transformer에 입력값으로 들어가는 데이터 단위를 말합니다. 출력값 역시 토큰의 집합이죠. 토큰을 데이터로 바꾼 뒤 읽으셔도 의미의 차이는 없을듯 합니다.\n",
            "아무튼, 이렇게 서로 상호보완하는 부분이 많습니다. 특성을 추출할 때 상대 데이터를 많이 고려한다는 뜻이죠.\n",
            "여기서는 Transfuser의 Transformer에 대해 값을 수정해가며 성능의 변화를 관측한걸 얘기합니다. 저자는 Town05 Short에서 성능 평가를 했는데요, 성능표는 다음과 같았습니다.\n",
            "\n",
            "하나씩 설명해드리도록 하겠습니다.\n",
            "이렇게 각 요소를 제거한 뒤 성능을 비교했습니다. Scale을 제외한 나머지 부분에서 하나의 공통점이 있는데요, 바로 RC는 증가하지만 DS가 떨어졌다는 점입니다.\n",
            "저자는 이를 보고 'Attention횟수가 많아질 수록 더 조심히 운전하게 된다'고 말했습니다.\n",
            "논문의 결말입니다. 저자는 앞서 말한 것을 conclusion에서 총체적으로 정리했습니다. 그리고 마지막에 자신들이 만든 모델에 다른 센서의 입력값을 추가해서 쓰거나 다른 AI task에 사용할 수 있다고 말하며 논문을 끝냈습니다.\n",
            "이렇게 길고 긴 논문 리뷰가 끝났습니다. 최선을 다해 리뷰해봤는데 미숙한 부분이 많았습니다. 이런식으로 데이터를 받아서 처리하는 모델도 처음 접했고 자율주행 task를 수행하는 모델도 처음이라 읽는데 많은 시간이 걸렸습니다. 그래도 리뷰하고 나니 뿌듯하네요.\n",
            "3주 뒤에 다른 논문을 세미나에서 발표하는데 그 논문도 velog에 올릴 계획입니다. 개강이 얼마 남지 않은 시기라 쓰기 힘들겠지만 하...할 수 있겠죠?\n",
            "마지막으로 제가 이 논문을 읽고 느낀점을 쓰고자 합니다. 제가 느낀 점은 다음과 같습니다.\n",
            "두 종류의 입력값을 특성 추출 과정에서 반영함으로써 안전한 운전을 구현했다는 사실이 흥미로웠다.\n",
            "허나 Transformer가 전체 입력값을 모두 고려하며 계산하기 때문에 연산량이 좀 많을텐데 실시간으로 판단이 필요한 운전에서 이런 점이 부담이 되지 않을까 싶다.\n",
            "추후 주행 속도도 개선하며 안전운전을 추구하는 모델이 나왔으면 좋겠다.\n",
            "그리고 제가 이걸 세미나에서 발표했을 때 교수님께서 \"꼭 두가지 데이터를 사용했어야 했을까, LiDAR에서 얻은 정보를 사용할 때 2D 데이터로 변환하는 과정에서 많은 데이터 손실이 있을텐데 그걸 감수하면서까지 사용할 이유가 있을지 모르겠다, 차라리 시야각이 넓은 이미지를 사용하면 데이터 손실도 없이 사용할 수 있지 않을까\" 라고 저에게 말씀하셨습니다.\n",
            "실은 저는 입력값에 대한 어떠한 의문도 가지지 않았는데 교수님의 말씀을 듣고 의문이 들었습니다. 실제로 표를 봤을 때\n",
            "\n",
            "여기 보시면 한가지 입력값만 받는 AIM과 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능차이가 크게 없다는 사실을 확인할 수 있습니다. 물론 장거리 주행에서는 DS에서 차이가 나긴 하지만 다들 점수가 낮기 때문에 큰 상관은 없다고 생각합니다.\n",
            "아무튼, 많은 공부가 되었고 재밌게 읽은 논문이었습니다. 다음 논문 리뷰에서 뵙겠습니다!\n",
            "꼼꼼한 논문 리뷰 잘 보았습니다. 저도 논문 리서치 중인데, 논문 리뷰는 이렇게 하는 것이군요.ㅎㅎ 본받아서 저도 열심히 조사해야겠어요. 감사합니다:)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "img_url_list = soup.find_all('img',{'src':\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fd919d9ce-64eb-4d23-9e83-c67e9f7b4ca7%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.06.23.png\"})\n",
        "img_url_list\n",
        "\n",
        "#for i_list in img_url_list:\n",
        "#  print(i_list.text.strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAGQUbAhLL0-",
        "outputId": "d0d7db8f-33ac-4f1c-a884-9f5a51f37bc5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<img src=\"https://velog.velcdn.com/images%2Fminkyu4506%2Fpost%2Fd919d9ce-64eb-4d23-9e83-c67e9f7b4ca7%2F%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7%202021-08-06%20%EC%98%A4%EC%A0%84%2012.06.23.png\"/>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_multi = []\n",
        "text_list = soup.find_all('p')\n",
        "#text_list = for t in text_list: t.text.strip()\n",
        "\n",
        "for t in text_list:\n",
        "  text_multi.append(t.text.strip())\n",
        "\n",
        "text_multi = ''.join(text_multi)  # list -> str\n",
        "\n",
        "file = open('multi_text.txt','w')\n",
        "file.write(text_multi)\n",
        "file.close()"
      ],
      "metadata": {
        "id": "HF2cXFRmPrac"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 확인"
      ],
      "metadata": {
        "id": "02fjD2YqURG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# readline\n",
        "\n",
        "f = open(\"/content/multi_text.txt\", 'r')\n",
        "while True:\n",
        "  line = f.readline()\n",
        "  if not line: break\n",
        "  print(line)\n",
        "\n",
        "f.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZ21hZnrT290",
        "outputId": "957dd1f2-429d-4caa-fd45-67f6645273e6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "안녕하세요. 밍기뉴와제제입니다.정말 오랜만에 돌아왔습니다. 논문은 여러개 봤는데 리뷰할 정도로 깊게 탐구한 논문이 별로 없어 한동안 글을 안쓰다 이번에 논문 세미나를 하다보니 꼼꼼히 살펴본 논문이 생겼습니다.이번에 리뷰를 하려는 논문은 'Multi-Modal Fusion Transformer for End-to-End Autonomous Driving '라는 논문입니다. 자율주행에 관한 논문이죠.이름을 보면 대충 짐작 가시겠지만 이 논문은 multimodal, 두가지 데이터를 처리하는 모델을 설계했습니다. 그리고 Transformer도 이용했다는 사실을 짐작할 수 있습니다.그러면 지금부터 논문 흐름에 맞춰 리뷰를 해보도록 하겠습니다.이 부분에서는 이전까지 자율주행 모델이 사용한 방식들을 소개 후 저자가 소개하는 모델 'transfuser'에 대해 설명합니다.이전에 Image-only model과 LiDAR-only model이 등장했고 이는 자율주행의 성능을 올리는데 많이 기여했습니다. 허나 이렇게 한가지 데이터만 입력값으로 사용한 모델은 near-ideal한 움직임을 보이는 객체들만 있는 환경에서 제한된 움직임만 필요한 경로에 주행해야만 높은 성능을 보여준다는 것이었죠. 굉장히 사용하기 까다로웠습니다.논문에서는 이를 두고 다음과 같이 말했습니다.adversarial scenarios에서 만족스럽지 못한 성능을 보여준다여기서 adversarial scenarios는 운전에 변수가 많이 생기는 환경을 말합니다. 예를 들면 비보호 회전을 해야하는 교차로, 랜덤하게 등장하는 자동차와 보행자 등이 운전에 변수를 주는 요소라 볼 수 있죠.\n",
            "\n",
            "그러면 이런 부분이 왜 낮은 성능이 나오게끔 하는걸까요? 다음의 그림을 보며 설명해 드리도록 하겠습니다.위 사진은 논문에서 말한 adversarial scenarios 중 하나입니다.\n",
            "\n",
            "여기서 초록색 박스 안에 있는 자동차(Ego-Vehicle)와 왼쪽 도로에서 건너오는 빨간색 박스 속 자동차들(Traffic), 그리고 노란색 박스 안에 있는 신호등(Traffic Lights)이 있습니다. 여기서 Ego-Vehicle이 자율주행을 하는 자동차죠.이 상황에서 Ego-Vehicle이 카메라와 LiDAR에서 얻은 데이터를 살펴봅시다. LiDAR의 정의는 다음과 같습니다.LiDAR : Light Detection And Ranging, 레이저를 발사 후 돌아오는 시간을 계산해 주변 물체를 검출하는 센서LiDAR는 3D 데이터인 Point Cloud를 생산하며 여기엔 카메라가 관측할 수 없는 넓은 범위에 존재하는 객체에 대한 정보가 포함되어 있습니다. 그림을 보면 카메라 뷰에서 보이지 않는 자동차(Traffic)을 검출했다는 사실을 확인할 수 있습니다.허나 LiDAR는 카메라가 검출한 신호등을 찾지 못했습니다. 즉, 각 센서별로 얻을 수 있는 정보가 다릅니다.이러한 상황에서 Image-only 혹은 LiDAR-only model을 사용해 자율주행을 한다고 가정해봅시다.\n",
            "\n",
            "그러면 아래와 같은 문제가 생길 확률이 높습니다.이건 꽤 큰 단점이죠. 그래서 사람들은 이를 해결하기 위한 방법을 찾고자 했습니다.사람들은 자율주행 자동차에 있는 센서에 주목했습니다.\n",
            "\n",
            "\n",
            "\n",
            "(출처 : https://towardsdatascience.com/how-to-make-a-vehicle-autonomous-16edf164c30f)위 사진은 자율주행 자동차에 들어있는 센서를 나타낸 그림입니다. 보시면 알겠지만 자율주행 자동차 안에는 수많은 센서들이 들어있습니다.이렇게 많은 센서를 보고 사람들이 생각한게 있습니다.\"자동차에 있는 두개의 센서를 함께 사용해보는건 어떨까?\"그래서 두가지 데이터를 함께 써보자는 아이디어를 떠올렸죠. 그리고 다음과 같은 질문을 남겼습니다.이 질문에 답하기 위해 수많은 논문들이 나왔습니다. 그 중 한가지 논문에 나온 모델 구조에 대해 간단히 소개해드리겠습니다.(출처 : Xiaozhi Chen, Huimin Ma, Ji Wan, Bo Li, and Tian Xia. Multi-view 3d object detection network for autonomous driving. In Proc. IEEE Conf. on Computer Vision and Pat- tern Recognition (CVPR), 2017)위 그림에 나온 구조가 두가지 데이터를 처리하는 대부분의 모델이 사용하는 구조입니다. 각 데이터별로 CNN에 넣어 특성맵을 추출한 뒤 원소 단위로 평균값을 낸다든지 더한다든지 하는 방식으로 Fusion해 하나의 출력값으로 만드는 방식이죠.두가지 데이터를 이용하는 방식은 한가지 데이터를 사용하는 방식보다 성능이 좋았습니다. 허나 여전히 단점이 있었습니다.바로 도심 속 운전같이 복잡한 상황에서 운전하기 힘들다는 점이었습니다.교차로에서 운전할 때를 고려해봅시다. 위에 제가 올린 사진과 같은 상황이죠. 여기서 자율주행을 하는 자동차(Ego-Vehicle)는 왼쪽에서 오는 자동차(Traffic)과 신호등의 신호(Traffic Lights) 사이의 연관성을 고려하며 운전을 해야합니다. 허나 각 데이터별로 특성맵을 추출하면 특성을 추출하는 과정에서 모든 정보를 고려할 수 없게 됩니다.즉, 모든 정보를 고려하지 않고 얻어낸 정보를 가지고 운전하기 때문에 사고가 날 확률이 높은 것이죠.이는 데이터의 문제가 아니라 데이터를 처리하는 모델 구조의 문제였습니다.그래서 저자는 Attention mechanism만 사용해 데이터를 처리하는 Transformer를 특성 추출 과정에서 사용하기로 했습니다.Transformer의 self-attention는 입력 값의 각 원소가 전체적인 입력값의 어느 부분을 더 주목해야 하는지 반영하게 해주니 이를 이용해 이미지와 LiDAR 데이터를 전체적으로 고려하며 특성맵을 추출하는 방식을 생각한 것입니다.\"두가지 데이터를 어떤 방식으로 합쳐서 사용하지?\" 에 대한 답변은 Transforemr였습니다.그리고 \"두가지 데이터로 어떤걸 선택하지?\"에 대한 답변을 해야합니다.저자는 이에 \"Single-view image and LiDAR를 입력 데이터로 사용한다\"고 말했습니다.\n",
            "\n",
            "\n",
            "\n",
            "이 둘을 사용하겠다는 것이죠.왜 Single-view image and LiDAR를 선택한 걸까요? 저자는 이 둘이 서로가 서로에게 부족한 점을 채워주는 상호보완성이 있기 때문에 선택했다고 말했습니다.즉, 이 둘을 입력데이터로 사용해 얻는 정보의 양이 제일 많다고 판단한 것이죠.이제 저자가 생각해낸 모델을 정리해봅시다.입력 데이터로 Single-view image and LiDAR를 받아 특성을 추출하는 과정에서 Transformer를 사용해 전체적인 정보를 고려하는 모델한문장으로 간단히 정리됩니다. 저자는 이렇게 설계된 모델을 Transfuser라고 정의했습니다.여기까지 모델의 Introduction 부분이었습니다. 깔끔히 쓰고 싶었는데 쉽지않네요. 허허...그럼 이제 Transfuser가 포함된 자율주행 모델이 만들어지는 과정을 소개한 Method 항목을 소개해 드리도록 하겠습니다.원래 Releated work를 슥 살펴보고 Method로 넘어가야 하는데 그러면 분량이 너무 많아져서 바로 Method로 건너왔습니다. 저도 자율주행 모델에 대해 잘 감이 안잡힌 상태에서 이 논문을 읽어서 Related work 부분이 논문 이해에 꽤나 도움이 되었습니다. 관심 있으신 분들은 따로 찾아서 읽어보시는걸 추천드립니다.아무튼, 이제 Method에 대해 설명해 드리도록 하겠습니다.Method에는 Transformer를 이용해 자율주행 모델을 만드는 일련의 과정이 적혀있습니다.모델을 만드는 과정은 다음과 같이 3단계로 나눌 수 있습니다.그러면 'Task 설정'부터 설명해 드리도록 하겠습니다.모델이 해결할 Task를 설정하고 이를 위한 학습법, 그리고 필요한 데이터셋을 설명하는 부분입니다.저자는 point-to-point navigation를 모델이 수행할 Task로 설정했습니다.저자는 point to point navigation이 목표지점까지 waypoint를 따라 사고 없이 완주하는 것이라 말했습니다. 여기서 사고는 다른 객체(자동차, 사람 등)과 충돌하거나 교통법규를 어기는 것을 말하죠.그리고 이를 학습하는 방법으로 imitation learning을 선택했습니다. imitation learning이란 강화학습의 일종인데요, 의미 그대로 해당 task에서 전문가(Expert)가 하는걸 따라하는 학습법입니다.강화 학습은 학습 주체인 agent와 agent가 행동하는데 규범이 되는 policy, 행동의 결과인 action, action으로 인한 상태 state, 그리고 state에 대한 보상 reward가 있습니다.여기서 보상 reward를 가장 많이 받는 방향으로 학습시키는 것이 목표죠.reward를 많이 받도록 만드는 방식은 여러가지가 있습니다. 그중 하나가 행동 규범힌 policy를 학습가능한 상태(parameterize)로 만드는 것이죠.imitation learning도 그 방식을 사용하고 있으며 논문에서는 다음과 같이 설명합니다.Policy를 Expert의 policy를 따라하게끔 학습하는 것그런데 여기서 궁금증이 생겼습니다. 왜 imiation learning을 선택한거지? 그래서 찾아봤습니다.\n",
            "\n",
            "찾아보니까 이렇게 policy를 학습 대상으로 삼아 학습시키는 방식은 고차원 데이터를 처리하고 연속된 action을 해야하는 모델의 학습에 적합하다고 합니다.이미지라는 고차원 데이터를 처리해 연속된 action이 필요한 운전을 하는 자율주행 모델에 적합한방식이라 선택한게 아닌가 싶습니다.그러면 이제 저자가 imitation learning을 사용한 학습과정을 설명해 드리도록 하겠습니다.우선 데이터셋을 수집해야하죠? 학습을 위한 학습 데이터셋과 평가를 위한 테스트 데이터셋이 필요합니다.데이터셋은 자율주행 오픈소스 시뮬레이터 CARLA(https://carla.org)에 있는 가상 환경에서 수집\n",
            "\n",
            "합니다. 별다른 이유는 적지 않았지만 아무래도 사고가 날 수 있는 상황에 대한 데이터도 모으기 때문에 그런게 아닌가 싶네요.여튼, CARLA에 있는 가상환경에서 Expert가 주행하며 데이터를 모읍니다. imitation learning에서 말씀드린 Expert 맞습니다.Expert는 가상환경을 주행하며 입력 데이터와 출력 데이터를 수집합니다. 그렇게 해서\n",
            "\n",
            "\n",
            "\n",
            "위와 같은 데이터셋 D를 만들어줍니다.여기서 X는 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 한 시점(single time step)에 이미지 한장, point cloud 하나가 있는 것이죠.그리고 W는 T개의 waypoint가 모인 w로 이루어져 있습니다. 즉, 이미지와 point cloud를 하나씩 넣으면 출력값으로 T개의 Waypoint가 나오는 모델을 만들겠다는 뜻이죠.이렇게 데이터셋을 모았으니 학습을 시켜봅시다. 학습 방식은 다음과 같이 정의할 수 있습니다.\n",
            "\n",
            "\n",
            "\n",
            "여기서 L은 Loss함수입니다. 그러니까 Expert가 주행한 경로와 우리가 만든 agent의 policy에 따른 action, 다시 말해 우리가 만든 모델이 예측한 주행 경로 사이의 loss가 최소가 되게끔 policy를 학습시키겠다는 뜻이죠.저자는 이러한 학습 방식을 지도학습의 방식이라고 말했습니다. Expert의 데이터를 label data, 내가 만든 모델의 데이터가 prediction data라고 보면 저자의 말이 이해가 되시지 않을까 싶습니다.그래서 강화학습은 어떻게 학습 시키는걸까 찾아봤습니다. 강화학습은 데이터셋을 사용하지 않고 학습하기 때문에 매 순간 자기 자신이 만든 state와 reward를 보고 다음 action에 반영하며 점점 높은 reward만 받는 모델로 학습되는 방식을 사용한다는 사실을 알아냈습니다. 지도학습으로만 모델을 학습시켜본 저에게 있어서 강화학습은 상당히 신기한 방식입니다.저자는 학습 이후 어떻게 자율주행에 사용할지도 설명해 주었습니다.\n",
            "\n",
            "저자는 모델이 예측한 경로를 inverse dynamics model에 넣어 얻은 action으로 주행을 한다고 말했고 이 때 inverse dynamics model을 PID controller로 구현했다고 설명했습니다.PID controller는 간단한게 말해 주어진 출력값을 위해 필요한 제어값(가속, 감속, 회전 등)을 구하는 요소라고 보시면 됩니다. 자세한 설명은 여기서 확인하실 수 있습니다.저자는 이러한 과정을 다음과 같은 식으로 나타냈습니다.\n",
            "\n",
            "\n",
            "\n",
            "action = PID(예측 경로)인 것이죠. 여기서 action은 agent가 행한 action과 동일한 개념입니다.마지막에 등장하는 문단인데 처음에는 이게 왜 있는건가 싶었습니다.읽어보니 저자들은 CARLA의 표준 프로토콜을 따르고 목표 지점이 GPS 좌표로 제공되며 목표 지점과 자동차가 안내한 지점이 몇백미터 떨어질 수 있다고 나와있습니다.다른 부분은 그러려니 하고 읽었는데 마지막 부분 '목표 지점과 안내 지점이 몇백미터 떨어질 수 있다'는 말이 거슬렸습니다. 도대체 뭔 뜻이지?제가 논문 세미나를 할 때 이 논문을 가지고 했는데요, 이에 관해 세미나 계신 분들께 여쭤보고 답을 들었는데도 이해가 제대로 안되서 구글에 검색까지 해봤습니다.구글에 검색을 해보니 다음과 같은 글을 발견했습니다.The global planner plans a global path around obstacles대충 번역하면 장애물을 돌아가는 global path를 생성하는게 global planner라고 하네요.아마 목표 지점에 가기 힘들면 그 근처로 안내할 수 있음을 말하고 싶어서 이 부분을 추가한게 아닌가 싶습니다.여기까지 Problem Setting이었습니다.이제 데이터셋을 어떻게 만들었는지? 정확히는 모델의 학습에 사용하기 위해 어떤 작업을 했는지 설명해 드리도록 하겠습니다.우선 입력 데이터부터 설명해 드리고자 합니다.입력 데이터는 앞서 말씀드렸듯 전면 카메라 이미지와 LiDAR에서 얻은 Point cloud로 구성되어 있습니다. 카메라 이미지는 2D 데이터고 Point cloud는 3D 데이터라 각자 처리방식이 다릅니다.카메라 이미지\n",
            "\n",
            "카메라에서 촬영된 이미지는 400X300 사이즈인데요, 여기서 가운데 256X256 영역만 추출해서 사용합니다. 왜냐하면 렌즈 구조상 외곽 이미지는 왜곡 되어있기 때문입니다. 이렇게 256X256X3 사이즈의 데이터를 얻습니다.LiDAR Point Cloud\n",
            "\n",
            "저자는 LiDAR에서 얻은 Point Cloud 중 자동차의 전면 32m, 좌우 측면 각 16m씩 해서 총 32m X 32m 영역만 사용합니다. 그리고 이를 2D 데이터로 변환해주는데요, 한 셀당 0.125m X 0.125m로 해서 256 X 256 픽셀 데이터로 변환해줍니다.\n",
            "\n",
            "그리고 Point Cloud는 3D 데이터라 높이에 관한 데이터도 있는데요, 저자는 이를 2개의 채널에 담았습니다. 하나는 지면 위(+) 높이 데이터, 다른 하나는 지면 밑(-) 높이 데이터를 담았죠.\n",
            "\n",
            "이렇게 256X256X2 사이즈의 데이터를 얻습니다.출력값 양식을 정의하는 부분입니다.출력값, 즉 waypoint는 BEV space에서 (x,y)의 양식을 지닙니다.이런 방식으로 나온다는 뜻이죠. 중심에 자동차가 있고 앞에 빨간 점으로 자동차가 이동할 waypoint가 나와 있습니다. 이 때 waypoint의 집합 trajectory는 다음과 같이 정의됩니다.앞서 데이터셋을 구성할 때 T개의 waypoint 예측값이 모인 데이터셋을 만든다고 말씀드렸는데요, 저자는 T를 4로 정의했습니다. 왜 T를 4로 정의했냐면 예측 궤적을 가기 위한 제어값을 얻는 PID controller가 요구하는 waypoint의 default number가 4라서 T를 4로 설정했다고 말했습니다.여기까지 Input and Output Parameterization였습니다.다음으로 모델의 구조에 대해 설명해 드리고자 합니다.모델의 구조는 크게 두 가지로 나눌 수 있습니다. 하나는 Multi-Modal Fusion Transformer고 다른 하나는 Waypoint Prediction Network입니다.Multi-Modal Fusion Transformer는 저자가 새로운 제안한 Transfuser를 말하는 것이구요, Waypoint Prediction Network는 Transfuser에서 얻은 값을 가지고 경로를 예측하는 모델입니다.우선 Transfuser부터 먼저 설명해 드리도록 하겠습니다.Transfuser는 다음과 같은 구조를 가지고 있습니다.\n",
            "\n",
            "\n",
            "\n",
            "제가 Trnafuser는 특성을 추출하는 과정에서 Transformer를 이용해 전체 데이터를 고려하는 모델이라고 말씀드렸는데요, 이 그림을 보시면 \"아...이런 뜻이구나\" 이해하시지 않을까 싶습니다.여기서 눈여겨볼 항목은 당연히 저자가 강조한 Transformer를 이용해 전체 데이터 정보를 각 특성맵에 반영해주는 부분입니다.\n",
            "\n",
            " \n",
            "\n",
            "이 부분을 말하는 것이죠. 아래 그림은 윗 그림에서 Transformer 부분을 강조한 그림입니다.여기서 진행되는 연산의 순서를 말씀드리면 다음과 같습니다.코드로 나타내면 상당히 간단해집니다.\n",
            "\n",
            "\n",
            "\n",
            "아무튼 간단해집니다.여튼, 이런 과정을 총 4번 반복합니다. 더 해도 안된다는 법은 없는데 저자는 4번 반복하라고 말했습니다.4번 반복한 뒤 마지막에 Average Pooling + Flatten연산을 해서 1 X 1 X 512 벡터를 2개 생성합니다. 이미지에서 얻고 LiDAR에서 얻으니까 총 2개를 얻는 것이죠.이 2개의 벡터를 element-wise summation해서 하나의 1 X 1 X 512 벡터로 만들어줍니다.이렇게 우리는 최종 출력값 1 X 1 X 512 벡터를 얻었습니다. 이제 Waypoint Prediction Network를 확인해보도록 합시다.앞서 우리는 Transfuser에서 1 X 1 X 512 사이즈의 벡터를 얻었습니다.이 벡터는 Waypoint Prediction Network에 쓰입니다.Waypoint Predictoin Network는 다음과 같은 구조를 가지고 있습니다.보시면 MLP와 GRU로 이루어졌다는 사실을 확인하실 수 있습니다.MLP\n",
            "\n",
            "MLP는 3개의 Linear Layer로 이루어져 있습니다. MLP는 입력값으로 들어오는 1 X 1 X 512 사이즈의 벡터를 1 X 1 X 64 벡터로 압축해줍니다. 계산의 효율성을 위해 줄여주는 겁니다.\n",
            "\n",
            "코드는 다음과 같습니다.GRU\n",
            "\n",
            "GRU는 RNN에서 많이 쓰였던 LSTM을 개선한 알고리즘 입니다. 시계열 데이터를 처리하는데 적합한 알고리즘이죠. 이걸 레이어 형식으로 추가했습니다.\n",
            "\n",
            "GRU는 현 시점의 입력 데이터와 hidden state를 받아 연산을 처리합니다. waypoint prediction network에서는 자동차의 좌표와 목표 지점의 좌표를 더한 값을 입력 값으로 하였습니다. 이 때 좌표의 단위는 gps입니다.\n",
            "\n",
            "여기서 흥미로운 점이 있습니다. 바로 첫 시점의 입력 데이터 중 자동차의 좌표가 (0,0)이라는 점입니다. 이는 자동차가 좌표계의 원점에 있다고 가정했기 때문입니다.\n",
            "\n",
            "그러니까 입력 데이터를 넣는 시점에서 자동차의 위치가 x = (0,0)에 있다고 보는 것이고 (0,0)를 기준으로 향후 4 time의 waypoint를 예측하는 것이라 보시면 되겠습니다.\n",
            "\n",
            "다시 본론으로 돌아옵시다. 입력 데이터를 알아봤으니 이제 hidden state로 넘어가야죠. hidden state는 앞서 얻은 1 X 1 X 64 벡터로 초기화해줍니다. 우리가 입력 데이터로 얻은 특성을 hidden state를 초기화하는데 사용하는 겁니다.\n",
            "\n",
            "이렇게 입력값을 넣어주면 출력값이 나올겁니다. 이 출력값을 Linear layer에 넣으면 현 시점의 자동차에서 움직여야할 좌표 dx가 생성됩니다.\n",
            "\n",
            "이 dx에 기존 자동차의 좌표 x에 더하면 이제 다음 시점에 이동할 waypoint가 되는 겁니다.\n",
            "\n",
            "이 waypoints는 다음 시점에서 현재 좌표가 되겠죠? next_x = x + dx인 겁니다.\n",
            "\n",
            "여튼 이 과정을 4번 반복해 waypoint 4개를 얻습니다.모델의 구조에는 없지만 자율주행을 수행하기 위해 꼭 있어야할 PID controller입니다.\n",
            "\n",
            "앞서 예측한 경로를 PID controller에 넣어 주행에 필요한 제어값을 얻는다고 말씀드렸습니다.\n",
            "\n",
            "실은 그 이상으로 설명드릴게 없습니다. 그러니 여기서는 구현된 코드를 보여드리고 넘어가도록 하겠습니다.\n",
            "\n",
            "\n",
            "\n",
            "코드의 return 부분을 보시면 운전에 필요한 데이터들이 나와있습니다. steer는 차를 얼마나 회전할지 나타낸거고 throttle는 엔진에 들어갈 공기량을 제어하니까 가속을 얼마나 할지 나타낸거고 brake는 감속을 얼마나 할지 나타내는 것이죠.그런데 낯선 데이터가 하나 있습니다. 바로 metadata입니다. 슥 살펴보니 steer, throttle, brake만으로 설명이 안되는 정보를 보충 설명해주는 데이터인듯 합니다. 아마 저자가 실험했을 때 제어값의 정보 부족으로 좀 애먹었던게 아닌가 싶네요. 제 추측입니다.여기까지 모델의 구조를 살펴봤습니다.이제 실험 부분을 설명해 드리고자 합니다.여기서는 실험 세팅(experimental setup), 성능 비교(Results), 입력 데이터간 상호보완성 비교(Attention Map Visualizations), 구성 요소를 하나씩 빼면서 성능 확인(Ablation Study) 순으로 내용이 전개됩니다.여기서는 성능 측정을 위해 모델이 해야할 task와 이를 위해 필요한 데이터셋, 평가 지표와 성능을 비교할 모델을 소개하고 있습니다.모델이 수행할 task는 다양한 주행 환경에서 제한 시간 안에 운전 규정을 시키며 주행하는 것입니다.여기서 주행 경로는 gps좌표 형식의 waypoint의 집합으로 제공되며 주행 도중에 일정 확률로 자동차나 보행자가 등장할 수 있고 차선 변경, 회전 등 주행 중에 충분히 일어날 수 있는 상황도 경로에 포함되어 있습니다.앞서 논문에서 말한 '복잡한 운전 상황'속 주행 성능을 평가하는거라 생각하시면 됩니다.데이터셋을 모으는 방법이 적혀있습니다.앞서 말씀드렸듯 Expert가 CARLA에 있는 가상환경에서 주행하며 데이터를 모은다고 말씀드렸습니다. 여기서 더 자세히 써보도록 하겠습니다.CARLA에는 주행을 할 수 있는 8개의 Town이 있습니다. 8개의 가상환경이 있는 것이죠. 각 town의 특성은 다음과 같습니다.\n",
            "\n",
            "\n",
            "\n",
            "각자 특성을 가지고 있죠. Expert는 여기서 Town 01, 02, 03, 04, 06, 07, 10에 사전 정의된 경로들을 달리며 학습용 데이터셋을 수집합니다.그리고 학습용 데이터셋으로 모델을 훈련시키고 난 뒤 Town05에서 주행 성능을 평가합니다.Town05는 1차선부터 n차선, 그리고 일반도로부터 고속도로까지 다양한 도로가 있기 때문에 주행 성능을 평가하는 맵으로 선정했다고 말했습니다.Town05에 깔려있는 도로를 나타낸 사진입니다. 다양한 도로로 구성되어 있음을 확인할 수 있습니다.저자는 어떠한 주행 경로에서 성능을 평가하는지도 설명했습니다. 저자는 단거리 경로와 장거리 경로를 각 10개씩 뽑았고 이를 Town05 Short, Town05 Long이라 이름 지었습니다. 특징은 다음과 같습니다.그리고 주행 중에 자동차나 사람이 등장할 수 있다는 공통점이 있습니다.마지막으로 날씨입니다. 맑은 날 주행하는거랑 비오는 날에 주행하는건 난이도가 어느정도 차이가 나는데요, 저자는 동적인 객체와 신호등에 대한 주행 성능 평가에 집중할 것이기 때문에 날씨는 '항상 맑음'으로 고정한다고 말했습니다.개인적으로 아쉬운 부분이었습니다. 날씨도 변수를 줘서 실험을 했으면 더 좋지 않았을까 생각합니다.구글에 검색해보니 '측정 수단'이라는 뜻으로 해석됩니다. 즉, 평가지표입니다.저자는 평가 지표로 RC, DS, Infraction Count를 선택했습니다. 하나씩 설명해 드리도록 하겠습니다.Transfuser가 포함된 자율주행 모델과 성능을 비교할 모델을 적어놓았습니다. 5개의 모델과 비교합니다.모델 종류는 다음과 같습니다.실험 결과는 다음과 같습니다.\n",
            "\n",
            "\n",
            "\n",
            "왼쪽 사진은 Short, Long 경로에서 모델별 RC, DS를 나타낸거고 오른쪽 사진은 사고율을 나타낸 겁니다.우선 왼쪽 표에 대해서 설명을 해드리도록 하겠습니다.여기서 눈여겨볼 부분은 한가지 입력값을 받는 CILRS, LBC, AIM보다 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능이 더 좋다는 겁니다. 두가지 입력값을 쓰기만 해도 한가지 입력값을 쓰는 것보다 성능이 좋다는 사실을 알 수 있습니다.그리고 또다시 눈여겨볼 부분은 Transfuser가 Late Fusion, Geometric Fusion보다 RC는 낮은데 DS가 높다는 것입니다. 즉, Transfuser는 주행 거리는 짧지만 안전운전을 더 잘한다는 뜻이죠.저자는 이를 보고 'Late Fusion, Geometric Fusion는 안전하게 운전하는 것보다 목표 지점에 가는데 중점을 뒀기 때문에 이런 결과가 나왔다'고 말했습니다.그리고 Expert의 점수도 나와있는데요, Expert도 장거리 운전에서는 그리 좋지 못한 성적을 얻었습니다. 신기합니다.모델별 평균 사고율이 나옵니다. 초록색 막대가 Transfuser인데요, 모든 사고 항목에서 가장 낮습니다. 그런데  빨간불 신호 위반에서 다른 모델보다 낮긴 하지만 그래도 다른 사고 항목에 비하면 굉장히 높은 수치를 보입니다. 왜 그런걸까요?여기선 모델의 한계점에 대해 저자가 얘기하는 부분입니다. 저자는 모델의 한계점으로 빨간불 신호 위반의 확률이 높은 것을 꼽았습니다.높은 신호위반 확률을 보이는 이유는 성능 평가를 위해 주행하던 경로에서 신호등이 카메라 구석에 찍혔는데 이 때문에 신호등의 빨간 불빛을 감지하기가 힘들어 빨간불에서 정차하지 않고 주행하는 일이 많았다고 합니다.그리고 이러한 문제를 해결할 additional supervision을 기대해본다고 말했습니다.여기서는 카메라 이미지와 LiDAR point cloud간 상호보완성을 보여줍니다.어떻게 보여주냐면 교차로에서 신호대기중인 차량에서 얻은 이미지, Point cloud를 Transfuser로 특성을 추출하는 과정에서 self-attention을 통해 나온 16X8 사이즈의 벡터를 통해 설명합니다.여기서 반은 이미지쪽 벡터고 나머지 반은 LiDAR쪽 벡터입니다. 여기서 각각 자동차와 신호등에 대한 정보가 담긴 부분만 추출해 서로 얼마나 attention을 했는지 확인해봅니다. attention이 반영된 정도는 각 요소별 곱해진 score를 보고 알 수 있죠.그렇게 attention된 정도를 확인한 결과, 다음의 사실을 알 수 있었습니다.여기서 토큰은 transformer에 입력값으로 들어가는 데이터 단위를 말합니다. 출력값 역시 토큰의 집합이죠. 토큰을 데이터로 바꾼 뒤 읽으셔도 의미의 차이는 없을듯 합니다.아무튼, 이렇게 서로 상호보완하는 부분이 많습니다. 특성을 추출할 때 상대 데이터를 많이 고려한다는 뜻이죠.여기서는 Transfuser의 Transformer에 대해 값을 수정해가며 성능의 변화를 관측한걸 얘기합니다. 저자는 Town05 Short에서 성능 평가를 했는데요, 성능표는 다음과 같았습니다.\n",
            "\n",
            "\n",
            "\n",
            "하나씩 설명해드리도록 하겠습니다.이렇게 각 요소를 제거한 뒤 성능을 비교했습니다. Scale을 제외한 나머지 부분에서 하나의 공통점이 있는데요, 바로 RC는 증가하지만 DS가 떨어졌다는 점입니다.저자는 이를 보고 'Attention횟수가 많아질 수록 더 조심히 운전하게 된다'고 말했습니다.논문의 결말입니다. 저자는 앞서 말한 것을 conclusion에서 총체적으로 정리했습니다. 그리고 마지막에 자신들이 만든 모델에 다른 센서의 입력값을 추가해서 쓰거나 다른 AI task에 사용할 수 있다고 말하며 논문을 끝냈습니다.이렇게 길고 긴 논문 리뷰가 끝났습니다. 최선을 다해 리뷰해봤는데 미숙한 부분이 많았습니다. 이런식으로 데이터를 받아서 처리하는 모델도 처음 접했고 자율주행 task를 수행하는 모델도 처음이라 읽는데 많은 시간이 걸렸습니다. 그래도 리뷰하고 나니 뿌듯하네요.3주 뒤에 다른 논문을 세미나에서 발표하는데 그 논문도 velog에 올릴 계획입니다. 개강이 얼마 남지 않은 시기라 쓰기 힘들겠지만 하...할 수 있겠죠?마지막으로 제가 이 논문을 읽고 느낀점을 쓰고자 합니다. 제가 느낀 점은 다음과 같습니다.두 종류의 입력값을 특성 추출 과정에서 반영함으로써 안전한 운전을 구현했다는 사실이 흥미로웠다.허나 Transformer가 전체 입력값을 모두 고려하며 계산하기 때문에 연산량이 좀 많을텐데 실시간으로 판단이 필요한 운전에서 이런 점이 부담이 되지 않을까 싶다.추후 주행 속도도 개선하며 안전운전을 추구하는 모델이 나왔으면 좋겠다.그리고 제가 이걸 세미나에서 발표했을 때 교수님께서 \"꼭 두가지 데이터를 사용했어야 했을까, LiDAR에서 얻은 정보를 사용할 때 2D 데이터로 변환하는 과정에서 많은 데이터 손실이 있을텐데 그걸 감수하면서까지 사용할 이유가 있을지 모르겠다, 차라리 시야각이 넓은 이미지를 사용하면 데이터 손실도 없이 사용할 수 있지 않을까\" 라고 저에게 말씀하셨습니다.실은 저는 입력값에 대한 어떠한 의문도 가지지 않았는데 교수님의 말씀을 듣고 의문이 들었습니다. 실제로 표를 봤을 때\n",
            "\n",
            "\n",
            "\n",
            "여기 보시면 한가지 입력값만 받는 AIM과 두가지 입력값을 받는 Late Fusion, Geometric Fusion, Transfuser의 성능차이가 크게 없다는 사실을 확인할 수 있습니다. 물론 장거리 주행에서는 DS에서 차이가 나긴 하지만 다들 점수가 낮기 때문에 큰 상관은 없다고 생각합니다.아무튼, 많은 공부가 되었고 재밌게 읽은 논문이었습니다. 다음 논문 리뷰에서 뵙겠습니다!꼼꼼한 논문 리뷰 잘 보았습니다. 저도 논문 리서치 중인데, 논문 리뷰는 이렇게 하는 것이군요.ㅎㅎ 본받아서 저도 열심히 조사해야겠어요. 감사합니다:)\n"
          ]
        }
      ]
    }
  ]
}